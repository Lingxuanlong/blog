### 5.7 Mysql

https://www.runoob.com/mysql/mysql-tutorial.html

#### 5.7.1 概述

​     MySQL 是一个关系型数据库管理系统，由瑞典 MySQL AB 公司开发，目前属于 Oracle 公司。MySQL 是一种关联数据库管理系统，关联数据库将数据保存在不同的表中，而不是将所有数据放在一个大仓库内，这样就增加了速度并提高了灵活性。

- MySQL 是开源的，目前隶属于 Oracle 旗下产品。
- MySQL 支持大型的数据库。可以处理拥有上千万条记录的大型数据库。
- MySQL 使用标准的 SQL 数据语言形式。
- MySQL 可以运行于多个系统上，并且支持多种语言。这些编程语言包括 C、C++、Python、Java、Perl、PHP、Eiffel、Ruby 和 Tcl 等。
- MySQL 对PHP有很好的支持，PHP 是目前最流行的 Web 开发语言。
- MySQL 支持大型数据库，支持 5000 万条记录的数据仓库，32 位系统表文件最大可支持 4GB，64 位系统支持最大的表文件为8TB。
- MySQL 是可以定制的，采用了 GPL 协议，你可以修改源码来开发自己的 MySQL 系统。

安装

https://www.cnblogs.com/fnlingnzb-learner/p/5830622.html

mysql 官方下载地址

https://dev.mysql.com/downloads/mysql/

my.ini

```ini
[client]
# 设置mysql客户端默认字符集
default-character-set=utf8
 
[mysqld]
# 设置3306端口
port = 3306
# 设置mysql的安装目录
basedir=C:\\web\\mysql-8.0.11
# 设置 mysql数据库的数据的存放目录，MySQL 8+ 不需要以下配置，系统自己生成即可，否则有可能报错
# datadir=C:\\web\\sqldata
# 允许最大连接数
max_connections=20
# 服务端使用的字符集默认为8比特编码的latin1字符集
character-set-server=utf8
# 创建新表时将使用的默认存储引擎
default-storage-engine=INNODB
```



### Memcached 

##### Memcached 安装

https://www.runoob.com/memcached/memcached-install.html



### 5.8 Oracle

### 5.9 Solr

### 5.10 FreeMaker

### 5.11 Netty

### 5.12 Nginx

### 5.13 Tomcat

### 5.14 Apache

### 5.15 FastDFS

### 5.16 Jenkins

#### 一、介绍Jenkins

##### 1、Jenkins概念

　　Jenkins是一个功能强大的应用程序，允许**持续集成和持续交付项目**，无论用的是什么平台。这是一个免费的源代码，可以处理任何类型的构建或持续集成。集成Jenkins可以用于一些测试和部署技术。Jenkins是一种软件允许持续集成。

##### 2、Jenkins目的

① 持续、自动地构建/测试软件项目。

② 监控软件开放流程，快速问题定位及处理，提示开放效率。

##### 3、特性

① 开源的java语言开发持续集成工具，支持CI，CD。

② 易于安装部署配置：可通过yum安装,或下载war包以及通过docker容器等快速实现安装部署，可方便web界面配置管理。

③ 消息通知及测试报告：集成RSS/E-mail通过RSS发布构建结果或当构建完成时通过e-mail通知，生成JUnit/TestNG测试报告。

④ 分布式构建：支持Jenkins能够让多台计算机一起构建/测试。

⑤ 文件识别:Jenkins能够跟踪哪次构建生成哪些jar，哪次构建使用哪个版本的jar等。

⑥ 丰富的插件支持:支持扩展插件，你可以开发适合自己团队使用的工具，如git，svn，maven，docker等。

##### 4、产品发布流程

产品设计成型 -> 开发人员开发代码 -> 测试人员测试功能 -> 运维人员发布上线

持续集成 （Continuous integration，简称CI）

持续交付（Continuous delivery）

持续部署（continuous deployment）

 

#### 二、安装Jenkins

##### 1、安装JDK

  Jenkins是Java编写的，所以需要先安装JDK，这里采用yum安装，如果对版本有需求，可以直接在Oracle官网下载JDK；也可自己编译安装。

[root@jenkins ~]# yum install -y java-1.8.0

 

##### 2、安装Jekins

[root@jenkins ~]# cd /etc/yum.repos.d/

[root@jenkins yum.repos.d]# wget http://pkg.jenkins.io/redhat/jenkins.repo

[root@jenkins ~]# rpm --import http://pkg.jenkins.io/redhat/jenkins.io.key

[root@jenkins ~]# yum install -y jenkins

 

##### 3、修改配置文件

（1）查询yum下载Jenkins安装的文件

[root@jenkins ~]# rpm -ql jenkins

```
/etc/init.d/jenkins
/etc/logrotate.d/jenkins
/etc/sysconfig/jenkins
/usr/lib/jenkins
/usr/lib/jenkins/jenkins.war
/usr/sbin/rcjenkins
/var/cache/jenkins
/var/lib/jenkins
/var/log/jenkins
```

 

（2）创建Jenkins主目录

[root@jenkins ~]# mkdir /data/jenkins -p

[root@jenkins ~]# chown -R jenkins.jenkins /data/jenkins/

 

（3）修改配置文件

[root@jenkins ~]# vim /etc/sysconfig/jenkins

```
JENKINS_HOME="/mnt/cellar/jenkins"
JENKINS_USER="jenkins"
JENKINS_JAVA_OPTIONS="-Djava.awt.headless=true -Xms256m -Xmx512m -XX:MaxNewSize=256m -XX:Maxize=256m"
JENKINS_PORT="8000" 
```

（4）开启Jenkins服务

[root@jenkins bin]# systemctl start jenkins

 

（5）网页打开配置

打开192.168.130.110:8000/

**① 为了安全考虑，首先需要解锁Jenkins，请在/var/lib/jenkins/secrets/initialAdminPassword中查看文件。**

![img](https://img2018.cnblogs.com/blog/1216496/201809/1216496-20180929154422645-196405166.png)

在Jenkins服务器上查询管理员密码

[root@centos7-1 ~]# cat /data/jenkins/secrets/initialAdminPassword

250d0360e2a149dbb7402f96a26945e2

 

**② 选择需要安装的插件**

选择默认推荐即可，会安装通用的社区插件，剩下的可以在使用的时候再进行安装。

![img](https://img2018.cnblogs.com/blog/1216496/201809/1216496-20180929154455631-121998829.png)

开始安装，由于网络原因，有一些插件会安装失败。

![img](https://img2018.cnblogs.com/blog/1216496/201809/1216496-20180929154509960-593928049.png)

 

**③ 设置Admin用户和密码**

![img](https://img2018.cnblogs.com/blog/1216496/201809/1216496-20180929154521356-1783143237.png)

 

**④ 安装完成**

![img](https://img2018.cnblogs.com/blog/1216496/201809/1216496-20180929154533743-185875991.png)

 

**⑤ 登录Jenkins**

![img](https://img2018.cnblogs.com/blog/1216496/201809/1216496-20180929154546439-1243749439.png)

 

#### 三、安装完后，简单的配置

##### 1、系统配置

① 系统消息：Welcome to Jenkins~

② 全局属性--->环境变量，可根据自己的项目添加；如：gitlab：

![img](https://img2018.cnblogs.com/blog/1216496/201812/1216496-20181225161055783-1178107.png)

 

③ 扩展邮件通知（用于之后项目构建后发送邮件）

![img](https://img2018.cnblogs.com/blog/1216496/201812/1216496-20181225161119613-946281686.png)

 

④ 邮件配置

　　管理监控配置--->系统管理员邮件地址：along@163.com，要和下面的用户名一致；

　　邮件通知，配置如下：可以点击测试，是否配置成功

![img](https://img2018.cnblogs.com/blog/1216496/201812/1216496-20181225161136561-477202932.png)

 

##### 2、全局工具配置

如果你持续集成需要用的哪些工具，就需要在这里添加配置；后边持续集成中，将会详细讲解；

这里只举例：添加JDK工具

点击新增---> 取消自动安装 ---->然后查询Jenkins服务器上JDK的路径，填写JAVA_HOME --->  保存即可

![img](https://img2018.cnblogs.com/blog/1216496/201809/1216496-20180929154647848-771853598.png)

 

##### 3、插件管理

这里有可更新、可选未安装插件、已安装插件；可以通过过滤快速查找

![img](https://img2018.cnblogs.com/blog/1216496/201809/1216496-20180929155328709-302472729.png)

 

#### 四、开始一个简单的项目

##### 1、新建任务

输入一个项目名称，构建一个自由风格的软件项目

![img](https://img2018.cnblogs.com/blog/1216496/201812/1216496-20181225100855566-682627741.png) 

 

##### 2、配置项目

（1）General

描述：test  自己随意添加；

显示名称：along 是Jenkins看到的项目名称；

其他更多的用法，后续再讲；

![img](https://img2018.cnblogs.com/blog/1216496/201809/1216496-20180929161011857-231187012.png)

（2）源码管理（就是拉取代码的地方，可以选择git或SVN）

① 选择git，输入gitlab项目地址

![img](https://img2018.cnblogs.com/blog/1216496/201812/1216496-20181225101954642-1408979051.png)

 

② 点击Add添加凭据

选择SSH Username with pricate key，秘钥认证，输入私钥即可；

注：Jenkins服务器需在gitlab项目上有key

![img](https://img2018.cnblogs.com/blog/1216496/201809/1216496-20180929155449880-1498963020.png)

因为只是简单的示范，所以就只有这些简单的配置； 

 

##### 3、构建项目

（1）点击项目damo，立即构建

![img](https://img2018.cnblogs.com/blog/1216496/201809/1216496-20180929155508543-1988910911.png)

（2）可以点击#1，查询详细的控制台输出信息；

![img](https://img2018.cnblogs.com/blog/1216496/201809/1216496-20180929155516248-1862719168.png)

 

（3）在Jenkins服务器上认证

在这个目录下能找到自己拉取git的项目；证明项目成功完成

[root@jenkins ~]# ls /data/jenkins/workspace/  

damo  damo@tmp

 

### 5.17 Doker

### 5.18 Mycat

### 5.19 Swagger

#### 1：简介

​    Swagger是一款接口文档生成中间件技术 便于维护现有开发的接口

#### 2：SpringBoot上集成

pom.xml加入依赖

~~~xml
<dependency>
    <groupId>io.springfox</groupId>
    <artifactId>springfox-swagger2</artifactId>
    <version>2.9.2</version>
</dependency>
<dependency>
    <groupId>io.springfox</groupId>
    <artifactId>springfox-swagger-ui</artifactId>
    <version>2.9.2</version>
</dependency>
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-web</artifactId>
</dependency>
~~~

配置 swaggerConfig 文件

~~~java
@Configuration
@EnableSwagger2
public class SwaggerConfig {
    @Bean
    public Docket createRestApi() {
        return new Docket(DocumentationType.SWAGGER_2)
                .pathMapping("/")
                .select()
                .apis(RequestHandlerSelectors.basePackage("com.nvn.controller"))
                .paths(PathSelectors.any())
                .build().apiInfo(new ApiInfoBuilder()
                        .title("SpringBoot整合Swagger")
                        .description("SpringBoot整合Swagger，详细信息......")
                        .version("9.0")
                        .contact(new Contact("啊啊啊啊","blog.csdn.net","aaa@gmail.com"))
                        .license("The Apache License")
                        .licenseUrl("http://www.baidu.com")
                        .build());
    }
}
~~~

​     这里提供一个配置类，首先通过@EnableSwagger2注解启用Swagger2，然后配置一个Docket Bean，这个Bean中，配置映射路径和要扫描的接口的位置，在apiInfo中，主要配置一下Swagger2文档网站的信息，例如网站的title，网站的描述，联系人的信息，使用的协议等等。

如此，Swagger2就算配置成功了，非常方便。

此时启动项目，输入http://localhost:8080/swagger-ui.html，能够看到如下页面，说明已经配置成功了：

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190324120135562.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly93YW5nc29uZy5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70)

这里边涉及到多个API，我来向小伙伴们分别说明：

~~~java
@RestController
@Api(tags = "用户管理相关接口")
@RequestMapping("/user")
public class UserController {

    @PostMapping("/")
    @ApiOperation("添加用户的接口")
    @ApiImplicitParams({
            @ApiImplicitParam(name = "username", value = "用户名", defaultValue = "李四"),
            @ApiImplicitParam(name = "address", value = "用户地址", defaultValue = "深圳", required = true)
    }
    )
    public RespBean addUser(String username, @RequestParam(required = true) String address) {
        return new RespBean();
    }

    @GetMapping("/")
    @ApiOperation("根据id查询用户的接口")
    @ApiImplicitParam(name = "id", value = "用户id", defaultValue = "99", required = true)
    public User getUserById(@PathVariable Integer id) {
        User user = new User();
        user.setId(id);
        return user;
    }
    @PutMapping("/{id}")
    @ApiOperation("根据id更新用户的接口")
    public User updateUserById(@RequestBody User user) {
        return user;
    }
}
~~~



~~~java
@ApiModel
public class User {
    @ApiModelProperty(value = "用户id")
    private Integer id;
    @ApiModelProperty(value = "用户名")
    private String username;
    @ApiModelProperty(value = "用户地址")
    private String address;
    //getter/setter
}
~~~



1. @Api注解可以用来标记当前Controller的功能。
2. @ApiOperation注解用来标记一个方法的作用。
3. @ApiImplicitParam注解用来描述一个参数，可以配置参数的中文含义，也可以给参数设置默认值，这样在接口测试的时候可以避免手动输入。
4. 如果有多个参数，则需要使用多个@ApiImplicitParam注解来描述，多个@ApiImplicitParam注解需要放在一个@ApiImplicitParams注解中。
5. 需要注意的是，@ApiImplicitParam注解中虽然可以指定参数是必填的，但是却不能代替@RequestParam(required = true)，前者的必填只是在Swagger2框架内必填，抛弃了Swagger2，这个限制就没用了，所以假如开发者需要指定一个参数必填，@RequestParam(required = true)注解还是不能省略。
6. 如果参数是一个对象（例如上文的更新接口），对于参数的描述也可以放在实体类中。



如果项目中有加入security权限控制 记得在权限配置中开发访问权限

~~~java
@Override
public void configure(WebSecurity web) throws Exception {
    web.ignoring()
            .antMatchers("/swagger-ui.html")
            .antMatchers("/v2/**")
            .antMatchers("/swagger-resources/**");
}
~~~



### 5.20 Taskcontroll

### 5.21 Docker

#### 5.21.1 docker 简介

 Docker是基于Go语言实现的云开源项目

*Docker的主要目标是“Build,Ship and Run Any App,Anywhere”，也就是通过对应用组件的封装、分发、部署、运行等生命周期的管理，使用户的App（可以使一个WEB应用或数据库应用等等）及其运行环境能够做到“一次封装，到处运行”



##### 一. Docker的三大核心概念：镜像、容器、仓库。

镜像：类似虚拟机的镜像、用俗话说就是安装文件。

容器：类似一个轻量级的沙箱，容器是从镜像创建应用运行实例，

可以将其启动、开始、停止、删除、而这些容器都是相互隔离、互不可见的。

仓库：类似代码仓库，是Docker集中存放镜像文件的场所。

![img](https://img-blog.csdn.net/20180921092727583?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2RlYnVnYnVnYmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

#### 5.21.2 docker 安装

#####  5.21.2.1 Linux下

// 安装lsb  -bash: lsb_release: 未找到命令

~~~
https://blog.csdn.net/xufengzhu/article/details/73330741
~~~



此处在Centos7进行安装，可以使用以下命令查看CentOS版本

```
lsb_release -a
```

![img](https://img2018.cnblogs.com/blog/761230/201909/761230-20190920092034990-377974794.png)

在 CentOS 7安装docker要求系统为64位、系统内核版本为 3.10 以上，可以使用以下命令查看

~~~
uname -r
~~~

![img](https://img2018.cnblogs.com/blog/761230/201909/761230-20190920092306272-1825494524.png)

用Yum源安装

**查看是否已安装docker列表**

```
yum list installed | grep docker
```

![img](https://img2018.cnblogs.com/blog/761230/201909/761230-20190924101015120-484595522.png)

 **安装docker**

```
yum -y install docker
```

-y表示不询问安装，直到安装成功，安装完后再次查看安装列表

![img](https://img2018.cnblogs.com/blog/761230/201909/761230-20190924101635249-774913670.png)

**启动docker**

```
systemctl start docker
```

CentOS7下载docker后启动会出现的错误：Job for docker.service failed because the control process exited with error code. See "systemctl status docker.service" and "journalctl -xe" for details
说明docker就没有启动成功

 

解决方法：

vim /etc/sysconfig/docker-storage

添加配置文件中：

```
DOCKER_STORAGE_OPTIONS="--selinux-enabled --log-driver=journald --signature-verification=false"

vim /etc/docker/daemon.json

写入指定参数：
{ "storage-driver": "devicemapper" }
重启docker服务
```

systemctl restart docker

没有出现错误信息，说明问题已经解决

**查看docker服务状态**

```
systemctl status docker
```

![img](https://img2018.cnblogs.com/blog/761230/201909/761230-20190924101735498-1013963263.png)

以上说明docker安装成功



离线安装模式

 **安装包官方地址**：https://download.docker.com/linux/static/stable/x86_64/

可以先下载到本地，然后通过ftp工具上传到服务器上，或者在服务器上使用命令下载

```
wget https://download.docker.com/linux/static/stable/x86_64/docker-18.06.3-ce.tgz
```

**解压**

```
tar -zxvf docker-18.06.3-ce.tgz
```

 **将解压出来的docker文件复制到 /usr/bin/ 目录下**

```
cp docker/* /usr/bin/
```

**在/etc/systemd/system/目录下新增docker.service文件**，内容如下，这样可以将docker注册为service服务

~~~xml
[Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
After=network-online.target firewalld.service
Wants=network-online.target
  
[Service]
Type=notify
# the default is not to use systemd for cgroups because the delegate issues still
# exists and systemd currently does not support the cgroup feature set required
# for containers run by docker
ExecStart=/usr/bin/dockerd --selinux-enabled=false <font color='red'>--insecure-registry=127.0.0.1</font></font>
ExecReload=/bin/kill -s HUP $MAINPID
# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinitys
# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
#TasksMax=infinity
TimeoutStartSec=0
# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes
# kill only the docker process, not all processes in the cgroup
KillMode=process
# restart the docker process if it exits prematurely
Restart=on-failure
StartLimitBurst=3
StartLimitInterval=60s
  
[Install]
WantedBy=multi-user.target
~~~

此处的--insecure-registry=127.0.0.1（此处改成你私服ip）设置是针对有搭建了自己私服Harbor时允许docker进行不安全的访问，否则访问将会被拒绝。

**启动docker**

给docker.service文件添加执行权限

```
chmod +x /etc/systemd/system/docker.service 
```

重新加载配置文件（每次有修改docker.service文件时都要重新加载下）

```
systemctl daemon-reload                
```

启动

```
systemctl start docker
```

设置开机启动

```
systemctl enable docker.service
```

查看docker服务状态

```
systemctl status docker
```

![img](https://img2018.cnblogs.com/blog/761230/201909/761230-20190924100503875-876834976.png)

上图表示docker已安装成功

#### 5.21.3 docker 核心

~~~
docker排坑

问题 ： Error response from daemon: manifest for *:latest not found

我们可以登录docker hub：https://hub.docker.com/u/library，搜索自己想要下载的镜像名:
~~~

##### 5.21.3.1 Docker 安装mysql 

###### 1.docker使用非root权限运行docker

```
sudo usermod -aG docker your-user
```

###### 2.第一步，拉取MySQL镜像

```
docker pull mysql:5.5
```

查看镜像

```
docker images
```

###### 3.创建并启动一个MySQL容器

```
docker run --name yi-mysql -e MYSQL_ROOT_PASSWORD=123456 -p 3306:3306 -d mysql:5.5
```

- –name：给新创建的容器命名，此处命名为`pwc-mysql`
- -e：配置信息，此处配置`mysql`的`root用户`的登陆密码
- -p：端口映射，此处映射`主机3306端口`到`容器pwc-mysql的3306端口`
- -d：成功启动容器后输出容器的完整ID，例如上图 `73f8811f669ee...`

###### **查看容器运行状态：**

```
docker ps
```

###### 4.测试MySQL

可以用navicat或者其他工具连接测试

###### 5.创建多个mysql服务

```
 docker run --name dbdb -e MYSQL_ROOT_PASSWORD=123456 -p 4306:3306 -d mysql:5.5
```

###### 6.查看所有容器

```
docker ps -a
```

###### 7.启动和关闭容器

启动：

```
docker start yi-mysql   //通过指定容器名字
docker start 847r758488f  //通过指定容器ID
```

关闭：

```
docker stop yi-mysql   //通过指定容器名字
docker stop 847r758488f //通过指定容器ID
```

###### 8.进行容器的命令行模式

docker exec -it 055201b67e06 bash

即可进行MySQL各种命令

```
mysql -uroot -p -h localhost
```

退出容器 Ctrl+D或者exit



##### 5.21.3.2 Docker 安装tomcat

###### 搜索tomcat

```
docker search tomcat

```

###### 下载tomcat

```
docker pull tomcat:8.5

```

其中8.5是tomcat的版本

###### 查看下载的tomcat

```
docker images

```

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190621130313299.png)

###### 启动容器

```
docker run --name tomcat8001 -p 8001:8080 -v /soft/tomcat/8001/conf:/usr/local/tomcat/conf -v /soft/tomcat/8001/logs:/usr/local/tomcat/logs -v /soft/tomcat/8001/webapps:/usr/local/tomcat/webapps -d tomcat:8.5

```

–name 为启动的tomcat容器重新起一个名字
-p 8001:8080 将宿主机的8001端口映射到容器的8080端口
-v /soft/tomcat/8001/conf:/usr/local/tomcat/conf 将容器的目录映射到宿主机的目录中
-d 表示后台启动容器
查看是否启动成功

```
docker ps

```

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190621130547714.png)
如果看到tomcat的启动信息，说明启动成功，否则，启动失败。

###### 停止容器

```
docker stop tomcat8001   /   docker stop "CONTAINER ID"

```

###### 重新启动容器

```
docker start tomcat8001  // docker start "CONTAINER ID"

```

###### 启动失败的解决方法

1.启动失败查看所有被启动过的容器，包括关闭的容器

```
docker ps -a

```

如果出现如下图所示：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190621131016498.png)
解决方法为：
首先先启动一容器：

```
docker run --name tomcat -p 8001:8080 -d tomcat:8.5

```

之后拷贝tomcat容器的conf、logs、webapps目录到宿主机

```
docker cp tomcat:/usr/local/tomcat/conf /soft/tomcat/8001
docker cp tomcat:/usr/local/tomcat/logs /soft/tomcat/8001
docker cp tomcat:/usr/local/tomcat/webapps /soft/tomcat/8001

```

然后停止刚开启的tomcat容器，并删除

```
docker rm tomcat

```

最后重新启动一个tomcat容器

```
docker run --name tomcat8001 -p 8001:8080 -v /soft/tomcat/8001/conf:/usr/local/tomcat/conf -v /soft/tomcat/8
```



##### 5.21.3.3 Docker 安装nginx

~~~
##########################################
#运行容器

#安装Nginx

#搜索、下载镜像
docker search nginx
docker pull nginx
docker images nginx


#运行容器mynginx
docker run -p 80:80 --name mynginx -d nginx

#查看端口
netstat -antp|grep 80
#访问测试
curl 127.0.0.1
#外部浏览器访问ip正常，部署成功

#进入Nginx容器
docker exec -it mynginx /bin/sh
#退出容器 exit
Ctrl+d #快捷键

#列出容器
docker ps -a
#删除容器
docker rm mynginx

##########################################


运行Nginx部署网站
##########################################

#接下来思考问题：
#Nginx配置、查看日志、部署网站
#需要把外部的目录或文件映射到docker容器

#创建目录
Ngdir=/www/docker/nginx
mkdir -p $Ngdir/{www,log,conf/conf.d}

#创建配置(采用默认配置去注释)
echo '#man config
user nginx;
worker_processes 1;
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;
events {
worker_connections 1024;
}
http {
include /etc/nginx/mime.types;
default_type application/octet-stream;
log_format main '$remote_addr - $remote_user [$time_local] "$request" '
'$status $body_bytes_sent "$http_referer" '
'"$http_user_agent" "$http_x_forwarded_for"';
access_log /var/log/nginx/access.log main;
sendfile on;
keepalive_timeout 65;
include /etc/nginx/conf.d/*.conf;
}
'>$Ngdir/conf/nginx.conf
#
echo '#nginx
server {
listen 80;
server_name localhost;
location / {
root /usr/share/nginx/html;
index index.html index.htm;
}
error_page 500 502 503 504 404 /50x.html;
location = /50x.html {
root /usr/share/nginx/html;
}
}
'>$Ngdir/conf/conf.d/default.conf
#html
echo 'Welcome to nginx!'>$Ngdir/www/index.html
echo 'error_page 500 502 503 504 404'>$Ngdir/www/50x.html

#使用nginx镜像，创建容器mynginx
docker run -p 80:80 --name mynginx \
-v $Ngdir/conf/nginx.conf:/etc/nginx/nginx.conf:ro \
-v $Ngdir/conf/conf.d:/etc/nginx/conf.d:ro \
-v $Ngdir/www:/usr/share/nginx/html:rw \
-v $Ngdir/log:/var/log/nginx:rw \
-d nginx

#测试html内容
curl 127.0.0.1
curl 127.0.0.1/123
#查看error.log
cat $Ngdir/log/error.log

#测试成功 ^_^

# 参数说明：
# -p 80:80：本地80端口:映射docker容器80端口
# -v $Ngdir/log:/var/log/nginx 主机log目录挂载到容器log/nginx
~~~



##### 5.21.3.4 Docker 安装 Sql Server

　　然后根据这个上docker拉取镜像

```
 docker pull mcr.microsoft.com/mssql/server:2017-latest
```

　　查看镜像并允许此镜像

```
docker images
sudo docker run -e "ACCEPT_EULA=Y" -e "SA_PASSWORD=MyPassWord123"  -p 1433:1433 --name sql1  -d mcr.microsoft.com/mssql/server:2017-latest
```

 

　　然后查看是否允许成功

```
Docker ps -a
```

 

　　出现下图这样既允许成功，显示UP(如果失败的话通过docker logs 容器名进行查看错误日志)

 ![img](https://img2018.cnblogs.com/blog/1470432/201907/1470432-20190730175207460-1936354168.png)

 https://www.cnblogs.com/Fengyinyong/p/13916376.html

　　然后这里我们就配置了SQL Server，接下来我们实际进入容器内操作。

```
sudo docker exec -it sql1 "bash"

/opt/mssql-tools/bin/sqlcmd -S localhost -U SA -P "MyPassWord123"
```

　　然后现在就可以进行日常的数据库操作了，输入命令后执行Go结束

 ![img](https://img2018.cnblogs.com/blog/1470432/201907/1470432-20190730175223314-731769061.png)

 

　　　　创建库

```
CREATE DATABASE TestDB
```

 

　　　　使用库、创建表

```
USE TestDB

CREATE TABLE Inventory (id INT, LastName NVARCHAR(50), FirstName NVARCHAR(50))
```

 

　　　　查询表

```
Select * from  Inventory
```

 

　　　　查询用户创建的表

```
select name from sysobjects where type = 'U'
```

 

 ~~~
###### 　　**系统表sysobjects保存的都是数据库对象,其中type表示各种对象的类型，具体包括:**

###### 　　**U = 用户表**

###### 　　**S = 系统表**

###### 　　**C = CHECK 约束**

###### 　　**D = 默认值或 DEFAULT 约束**

###### 　　**F = FOREIGN KEY 约束**

###### 　　**L = 日志**

###### 　　**FN = 标量函数**

###### 　　**IF = 内嵌表函数**

###### 　　**P = 存储过程**

###### 　　**PK = PRIMARY KEY 约束（类型是 K）**

###### 　　**RF = 复制筛选存储过程**

###### 　　**TF = 表函数**

###### 　　**TR = 触发器**

###### 　　**UQ = UNIQUE 约束（类型是 K）**

###### 　　**V = 视图**

###### 　　**X = 扩展存储过程及相关的对象信息。**
 ~~~



###### **其他配置**

　　一、更改sa的登录密码

```
sudo docker exec -it sql1 /opt/mssql-tools/bin/sqlcmd  -S localhost -U SA -P "MyPassWord123"  -Q 'ALTER LOGIN SA WITH PASSWORD="MyPassWord456"'
```

 

　　二、保留数据

- - 将主机目录装载为数据卷

```
docker run -e 'ACCEPT_EULA=Y' -e 'MSSQL_SA_PASSWORD=MyPassWord456' -p 1433:1433 -v  /var/opt/mssql -d mcr.microsoft.com/mssql/server:2017-latest
```

 

- -  使用数据卷容器

```
docker run -e 'ACCEPT_EULA=Y' -e 'MSSQL_SA_PASSWORD=MyPassWord456' -p 1433:1433 -v sqlvolume:/var/opt/mssql -d mcr.microsoft.com/mssql/server:2017-latest
```

 

　　三、删除或退出容器

 　　　删除容器：docker rm 容器名

　　　 删除镜像：docker rmi 镜像名

　　　 退出容器;Ctrl+D



##### 5.21.3.5 Docker 安装jenkins

###### **查看docker的jenkins镜像版本**

```
#查看jenkins版本命令
docker search jenkins
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

```
[root@localhost docker]# docker search jenkins
NAME                                   DESCRIPTION                                     STARS               OFFICIAL            AUTOMATED
jenkins                                Official Jenkins Docker image                   4153                [OK]                
jenkins/jenkins                        The leading open source automation server       1326                                    
jenkinsci/jenkins                      Jenkins Continuous Integration and Delivery …   355                                     
jenkinsci/blueocean                    https://jenkins.io/projects/blueocean           339                                     
jenkinsci/jnlp-slave                   A Jenkins slave using JNLP to establish conn…   101                                     [OK]
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

 

[回到顶部](https://www.cnblogs.com/nhdlb/p/12576273.html#_labelTop)

###### **远程拉取镜像**

```
#拉取镜像命令(不标注表示最新的)
docker pull jenkins
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

```
[root@localhost docker]# docker pull jenkins
Using default tag: latest
latest: Pulling from library/jenkins
55cbf04beb70: Pull complete 
1607093a898c: Pull complete 
9a8ea045c926: Pull complete 
d4eee24d4dac: Pull complete 
c58988e753d7: Pull complete 
794a04897db9: Pull complete 
70fcfa476f73: Pull complete
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

 

[回到顶部](https://www.cnblogs.com/nhdlb/p/12576273.html#_labelTop)

###### **创建挂载目录**

**挂载目录用于映射jenkins的jenkins_home下的配置文件等信息。**

```
#本文的挂载目录是home下
mkdir /home/jenkins
```

**重点：此目录需要设置权限，否则启动容器报错权限错误**

```
#修改权限（1000:1000 是UID和GID）
chown -R 1000:1000 /home/jenkins/
```

 

[回到顶部](https://www.cnblogs.com/nhdlb/p/12576273.html#_labelTop)

###### **启动容器**

```
#运用镜像启动容器命令
docker run -d -p 8000:8080 -p 50000:50000 -v /home/jenkins:/var/jenkins_home --name jenkins --restart always --privileged=true  -u root jenkins
```

**-p : 映射端口，宿主机端口：容器端口**

**-v : 挂载，宿主机目录：容器目录**

**--name : 自定义容器名**

**-u : 权限用户名**

**--privileged : 使用该参数，container内的root拥有真正的root权限，否则，container（容器）内的root只是外部的一个普通用户权限，privileged启动的容器可以看到很多host上的设备，并且可以执行mount，甚至允许你在docker容器内启动docker容器。**

**未设置privileged参数**

**![img](https://img2020.cnblogs.com/blog/1582099/202003/1582099-20200326180014286-902354315.png)**

###### **设置privileged参数**

**![img](https://img2020.cnblogs.com/blog/1582099/202003/1582099-20200326180114524-2140536814.png)**

 **-p 50000:50000 : 如果您在其他机器上设置了一个或多个基于JNLP的Jenkins代理程序，而这些代理程序又与 jenkinsci/blueocean 容器交互（充当“主”Jenkins服务器，或者简称为“Jenkins主”）， 则这是必需的。默认情况下，基于JNLP的Jenkins代理通过TCP端口50000与Jenkins主站进行通信。**

 

[回到顶部](https://www.cnblogs.com/nhdlb/p/12576273.html#_labelTop)

###### **修改default.json、hudson.model.UpdateCenter.xml配置文件**

**启动容器后，进入刚才设置的挂载目录 /home/jenkins 内，可以看到已经有映射的配置文件了。**

**![img](https://img2020.cnblogs.com/blog/1582099/202003/1582099-20200326180722031-1849480941.png)**

**首先修改****hudson.model.UpdateCenter.xml配置文件**

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

```
默认路径

http://updates.jenkins-ci.org/update-center.json

改成路径

http://mirror.xmission.com/jenkins/updates/update-center.json
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

**完成后修改 /updates/default.json 配置文件**

```
默认路径
"connectionCheckUrl":"http://www.google.com/" 
改为路径
"connectionCheckUrl":"http://www.baidu.com/"
```

 

[回到顶部](https://www.cnblogs.com/nhdlb/p/12576273.html#_labelTop)

###### **重启jenkins容器**

```
#重启jenkins容器
docker restart jenkins
```

 

[回到顶部](https://www.cnblogs.com/nhdlb/p/12576273.html#_labelTop)

###### **测试**

**![img](https://img2020.cnblogs.com/blog/1582099/202003/1582099-20200326181347255-700999645.png)**

**成功！**



##### [docker上部署nginx容器80端口自动转443端口]

拉去nginx镜像

\# docker pull nginx

运行nginx容器config用于拷贝nginx配置文件

\# docker run --name nginxconfig -d docker.io/nginx

\# docker cp nginxconfig:/etc/nginx/ /root/

删除

\# docker stop nginxconfig

\# docker rm nginxconfig

创建服务nginx容器

\# docker run --name nginx -p 80:80 -p 443:443 -v /root/nginx/:/etc/nginx/ -d docker.io/nginx

- 映射端口443，用于https请求
- 映射端口80，用于http请求

nginx配置文件如下（不做任何修改）

~~~xml
[root@iZm5eclei4hhnwn6mo9va6Z ~]# ls
mysql  nginx   redis
[root@iZm5eclei4hhnwn6mo9va6Z ~]#
[root@iZm5eclei4hhnwn6mo9va6Z ~]# cd nginx
[root@iZm5eclei4hhnwn6mo9va6Z nginx]#
[root@iZm5eclei4hhnwn6mo9va6Z nginx]# ls
certs  conf.d  fastcgi_params  koi-utf  koi-win  mime.types  modules  nginx.conf  scgi_params  uwsgi_params  win-utf
[root@iZm5eclei4hhnwn6mo9va6Z nginx]#
[root@iZm5eclei4hhnwn6mo9va6Z nginx]# cat nginx.conf
user  nginx;                                #运行nginx的用户
worker_processes  1;                        #启动进程设置成和CPU数量相等

error_log  /var/log/nginx/error.log warn;   #全局错误日志
pid        /var/run/nginx.pid;              #PID文件的位置

#工作模式及连接数上限
events {
    worker_connections  1024;               #单个后台work进程最大并发数设置为1024
}
http {
    include       /etc/nginx/mime.types;    #设定mime类型
    default_type  application/octet-stream;

    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '       #设定日志格式
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';

    access_log  /var/log/nginx/access.log  main;

    sendfile        on;
    #tcp_nopush     on;

    keepalive_timeout  65;                 #设置连接超时的事件

    #gzip  on;                             #开启GZIP压缩

    include /etc/nginx/conf.d/*.conf;
}
[root@iZm5eclei4hhnwn6mo9va6Z nginx]#
~~~

拷贝申请的阿里云ssl证书

~~~
[root@iZm5eclei4hhnwn6mo9va6Z nginx]# cd certs/
[root@iZm5eclei4hhnwn6mo9va6Z certs]#
[root@iZm5eclei4hhnwn6mo9va6Z certs]# ls
2032088_cnbi.jiaxin365.cn.key  2032088_cnbi.jiaxin365.cn.pem
[root@iZm5eclei4hhnwn6mo9va6Z certs]#
[root@iZm5eclei4hhnwn6mo9va6Z certs]# pwd
/root/nginx/certs
~~~

配置http自动跳往https

~~~
[root@iZm5eclei4hhnwn6mo9va6Z nginx]# cd conf.d/
[root@iZm5eclei4hhnwn6mo9va6Z conf.d]#
[root@iZm5eclei4hhnwn6mo9va6Z conf.d]# pwd
/root/nginx/conf.d
[root@iZm5eclei4hhnwn6mo9va6Z conf.d]#
[root@iZm5eclei4hhnwn6mo9va6Z conf.d]# ls
default.conf
[root@iZm5eclei4hhnwn6mo9va6Z conf.d]#
[root@iZm5eclei4hhnwn6mo9va6Z conf.d]# cat default.conf
server {
        server_name  cnbi.jiaxin365.cn;    #域名
        listen 80;                         #侦听80端口
        rewrite ^(.*) https://$server_name$1 permanent;       #${server_name}可以换成$host
    }                                                         #设置http自动跳转https


server {
    listen    443 ssl;                     #侦听443端口
    server_name  cnbi.jiaxin365.cn;        #域名

    #charset koi8-r;
    #access_log  /var/log/nginx/host.access.log  main;    # 增加ssl
    ssl on;                                #如果强制HTTPs访问，这行要打开
    ssl_certificate /etc/nginx/certs/2032088_cnbi.jiaxin365.cn.pem;
    ssl_certificate_key /etc/nginx/certs/2032088_cnbi.jiaxin365.cn.key;
    ssl_session_cache    shared:SSL:1m;
    ssl_session_timeout 5m;
    ssl_protocols  SSLv2 SSLv3 TLSv1.2;    # 指定密码为openssl支持的格式
    ssl_ciphers  HIGH:!aNULL:!MD5;         # 密码加密方式
    ssl_prefer_server_ciphers  on;         # 依赖SSLv3和TLSv1协议的服务器密码将优先于客户端密码
    location / {                           # 定义首页索引目录和名称
        root   /usr/share/nginx/html;
        index  index.html index.htm;
    }

    #error_page  404              /404.html;

    # redirect server error pages to the static page /50x.html
    #
    error_page   500 502 503 504  /50x.html;
    location = /50x.html {                #重定向错误页面到 /50x.html
        root   /usr/share/nginx/html;
    }

    # proxy the PHP scripts to Apache listening on 127.0.0.1:80
    #
    #location ~ \.php$ {
    #    proxy_pass   http://127.0.0.1;
    #}

    # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000
    #
    #location ~ \.php$ {
    #    root           html;
    #    fastcgi_pass   127.0.0.1:9000;
    #    fastcgi_index  index.php;
    #    fastcgi_param  SCRIPT_FILENAME  /scripts$fastcgi_script_name;
    #    include        fastcgi_params;
    #}

    # deny access to .htaccess files, if Apache's document root
    # concurs with nginx's one
    #
    #location ~ /\.ht {
    #    deny  all;
    #}
}
~~~

 重启容器

\# docker restart nginx

查看容器是否启动成功 

\# docker ps -a

打开浏览器测试



##### 5.21.3.6 Docker 安装 showDoc

部署ShowDoc


一.什么是ShowDoc？


每当接手一个他人开发好的模块或者项目，看着那些没有写注释的代码，我们都无比抓狂。文档呢？！文档呢？！ShowDoc就是一个非常适合IT团队的在线文档分享工具，它可以加快团队之间沟通的效率。

 

二.ShowDoc基本配置。（附上[[官网详细安装]][1]）


确保系统已经安装docker

 

1.安装镜像。(建议使用国内镜像)


#国内镜像安装命令

docker pull registry.docker-cn.com/star7th/showdoc

#国外官方镜像安装命令

docker pull star7th/showdoc


2.新建存放showdoc数据的目录

#新建两个目录

mkdir /showdoc_data

mkdir /showdoc_data/html


3.给showdoc_data目录权限


chmod 777 -R /showdoc_data


 4.启动showdoc容器。


docker run -d --name showdoc -p 4999:80 -v /showdoc_data/html:/var/www/html/ registry.docker-cn.com/star7th/showdoc


 5.转移数据。


#这一部留意命令行界面有没有权限禁止的错误提示。

#如果有则检查权限，或者安全限制（比如说可能selinux会禁止docker进程写文件。

docker exec showdoc \cp -fr /showdoc_data/html/ /var/www/


6.根据以上命令操作的话，以后showdoc的数据都会存放在 /showdoc_data/html 目录下。

 7.接下来，你可以打开 http://ip:4999/来访问showdoc。默认账户密码是showdoc/123456。



**二、下载 showdoc**

showdoc 的 GitHub 项目地址为：https://github.com/star7th/showdoc，下载地址为 https://github.com/star7th/showdoc.git 或者 git://github.com/star7th/showdoc.git

```
[root@masternode opt]# mkdir git_repository
[root@masternode opt]# chmod 777 git_repository
[root@masternode opt]# cd git_repository
[root@masternode git_repository]# git clone git://github.com/star7th/showdoc.git

```

git 默认是在当前目录下下载项目代码。

**三、创建镜像**

下载后，生成 showdoc 目录，进入目录，可以看到 Dockerfile 文件，使用 docker build -t showdoc ./ 命令根据 Dockerfile 来创建镜像，-t，--tag，镜像的名字及标签，通常 name:tag 或者 name 格式；可以在一次构建中为一个镜像设置多个标签。./ 表示当前 Dockerfile 所在目录。

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

```
[root@masternode git_repository]# cd showdoc
[root@masternode showdoc]# ls -ltr
total 36
-rw-r--r--  1 root root 1743 Jul  6 21:00 LICENSE.txt
-rw-r--r--  1 root root  257 Jul  6 21:00 Dockerfile
-rw-r--r--  1 root root 4221 Jul  6 21:00 README.md
drwxr-xr-x 14 root root  214 Jul  6 21:00 Public
drwxr-xr-x  2 root root   28 Jul  6 21:00 Sqlite
-rw-r--r--  1 root root  564 Jul  6 21:00 composer.json
-rw-r--r--  1 root root   30 Jul  6 21:00 robots.txt
drwxr-xr-x  2 root root  142 Jul  6 21:00 install
-rw-r--r--  1 root root 1023 Jul  6 21:00 index.php
-rw-r--r--  1 root root 4286 Jul  6 21:00 favicon.ico
drwxr-xr-x  4 root root   29 Jul  6 21:00 documentation
drwxr-xr-x  3 root root   38 Jul  6 21:00 web
drwxr-xr-x  4 root root   75 Jul  6 21:00 server
drwxr-xr-x  7 root root  250 Jul  6 21:00 web_src
[root@masternode showdoc]# pwd
/opt/git_repository/showdoc
[root@masternode showdoc]# docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
nginx               latest              f68d6e55e065        4 days ago          109MB
hello-world         latest              fce289e99eb9        6 months ago        1.84kB
[root@masternode showdoc]# docker build -t showdoc ./
......
[root@masternode showdoc]# docker images
REPOSITORY                TAG                 IMAGE ID            CREATED             SIZE
showdoc                   latest              40d2089cc644        15 seconds ago      384MB
nginx                     latest              f68d6e55e065        4 days ago          109MB
hello-world               latest              fce289e99eb9        6 months ago        1.84kB
richarvey/nginx-php-fpm   1.5.4               0b8e5203860f        12 months ago       300MB
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

此处 docker build 时间比较长，镜像创建好之后，使用 docker images 可以看到。

**四、新建并启动容器**

此处会涉及到端口映射的概念。

```
[root@masternode showdoc]# docker run -d --name showdoc -p 4999:80 showdoc
11f2354ab1cb48a264555660e8f363654f7bd23745f165fe03a379f94fabfe77
[root@masternode showdoc]# docker ps
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                                                                              NAMES
11f2354ab1cb        showdoc             "docker-php-entrypoi…"   9 seconds ago       Up 8 seconds        443/tcp, 9000/tcp, 0.0.0.0:4999->80                                         /tcp   showdoc
```

此处使用 -d 选项表示后台运行，--name 指定容器名称，-p 进行端口映射，宿主机端口:容器端口，将允许映射容器内应用的服务端口到本地宿主机端口，此处将本地宿主机的 4999 映射到了容器的 80 端口。之后访问宿主机的 4999 端口即可访问容器内 Web 应用提供的界面。



##### 5.21.3.7 Docker 安装 MongoDb

此外，我们还可以用 **docker search mongo** 命令来查看可用版本：

```
$ docker search mongo
NAME                              DESCRIPTION                      STARS     OFFICIAL   AUTOMATED
mongo                             MongoDB document databases ...   1989      [OK]       
mongo-express                     Web-based MongoDB admin int...   22        [OK]       
mvertes/alpine-mongo              light MongoDB container          19                   [OK]
mongooseim/mongooseim-docker      MongooseIM server the lates...   9                    [OK]
torusware/speedus-mongo           Always updated official Mon...   9                    [OK]
jacksoncage/mongo                 Instant MongoDB sharded cluster  6                    [OK]
mongoclient/mongoclient           Official docker image for M...   4                    [OK]
jadsonlourenco/mongo-rocks        Percona Mongodb with Rocksd...   4                    [OK]
asteris/apache-php-mongo          Apache2.4 + PHP + Mongo + m...   2                    [OK]
19hz/mongo-container              Mongodb replicaset for coreos    1                    [OK]
nitra/mongo                       Mongo3 centos7                   1                    [OK]
ackee/mongo                       MongoDB with fixed Bluemix p...  1                    [OK]
kobotoolbox/mongo                 https://github.com/kobotoolb...  1                    [OK]
valtlfelipe/mongo                 Docker Image based on the la...  1                    [OK]
```

###### 2、取最新版的 MongoDB 镜像

这里我们拉取官方的最新版本的镜像：

```
$ docker pull mongo:latest
```

[![img](https://www.runoob.com/wp-content/uploads/2016/06/docker-mongo3.png)](https://www.runoob.com/wp-content/uploads/2016/06/docker-mongo3.png)

###### 3、查看本地镜像

使用以下命令来查看是否已安装了 mongo：

```
$ docker images
```

[![img](https://www.runoob.com/wp-content/uploads/2016/06/docker-mongo4.png)](https://www.runoob.com/wp-content/uploads/2016/06/docker-mongo4.png)

在上图中可以看到我们已经安装了最新版本（latest）的 mongo 镜像。

###### 4、运行容器

安装完成后，我们可以使用以下命令来运行 mongo 容器：

```
$ docker run -itd --name mongo -p 27017:27017 mongo --auth
```

参数说明：

- **-p 27017:27017** ：映射容器服务的 27017 端口到宿主机的 27017 端口。外部可以直接通过 宿主机 ip:27017 访问到 mongo 的服务。
- **--auth**：需要密码才能访问容器服务。

[![img](https://www.runoob.com/wp-content/uploads/2016/06/docker-mongo5.png)](https://www.runoob.com/wp-content/uploads/2016/06/docker-mongo5.png)

###### 5、安装成功

最后我们可以通过 **docker ps** 命令查看容器的运行信息：

[![img](https://www.runoob.com/wp-content/uploads/2016/06/docker-mongo6.png)](https://www.runoob.com/wp-content/uploads/2016/06/docker-mongo6.png)

接着使用以下命令添加用户和设置密码，并且尝试连接。

```
$ docker exec -it mongo mongo admin
# 创建一个名为 admin，密码为 123456 的用户。
>  db.createUser({ user:'admin',pwd:'123456',roles:[ { role:'userAdminAnyDatabase', db: 'admin'},"readWriteAnyDatabase"]});
# 尝试使用上面创建的用户信息进行连接。
> db.auth('admin', '123456')


mongodb role类型
数据库用户角色（Database User Roles）：

read：授予User只读数据的权限
readWrite：授予User读写数据的权限
数据库管理角色（Database Administration Roles）：

dbAdmin：在当前dB中执行管理操作
dbOwner：在当前DB中执行任意操作
userAdmin：在当前DB中管理User
备份和还原角色（Backup and Restoration Roles）：

backup
restore
跨库角色（All-Database Roles）：

readAnyDatabase：授予在所有数据库上读取数据的权限
readWriteAnyDatabase：授予在所有数据库上读写数据的权限
userAdminAnyDatabase：授予在所有数据库上管理User的权限
dbAdminAnyDatabase：授予管理所有数据库的权限
集群管理角色（Cluster Administration Roles）：

clusterAdmin：授予管理集群的最高权限
clusterManager：授予管理和监控集群的权限，A user with this role can access the config and local databases, which are used in sharding and replication, respectively.
clusterMonitor：授予监控集群的权限，对监控工具具有readonly的权限
hostManager：管理Server
```

[![img](https://www.runoob.com/wp-content/uploads/2016/06/docker-mongo7.png)](https://www.runoob.com/wp-content/uploads/2016/06/docker-mongo7.png)



##### 5.21.3.8 Docker 安装 个人博客

二、部署wordpress

~~~shell
docker pull wordpress  --拉取镜像
docker images --查看镜像
我这里80端口被使用了，只能映射别的端口
docker run --name blog -p 8081:80 -itd 镜像id
docker ps --查看镜像
~~~




在浏览器输入ip:8081  出现如下界面



选择相应语音，在数据库中创建相应数据库，输入相应数据直至安装完成



安装成功后再次输入ip：8081




博客就这样搭建好啦，是不是很简单呢！

注：博客后台ip:8081/wp-admin/

##### 5.21.3.9 Docker 安装 nocos

###### 方式一

```
仅部署nacos-server,不使用prometheus/grafana等监控组件
```

###### 1.拉取镜像



```undefined
docker pull nacos/nacos-server
```

###### 2.挂载目录



```bash
mkdir -p /home/nacos/logs/                      #新建logs目录
mkdir -p /home/nacos/init.d/          
vim /home/nacos/init.d/custom.properties        #修改配置文件
添加如下参数:
```



```cpp
server.contextPath=/nacos
server.servlet.contextPath=/nacos
server.port=8848

spring.datasource.platform=mysql

db.num=1
db.url.0=jdbc:mysql://xx.xx.xx.x:3306/nacos_devtest_prod?characterEncoding=utf8&connectTimeout=1000&socketTimeout=3000&autoReconnect=true
db.user=user
db.password=pass


nacos.cmdb.dumpTaskInterval=3600
nacos.cmdb.eventTaskInterval=10
nacos.cmdb.labelTaskInterval=300
nacos.cmdb.loadDataAtStart=false

management.metrics.export.elastic.enabled=false

management.metrics.export.influx.enabled=false


server.tomcat.accesslog.enabled=true
server.tomcat.accesslog.pattern=%h %l %u %t "%r" %s %b %D %{User-Agent}i


nacos.security.ignore.urls=/,/**/*.css,/**/*.js,/**/*.html,/**/*.map,/**/*.svg,/**/*.png,/**/*.ico,/console-fe/public/**,/v1/auth/login,/v1/console/health/**,/v1/cs/**,/v1/ns/**,/v1/cmdb/**,/actuator/**,/v1/console/server/**
nacos.naming.distro.taskDispatchThreadCount=1
nacos.naming.distro.taskDispatchPeriod=200
nacos.naming.distro.batchSyncKeyCount=1000
nacos.naming.distro.initDataRatio=0.9
nacos.naming.distro.syncRetryDelay=5000
nacos.naming.data.warmup=true
nacos.naming.expireInstance=true
:wq 保存退出
```

###### 3.启动容器



```jsx
docker  run \
--name nacos -d \
-p 8848:8848 \
--privileged=true \
--restart=always \
-e JVM_XMS=256m \
-e JVM_XMX=256m \
-e MODE=standalone \
-e PREFER_HOST_MODE=hostname \
-v /home/nacos/logs:/home/nacos/logs \
-v /home/nacos/init.d/custom.properties:/home/nacos/init.d/custom.properties \
nacos/nacos-server
```

###### 方式二

```
通过docker-compose部署,包含prometheus/grafana等监控组件
```

###### 1.拉取仓库



```php
git clone --depth 1 https://github.com/nacos-group/nacos-docker.git
```

###### 2.运行docker-compose



```bash
cd nacos-docker
docker-compose -f example/standalone-derby.yaml up -d 
```



###### 方式三

拉镜像，版本查看：https://github.com/nacos-group/nacos-docker

```
docker pull nacos/nacos-server:1.1.4  //稳定版，无权限
docker pull nacos/nacos-server:1.3.1  //稳定版，有权限
```

创建数据目录

```
mkdir -p /home/dockerdata/nacos/logs
mkdir -p /home/dockerdata/nacos1.3.1/logs
 
```

 

运行镜像 默认账号密码：nacos/nacos

~~~shell


\#1.1.4

docker run -d \

-e PREFER_HOST_MODE=ip \

-e MODE=standalone \

-e SPRING_DATASOURCE_PLATFORM=mysql \

-e MYSQL_MASTER_SERVICE_HOST=172.168.1.33 \

-e MYSQL_MASTER_SERVICE_PORT=3306 \

-e MYSQL_MASTER_SERVICE_USER=root \

-e MYSQL_MASTER_SERVICE_PASSWORD=root \

-e MYSQL_MASTER_SERVICE_DB_NAME=nacos \

-e MYSQL_SLAVE_SERVICE_HOST=172.168.1.33 \

-e MYSQL_SLAVE_SERVICE_PORT=3306 \

-v /home/dockerdata/nacos/logs:/home/nacos/logs \

-p 8848:8848 \

--name nacos \

--restart=always \

nacos/nacos-server:1.1.4

 

 

\#1.3.1

docker run -d \
-e PREFER_HOST_MODE=ip \
-e MODE=standalone \
-e SPRING_DATASOURCE_PLATFORM=mysql \
-e MYSQL_SERVICE_HOST=172.168.1.33 \
-e MYSQL_SERVICE_PORT=3306 \
-e MYSQL_SERVICE_USER=root \
-e MYSQL_SERVICE_PASSWORD=root \
-e MYSQL_SERVICE_DB_NAME=nacos \
-e TIME_ZONE='Asia/Shanghai' \
-v /home/dockerdata/nacos1.3.1/logs:/home/nacos/logs \
-p 8848:8848 \
--name nacos1.3.1 \
--restart=always \
nacos/nacos-server:1.3.1
~~~





[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

nacos初始化sql,需要先创建nacos数据库后，然后执行下面的sql

https://github.com/alibaba/nacos/blob/master/config/src/main/resources/META-INF/nacos-db.sql

![img](https://images.cnblogs.com/OutliningIndicators/ContractedBlock.gif) View Code

 

1.1.4 升级1.3.1需要执行的脚本

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

```
ALTER TABLE `roles` ADD UNIQUE `uk_username_role` (`username`, `role`);

CREATE TABLE permissions (
    role varchar(50) NOT NULL,
    resource varchar(512) NOT NULL,
    action varchar(8) NOT NULL,
    constraint uk_role_permission UNIQUE (role,resource,action)
) ROW_FORMAT=DYNAMIC;
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

 如果启动1.3.1报错，比如mysql时区异常，把conf配置文件弄到主机上

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

```
docker cp nacos1.3.1:/home/nacos/conf /home/dockerdata/nacos1.3.1 

#修改mysql的配置后

docker stop nacos1.3.1
docker rm nacos1.3.1
```

~~~shell
docker run -d \
-e PREFER_HOST_MODE=ip \
-e MODE=standalone \
-e SPRING_DATASOURCE_PLATFORM=mysql \
-e MYSQL_SERVICE_HOST=172.168.1.33 \
-e MYSQL_SERVICE_PORT=3306 \
-e MYSQL_SERVICE_USER=root \
-e MYSQL_SERVICE_PASSWORD=root \
-e MYSQL_SERVICE_DB_NAME=nacos \
-e TIME_ZONE='Asia/Shanghai' \
-v /home/dockerdata/nacos1.3.1/logs:/home/nacos/logs \
-v /home/dockerdata/nacos1.3.1/conf:/home/nacos/conf \
-p 8848:8848 \
--name nacos1.3.1 \
--restart=always \
nacos/nacos-server:1.3.1
~~~



##### 5.21.3.10 Docker 安装 Elasticsearch

如果没有安装docker请参考我的另一篇使用docker安装redis   yum安装一行命令即可搞定

 使用 Docker 中国官方镜像加速

```
[root@VM_0_4_centos ~]# docker pull registry.docker-cn.com/library/elasticsearch
```

 查看镜像：命令 docker images

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

```
docker images
REPOSITORY                                     TAG                 IMAGE ID            CREATED             SIZE
registry.docker-cn.com/library/elasticsearch   latest              73e6fdf8bd4f        5 days ago          486 MB
registry.docker-cn.com/library/redis           latest              4e8db158f18d        2 weeks ago         83.4 MB
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

运行

注意：5.0*默认*分配jvm空间大小为*2g* 5.0之前好像是1g

如果你的服务器内存够大请随意，我的只有2g内存 第一次装没设置大小，结果嘛，大不了重装系统而已

-e ES_JAVA_OPTS="-Xms256m -Xmx256m" //设置初始内存 和最大内存

```
docker run -e ES_JAVA_OPTS="-Xms256m -Xmx256m" -d -p 9200:9200 -p 9300:9300 --name myes  73e6fdf8bd4f[注：这是要运行的镜像id]
```

docker ps 查看 可以看到myes以运行

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

```
docker ps
CONTAINER ID        IMAGE                                  COMMAND                  CREATED             STATUS              PORTS                                            NAMES
fa6da79ebd61        73e6fdf8bd4f                           "/docker-entrypoin..."   3 minutes ago       Up 3 minutes        0.0.0.0:9200->9200/tcp, 0.0.0.0:9300->9300/tcp   myes
7512230290be        registry.docker-cn.com/library/redis   "docker-entrypoint..."   26 hours ago        Up 26 hours         0.0.0.0:6379->6379/tcp                           myredis
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

 

测试：

浏览器输入：http://140.1x3.x.xx:9200/ 你的服务器ip 端口号

浏览器返回如下信息，证明安装成功

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

```
{
  "name" : "kdJt_qz",
  "cluster_name" : "elasticsearch",
  "cluster_uuid" : "24MHPea3QCGX10L_yyxe4A",
  "version" : {
    "number" : "5.6.10",
    "build_hash" : "b727a60",
    "build_date" : "2018-06-06T15:48:34.860Z",
    "build_snapshot" : false,
    "lucene_version" : "6.6.1"
  },
  "tagline" : "You Know, for Search"
}
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)



##### 5.21.3.10 Docker 安装 Jmeter

前置条件 配置好了JDK1.8

1: 下载tar安装包  

wget https://mirrors.tuna.tsinghua.edu.cn/apache/jmeter/binaries/apache-jmeter-5.4.tgz



2：编写Dockerfile镜像文件

vi Dockerfile

~~~shell
FROM java:8

ENV http_proxy ""
ENV https_proxy ""

RUN mkdir /jmeterdocker
RUN mkdir -p /jmeterdocker/test
RUN mkdir -p /jmeterdocker/test/input/jmx
RUN mkdir -p /jmeterdocker/test/input/testdata
RUN mkdir -p /jmeterdocker/test/report/html
RUN mkdir -p /jmeterdocker/test/report/jtl
RUN mkdir -p /jmeterdocker/test/report/outputdata
RUN cd /jmeterdocker

ENV JMETER_VERSION=5.4
ENV JMETER_HOME=/jmeterdocker/apache-jmeter-${JMETER_VERSION}
ENV JMETER_PATH=${JMETER_HOME}/bin:${PATH}
ENV PATH=${JMETER_HOME}/bin:${PATH}

COPY apache-jmeter-${JMETER_VERSION}.tgz /jmeterdocker

RUN cd /jmeterdocker \
&& tar xvf apache-jmeter-5.4.tgz \
&& rm apache-jmeter-5.4.tgz

~~~



3：执行命令生成镜像

docker build -t jmeter_test:v1 .

4：启动容器



~~~shell
docker run --name="my-jmeter" --net="host"  -v /tmp/jmeterspace/test/input/jmx:/jmeterdocker/test/input/jmx  -v /tmp/jmeterspace/test/input/testdata:/jmeterdocker/test/input/testdata  -v /tmp/jmeterspace/test/report/html:/jmeterdocker/test/report/html  -v /tmp/jmeterspace/test/report/jtl:/jmeterdocker/test/report/jtl  -v /tmp/jmeterspace/test/report/outputputdata:/jmeterdocker/test/report/outputdata   -it -d 【image id】
~~~









#### 拓展  Docker-compose

~~~shell
解决docker-compose 命令不存在、未找到命令错误

1.安装扩展源



sudo yum -y install epel-release

2.安装python-pip模块



sudo yum install python-pip

3.查看docker-compose版本



docker-compose version

\# 提示未找到命令

4.通过以命令进行安装



cd /usr/local/bin/

wget https://github.com/docker/compose/releases/download/1.14.0-rc2/docker-compose-Linux-x86_64

rename docker-compose-Linux-x86_64 docker-compose docker-compose-Linux-x86_64

chmod +x /usr/local/bin/docker-compose

5.再通过docker-compose version命令进行查看


~~~






#### 拓展：DockerFile

**Dockerfile概述**

> Dockerfile是docker中镜像文件的的描述文件，说的直白点就是镜像文件到底是由什么东西一步步构成的。
> 例如：你在淘宝上买了一个衣架，但是卖家并没有给你发一个完整的衣架，而是一些组件和一张图纸，你按照这个图纸一步一步将衣架组装起来，就成了你所需要的样子。那么Dockerfile 就是这张图纸，镜像文件就是你需要的这个衣架，Dockerfile 不建议随便命名，就用 Dockerfile。
> 因此，Dockerfile其内部包含了一条条的指令，每一条指令构建一层，因此每一条指令的内容，就是描述该层应当如何构建。

**Docker 执行 Dockerfile 的大致流程：**

> （1）docker从基础镜像运行一个容器；
> （2）执行一条指令并对容器作出修改；
> （3）执行类似dockercommit的操作提交一个新的镜像层
> （4）docker再基于刚提交的镜像运行一个新容器；
> （5）执行dockerfile中的下一条指令直到所有指令都执行完成。

**回顾Dockerfile**

> 说到Dockerfile，就离不开Dockerfile的核心组件，尤其是镜像。镜像是运行容器的基础环境，也就是说镜像是docker容器创建的关键，而创建镜像的三种方式之一的Dockerfile是最为灵活的。

**什么是Dockerfile？**
Dockerfile可以看做是被Docker程序所解释翻译的脚本，由一组命令集合而成，每一条命令都对应一条操作命令，有其翻译为Linux下的具体命令。用户可以通过自定义内容来快速构建镜像。
​ 其实说简单点，你可以认为Dockerfile是“专门用于构建镜像的shell脚本”。
​ 还记得Dockerfile的严格格式吗？我们先来看一下这个表格。
![img](https://s4.51cto.com/images/blog/202007/29/329c162ed62fb6551505e2840581fdad.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_90,type_ZmFuZ3poZW5naGVpdGk=)

###### 1.构建httpd服务镜像

```handlebars
[root@localhost ~]# cd /opt/
[root@localhost opt]# mkdir apache ##创建目录
[root@localhost opt]# cd apache/
[root@localhost sshd]# vim Dockerfile  ##编写dockerfile文件
#基于的基础镜像
FROM centos
#维护镜像的用户信息
MAINTAINER zjz
#镜像操作指令安装Apache软件
RUN yum -y update
RUN yum -y install httpd
#开启 80端口
EXPOSE 80
#复制网站首页文件
ADD index.html /var/www/html/index.html
#将执行脚本复制到镜像中
ADD run.sh /run.sh
RUN chmod 755 /run.sh
#启动容器是执行脚本
CMD ["/run.sh"]

其中注意：run 命令可以有多条CMD只能有一条，若有多条则只会执行最后一条

编写启动httpd服务的shell脚本

vim run.sh
#!/bin/bash
rm -rf /run/httpd/*
exec /usr/sbin/apachectl -D FOREGROUND


编写测试页面

vim index.html
this is docker httpd web

使用tree命令查看目录的文件结构
没有tree这个命令，用yum -y install tree 装一哈

[root@localhost apache]# tree ./
./
├── Dockerfile
├── index.html
└── run.sh

0 directories, 3 files
1.2.3.4.5.6.7.8.9.10.11.12.13.14.15.16.17.18.19.20.21.22.23.24.25.26.27.28.29.30.31.32.33.34.35.36.37.38.39.40.41.42.43.44.45.46.
```

构建和使用镜像（创建运行容器）

```handlebars
[root@localhost apache]# docker build -t httpd:new .
1.
```

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200728102634676.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDkwNzgxMw==,size_16,color_FFFFFF,t_70)

```handlebars
[root@localhost apache]# docker images
1.
```

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200728102803213.png)

```handlebars
#基于构建的镜像创建并运行容器，给容器取名为test
[root@localhost apache]# docker run --name test -d -P httpd:new  
1.2.
```

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200728102913188.png)

```handlebars
[root@localhost apache]# docker ps -a
1.
```

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200728103018381.png)
这样我们进入容器中检查一下这个页面文件是否存在

```handlebars
[root@localhost apache]# docker exec -it test /bin/bash
[root@0467d8d2d590 /]# cat /var/www/html/index.html 
this is docker httpd web
1.2.3.
```

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200728103316453.png)
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200728144850125.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDkwNzgxMw==,size_16,color_FFFFFF,t_70)

###### 2、构建sshd镜像

```handlebars
[root@localhost ~]# cd /opt/
[root@localhost opt]# mkdir sshd  ##创建目录
[root@localhost opt]# cd sshd/
[root@localhost sshd]# vim Dockerfile  ##编写dockerfile文件
#sshd服务的镜像构建——基于Dockerfile
#首先先下载基础镜像centos，创建对应的工作目录
#开始编写nginx的Dockerfile
#第一步：基础镜像
FROM centos:7
#第二步：维护者信息
MAINTAINER zjz
#第三步：指令集
RUN yum -y update
RUN yum -y install openssh* net-tools lsof telnet passwd 
RUN echo '123123' | passwd --stdin root
#不以PAM认证登录而是以密钥对登录（非对称密钥），即禁用ssh的PAM认证
RUN sed -i 's/UsePAM yes/UsePAM no/g' /etc/ssh/sshd_config
RUN ssh-keygen -t rsa -f /etc/ssh/ssh_host_rsa_key
#禁用ssh中PAM会话模块
RUN sed -i '/^session\s\+required\s\+pam_loginuid.so/s/^/#/' /etc/pam.d/sshd
#创建ssh工作目录和权限设置
RUN mkdir -p /root/.ssh && chown root:root /root && chmod 700 /root/.ssh
#开放22端口
EXPOSE 22
#第四步：启动容器时执行指令
CMD ["/usr/sbin/sshd","-D"]

构建镜像和运行容器
[root@localhost sshd]# docker run -d -P sshd:new 
6005aaad0e99897e11672e081101a43aee169c06acba08a48b1353317d9504eb
[root@localhost sshd]# docker ps -a
CONTAINER ID        IMAGE               COMMAND               CREATED             STATUS              PORTS                   NAMES
6005aaad0e99        sshd:new            "/usr/sbin/sshd -D"   7 seconds ago       Up 6 seconds        0.0.0.0:32768->22/tcp   pensive_poincare

测试
[root@localhost sshd]# ssh 192.168.10.52 -p 32768
The authenticity of host '[192.168.10.52]:32768 ([192.168.10.52]:32768)' can't be established.
RSA key fingerprint is c5:95:5d:0a:ce:b3:d8:cc:43:f7:b6:32:89:12:28:21.
Are you sure you want to continue connecting (yes/no)? yes
Warning: Permanently added '[192.168.10.52]:32768' (RSA) to the list of known hosts.
root@192.168.10.52's password: 
Permission denied, please try again.
root@192.168.10.52's password: 
[root@6005aaad0e99 ~]# exit
logout
Connection to 192.168.10.52 closed.

此时我们登录该容器（ssh或者docker exec命令）查看sshd服务的状态（但是systemctl无法使用）
[root@6005aaad0e99 ~]# systemctl status sshd
Failed to get D-Bus connection: Operation not permitted

一则我们可以使用下面的命令使用该命令，二则我们可以基于上面构建的镜像作为基础镜像构建systemctl的镜像来测试验证。
[root@localhost sshd]# docker run --privileged -itd -P sshd:new  /usr/sbin/init 
bf552af2fb6b7d512bc44c32262a5dcce092e26bb7bec8e73c866a5c5a755d83
[root@localhost sshd]#  docker ps -a
CONTAINER ID        IMAGE               COMMAND               CREATED             STATUS              PORTS                   NAMES
bf552af2fb6b        sshd:new            "/usr/sbin/init"      6 seconds ago       Up 6 seconds        0.0.0.0:32770->22/tcp   adoring_bose
bb24b2efd442        systemctl:new       "/usr/sbin/init"      13 minutes ago      Up 13 minutes       22/tcp                  sleepy_curie
0467d8d2d590        httpd:new           "/run.sh"             27 minutes ago      Up 27 minutes       0.0.0.0:32769->80/tcp   test
6005aaad0e99        sshd:new            "/usr/sbin/sshd -D"   About an hour ago   Up About an hour    0.0.0.0:32768->22/tcp   pensive_poincare
[root@localhost sshd]# ssh 192.168.10.52 -p 32770
The authenticity of host '[192.168.10.52]:32770 ([192.168.10.52]:32770)' can't be established.
ECDSA key fingerprint is e7:5b:57:32:ea:12:db:90:c5:da:d5:3d:95:ff:48:ab.
Are you sure you want to continue connecting (yes/no)? yes
Warning: Permanently added '[192.168.10.52]:32770' (ECDSA) to the list of known hosts.
root@192.168.10.52's password: 
[root@bf552af2fb6b ~]#  systemctl status sshd
● sshd.service - OpenSSH server daemon
   Loaded: loaded (/usr/lib/systemd/system/sshd.service; enabled; vendor preset: enabled)
   Active: active (running) since Tue 2020-07-28 02:55:53 UTC; 48s ago
     Docs: man:sshd(8)
           man:sshd_config(5)
 Main PID: 75 (sshd)
   CGroup: /docker/bf552af2fb6b7d512bc44c32262a5dcce092e26bb7bec8e73c866a5c5a755d83/system.slice/sshd.service
           ├─ 75 /usr/sbin/sshd -D
           ├─ 85 sshd: root@pts/1
           ├─ 89 -bash
           └─102 systemctl status sshd
           ‣ 75 /usr/sbin/sshd -D

Jul 28 02:55:53 bf552af2fb6b systemd[1]: Starting OpenSSH server daemon...
Jul 28 02:55:53 bf552af2fb6b sshd[75]: Server listening on 0.0.0.0 port 22.
Jul 28 02:55:53 bf552af2fb6b sshd[75]: WARNING: 'UsePAM no' is not supported in Red Hat Enterprise Linux and ...lems.
Jul 28 02:55:53 bf552af2fb6b sshd[75]: Server listening on :: port 22.
Jul 28 02:55:53 bf552af2fb6b systemd[1]: Started OpenSSH server daemon.
Jul 28 02:56:23 bf552af2fb6b sshd[85]: WARNING: 'UsePAM no' is not supported in Red Hat Enterprise Linux and ...lems.
Jul 28 02:56:27 bf552af2fb6b sshd[85]: Failed password for root from 192.168.10.52 port 35474 ssh2
Jul 28 02:56:29 bf552af2fb6b sshd[85]: Failed password for root from 192.168.10.52 port 35474 ssh2
Jul 28 02:56:31 bf552af2fb6b sshd[85]: Accepted password for root from 192.168.10.52 port 35474 ssh2
Hint: Some lines were ellipsized, use -l to show in full.

1.2.3.4.5.6.7.8.9.10.11.12.13.14.15.16.17.18.19.20.21.22.23.24.25.26.27.28.29.30.31.32.33.34.35.36.37.38.39.40.41.42.43.44.45.46.47.48.49.50.51.52.53.54.55.56.57.58.59.60.61.62.63.64.65.66.67.68.69.70.71.72.73.74.75.76.77.78.79.80.81.82.83.84.85.86.87.88.89.90.91.
```

###### 3、构建systemctl镜像

```handlebars
[root@localhost ~]# cd /opt/
[root@localhost opt]# mkdir systemctl  ##创建目录
[root@localhost opt]# cd systemctl/
[root@localhost sshd]# vim Dockerfile  ##编写dockerfile文件
FROM sshd:new
MAINTAINER zjz
ENV container docker
#下面的命令是放在一个镜像层中执行的，可以减少镜像层
#括号中的指令含义是遍历进入的目录文件，删除除了systemd-tmpfiles-setup.service的所有文件,之后删除一些其他文件
RUN (cd /lib/systemd/system/sysinit.target.wants/; for i in *; do [ $i == systemd-tmpfiles-setup.service ] || rm -f $i; done); \
rm -f /lib/systemd/system/multi-user.target.wants/*; \
rm -f /etc/systemd/system/*.wants/*; \
rm -f /lib/systemd/system/local-fs.target.wants/*; \
rm -f /lib/systemd/system/sockets.target.wants/*udev*; \
rm -f /lib/systemd/system/sockets.target.wants/*initctl*; \
rm -f /lib/systemd/system/basic.target.wants/*; \
rm -f /lib/systemd/system/anaconda.target.wants/*;
VOLUME [ "/sys/fs/cgroup" ]
CMD ["/usr/sbin/init"]
1.2.3.4.5.6.7.8.9.10.11.12.13.14.15.16.17.18.19.
```

构建运行及测试

```handlebars
[root@localhost systemctl]# docker build -t systemctl:new . ##创建镜像
[root@localhost systemctl]# docker run --privileged -it -v /sys/fs/cgroup/:/sys/fs/cgroup:ro systemctl:new /usr/sbin/init ##privateged container 内的root拥有真正的root权限，否则，container内的root只是外部的一个普通用户权限。
systemd 219 running in system mode. (+PAM +AUDIT +SELINUX +IMA -APPARMOR +SMACK +SYSVINIT +UTMP +LIBCRYPTSETUP +GCRYPT +GNUTLS +ACL +XZ +LZ4 -SECCOMP +BLKID +ELFUTILS +KMOD +IDN)
Detected virtualization docker.
Detected architecture x86-64.

Welcome to CentOS Linux 7 (Core)!

Set hostname to <bb24b2efd442>.
[  OK  ] Created slice Root Slice.
[  OK  ] Listening on Journal Socket.
[  OK  ] Created slice System Slice.
[  OK  ] Reached target Slices.
[  OK  ] Reached target Paths.
[  OK  ] Listening on Delayed Shutdown Socket.
[  OK  ] Reached target Local File Systems.
         Starting Create Volatile Files and Directories...
[  OK  ] Reached target Swap.
         Starting Journal Service...
[  OK  ] Started Create Volatile Files and Directories.
[ INFO ] Update UTMP about System Boot/Shutdown is not active.
[DEPEND] Dependency failed for Update UTMP about System Runlevel Changes.
Job systemd-update-utmp-runlevel.service/start failed with result 'dependency'.
[  OK  ] Started Journal Service.
[  OK  ] Reached target System Initialization.
[  OK  ] Listening on D-Bus System Message Bus Socket.
[  OK  ] Reached target Sockets.
[  OK  ] Reached target Basic System.
[  OK  ] Reached target Multi-User System.
[  OK  ] Started Daily Cleanup of Temporary Directories.
[  OK  ] Reached target Timers.
1.2.3.4.5.6.7.8.9.10.11.12.13.14.15.16.17.18.19.20.21.22.23.24.25.26.27.28.29.30.31.
```

重新开启一个终端进行测试

```handlebars
[root@localhost ~]# cd /opt/
[root@localhost opt]# cd systemctl/
[root@localhost systemctl]# docker ps -a
[root@localhost systemctl]# docker ps
CONTAINER ID        IMAGE               COMMAND               CREATED             STATUS              PORTS                   NAMES
bb24b2efd442        systemctl:new       "/usr/sbin/init"      9 minutes ago       Up 9 minutes        22/tcp                  sleepy_curie
0467d8d2d590        httpd:new           "/run.sh"             23 minutes ago      Up 23 minutes       0.0.0.0:32769->80/tcp   test
6005aaad0e99        sshd:new            "/usr/sbin/sshd -D"   44 minutes ago      Up 44 minutes       0.0.0.0:32768->22/tcp   pensive_poincare
[root@localhost systemctl]# docker exec -it sleepy_curie /bin/bash
[root@bb24b2efd442 /]# systemctl status sshd
● sshd.service - OpenSSH server daemon
   Loaded: loaded (/usr/lib/systemd/system/sshd.service; disabled; vendor preset: enabled)
   Active: inactive (dead)
     Docs: man:sshd(8)
           man:sshd_config(5)
[root@bb24b2efd442 /]# ssh 192.168.10.52 -p 22
The authenticity of host '192.168.10.52 (192.168.10.52)' can't be established.
ECDSA key fingerprint is SHA256:X3dOS5bVumqe/7loOyPanoa7rXqlTF79C5mavP1EQW0.
ECDSA key fingerprint is MD5:00:8f:be:85:3b:97:c9:05:bb:fb:fe:17:14:49:19:9f.
Are you sure you want to continue connecting (yes/no)? yes
Warning: Permanently added '192.168.10.52' (ECDSA) to the list of known hosts.
root@192.168.10.52's password: 
Last failed login: Tue Jul 28 10:46:42 CST 2020 from 172.17.0.4 on ssh:notty
There were 2 failed login attempts since the last successful login.
Last login: Tue Jul 28 10:43:54 2020 from 192.168.10.1
[root@localhost ~]# exit
logout
Connection to 192.168.10.52 closed.
[root@bb24b2efd442 /]# exit
exit

1.2.3.4.5.6.7.8.9.10.11.12.13.14.15.16.17.18.19.20.21.22.23.24.25.26.27.28.29.30.31.
```

###### 4.构建Nginx镜像

```handlebars
[root@localhost ~]# cd /opt/
[root@localhost opt]# mkdir nginx   ##创建Nginx目录
[root@localhost opt]# cd nginx/
[root@localhost nginx]# vim Dockerfile
FROM centos:7
MAINTAINER The is nginx <zjz>
RUN yum install -y proc-devel gcc gcc-c++ zlib zlib-devel make openssl-devel wget
ADD nginx-1.14.0.tar.gz /usr/local
WORKDIR /usr/local/nginx-1.14.0/
RUN ./configure --prefix=/usr/local/nginx && make && make install
EXPOSE 80
EXPOSE 443
RUN echo "daemon off;">>/usr/local/nginx/conf/nginx.conf
WORKDIR /root/nginx
ADD run.sh /run.sh
RUN chmod 755 /run.sh
CMD ["/run.sh"]

[root@localhost nginx]# vim run.sh
#!/bin/bash
/usr/local/nginx/sbin/nginx   ##开启Nginx服务

[root@localhost nginx]# rz    ##在xshell里上传nginx安装包

[root@localhost nginx]# ls
nginx-1.14.0.tar.gz
[root@localhost nginx]# docker build -t nginx:new .   ##创建镜像
[root@localhost nginx]# docker run -d -P nginx:new    ##创建容器
ba75ff06051430938bbb014450cd16f7b2b7a2fe023969a6a0ec76051d6872c5
[root@localhost nginx]# docker ps -a   ##查看容器

CONTAINER ID        IMAGE               COMMAND               CREATED             STATUS              PORTS                                           NAMES
ba75ff060514        nginx:new           "/run.sh"             14 seconds ago      Up 14 seconds       0.0.0.0:32772->80/tcp, 0.0.0.0:32771->443/tcp   pedantic_archimedes
1.2.3.4.5.6.7.8.9.10.11.12.13.14.15.16.17.18.19.20.21.22.23.24.25.26.27.28.29.30.31.32.33.
```

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200728135652379.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDkwNzgxMw==,size_16,color_FFFFFF,t_70)

###### 5.构建Tomcat镜像

```handlebars
[root@localhost opt]# mkdir tomcat
[root@localhost opt]# cd tomcat/
[root@localhost tomcat]# rz

[root@localhost tomcat]# ls
jdk-8u211-linux-x64.tar.gz
[root@localhost tomcat]# rz

[root@localhost tomcat]# ls
apache-tomcat-8.5.35.tar.gz  jdk-8u211-linux-x64.tar.gz
[root@localhost tomcat]# vim Dockerfile
FROM centos:7
MAINTAINER this is tomcat
ADD jdk-8u211-linux-x64.tar.gz /usr/local
WORKDIR /usr/local
RUN mv jdk1.8.0_211  /usr/local/java
ENV JAVA_HOME /usr/local/java     ##设置环境变量
ENV JAVA_BIN /usr/local/java/bin
ENV JRE_HOME /usr/local/java/jre
ENV PATH $PATH:/usr/local/java/bin:/usr/local/java/jre/bin
ENV CLASSPATH /usr/local/java/jre/bin:/usr/local/java/lib:/usr/local/java/jre/lib/charsets.jar
ADD apache-tomcat-8.5.35.tar.gz  /usr/local
WORKDIR /usr/local
RUN mv apache-tomcat-8.5.35  /usr/local/tomcat8
EXPOSE 8080
ENTRYPOINT ["/usr/local/tomcat8/bin/catalina.sh","run"]
[root@localhost tomcat]# docker build -t tomcat:centos .  ##创建镜像
[root@localhost tomcat]# docker run --name tomcat01 -p 1234:8080 -it  tomcat:centos /bin/bash
##创建容器
[root@localhost tomcat]# docker ps
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                                           NAMES
3f81e707d8b6        tomcat:centos       "/usr/local/tomcat8/…"   3 minutes ago       Up 3 minutes        0.0.0.0:1234->8080/tcp                          tomcat01

1.2.3.4.5.6.7.8.9.10.11.12.13.14.15.16.17.18.19.20.21.22.23.24.25.26.27.28.29.30.31.32.33.
```

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200728143626649.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDkwNzgxMw==,size_16,color_FFFFFF,t_70)

###### 6.构建MySQL镜像

```handlebars
[root@localhost mysql5.7]# cat Dockerfile

#基于基础镜像
FROM centos:7
#维护该镜像的用户信息
MAINTAINER zjz
#指令集
#下载相关工具
RUN yum -y install \
ncurses \
ncurses-devel \
bison \
cmake \
make \
gcc \
gcc-c++
#创建mysql用户
RUN useradd -s /sbin/nologin mysql
#复制软件包到指定目录（将会自动解压）
ADD mysql-boost-5.7.20.tar.gz /usr/local/src
#指定工作目录
WORKDIR /usr/local/src/mysql-5.7.20/
#cmake配置及编译安装
RUN cmake \
-DCMAKE_INSTALL_PREFIX=/usr/local/mysql \
-DMYSQL_UNIX_ADDR=/usr/local/mysql/mysql.sock \
-DSYSCONFDIR=/etc \
-DSYSTEMD_PID_DIR=/usr/local/mysql \
-DDEFAULT_CHARSET=utf8 \
-DDEFAULT_COLLATION=utf8_general_ci \
-DWITH_INNOBASE_STORAGE_ENGINE=1 \
-DWITH_ARCHIVE_STORAGE_ENGINE=1 \
-DWITH_BLACKHOLE_STORAGE_ENGINE=1 \
-DWITH_PERFSCHEMA_STORAGE_ENGINE=1 \
-DMYSQL_DATADIR=/usr/local/mysql/data \
-DWITH_BOOST=boost \
-DWITH_SYSTEMD=1 && make && make install
#更改mysql目录属主属组
RUN chown -R mysql:mysql /usr/local/mysql/
#删除默认安装的my.cnf文件
RUN rm -rf /etc/my.cnf
#复制一份my.cnf到etc目录下
ADD my.cnf /etc
#更改该文件权限
RUN chown mysql:mysql /etc/my.cnf
#设置环境变量，命令目录及库文件目录
ENV PATH=/usr/local/mysql/bin:/usr/local/mysql/lib:$PATH
#指定工作目录
WORKDIR /usr/local/mysql/
#初始化设置
RUN bin/mysqld \
--initialize-insecure \
--user=mysql \
--basedir=/usr/local/mysql \
--datadir=/usr/local/mysql/data
#优化启动方式
RUN cp /usr/local/mysql/usr/lib/systemd/system/mysqld.service /usr/lib/systemd/system/
EXPOSE 3306
#直接设置运行启动脚本
RUN echo -e "#!/bin/sh \nsystemctl enable mysqld" > /run.sh
RUN chmod 755 /run.sh
RUN sh /run.sh
#启动容器时执行
CMD ["init"]
1.2.3.4.5.6.7.8.9.10.11.12.13.14.15.16.17.18.19.20.21.22.23.24.25.26.27.28.29.30.31.32.33.34.35.36.37.38.39.40.41.42.43.44.45.46.47.48.49.50.51.52.53.54.55.56.57.58.59.60.61.62.63.64.
```

my.cnf文件

```handlebars
[client]
port = 3306
default-character-set=utf8
socket = /usr/local/mysql/mysql.sock

[mysql]
port = 3306
default-character-set=utf8
socket = /usr/local/mysql/mysql.sock

[mysqld]
user = mysql
basedir = /usr/local/mysql
datadir = /usr/local/mysql/data
port = 3306
character_set_server=utf8
pid-file = /usr/local/mysql/mysqld.pid
socket = /usr/local/mysql/mysql.sock
server-id = 1

sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES,NO_AUTO_CREATE_USER,NO_AUTO_VALUE_ON_ZERO,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,PIPES_AS_CONCAT,ANSI_QUOTES
1.2.3.4.5.6.7.8.9.10.11.12.13.14.15.16.17.18.19.20.21.
```

构建及运行

```handlebars
[root@localhost mysql5.7]# docker build -t mysql:latest .
...//友情提示MySQL5.7时间比较长
[root@localhost mysql5.7]# docker run --name mysql_new -d -P --privileged mysql:latest 
e9c9f93766d149a3387aed4cb5e04425269a884fccf06256b087d00e4c262222
[root@localhost mysql5.7]# docker ps -a
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                                           NAMES
e9c9f93766d1        mysql:latest        "init"                   6 seconds ago       Up 5 seconds        0.0.0.0:32774->3306/tcp  
1.2.3.4.5.6.7.
```

进入MySQL服务的容器中进行提权操作

```handlebars
[root@localhost mysql5.7]# docker exec -it mysql_new /bin/bash
[root@e9c9f93766d1 mysql]# mysql
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 3
Server version: 5.7.20 Source distribution

Copyright (c) 2000, 2017, Oracle and/or its affiliates. All rights reserved.

Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

mysql> grant all privileges on *.* to 'root'@'%' identified by '123456';
Query OK, 0 rows affected, 1 warning (0.00 sec)

mysql>  flush privileges;
Query OK, 0 rows affected (0.01 sec)

mysql> exit
Bye
[root@e9c9f93766d1 mysql]# exit
exit
1.2.3.4.5.6.7.8.9.10.11.12.13.14.15.16.17.18.19.20.21.22.23.24.
```

宿主机系统安装mariadb服务来测试

登录后复制

```handlebars
[root@localhost mysql5.7]# yum install mariadb -y
[root@localhost mysql5.7]# mysql -h 20.0.0.149 -P 32774 -uroot -p123456
Welcome to the MariaDB monitor.  Commands end with ; or \g.
Your MySQL connection id is 4
Server version: 5.7.20 Source distribution

Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

MySQL [(none)]> show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| mysql              |
| performance_schema |
| sys                |
+--------------------+
4 rows in set (0.01 sec)
#创建一个数据库，退出后再次然后进入容器查看
MySQL [(none)]> create database mydb;
Query OK, 1 row affected (0.00 sec)

MySQL [(none)]> exit
Bye

[root@localhost mysql5.7]# docker exec -it mysql_new /bin/bash
[root@e9c9f93766d1 mysql]# mysql
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 5
Server version: 5.7.20 Source distribution

Copyright (c) 2000, 2017, Oracle and/or its affiliates. All rights reserved.

Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

mysql> show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| mydb               |
| mysql              |
| performance_schema |
| sys                |
+--------------------+
5 rows in set (0.00 sec)

mysql> exit
Bye
[root@e9c9f93766d1 mysql]# exit
exit
[root@localhost mysql5.7]# 
1.2.3.4.5.6.7.8.9.10.11.12.13.14.15.16.17.18.19.20.21.22.23.24.25.26.27.28.29.30.31.32.33.34.35.36.37.38.39.40.41.42.43.44.45.46.47.48.49.50.51.52.53.54.55.56.57.58.
```

工程中一般不会将MySQL服务放在容器中运行，而是会单独使用服务器部署提供服务（搭建高可用集群架构）



5.21.3.10 docker 部署Jar

在服务器的/home目录下创建目录存放jar包及Dockerfile文件

将jar上传到该目录下

执行vim Dockerfile 命令创建Dockerfile文件，内容如下：

~~~makefile
FROM java:8
MAINTAINER test
ADD operation-manager-0.0.1-SNAPSHOT.jar operation.jar
EXPOSE 8080
ENTRYPOINT ["java","-jar","operation.jar"]
~~~



其中：
from java:8 拉取一个jdk为1.8的docker image
maintainer 作者是test
operation-manager-0.0.1-SNAPSHOT.ja 就是你上传的jar包，替换为jar包的名称
operation.jar 是你将该jar包重新命名为什么名称，在容器中运行
expose 该容器暴露的端口是多少，就是jar在容器中以多少端口运行
entrypoint 容器启动之后执行的命令，java -jar operation.jar 即启动jar

创建好Dockerfile文件之后，执行命令 docker build -t operation . 构建镜像：
注意最后的 . 表示 Dockerfile 文件在当前目录下
operation 指定构建之后镜像名称
镜像构建成功之后，就可以运行容器了
一般是用 docker run -d --name operation -p 8080:8080 operation 命令启动，
但是为了后续的项目更新方便，这里推荐使用下面这条命令：

~~~shell
docker run -d --name operation -p 8083:8080 -v /home/fxy/docker/service1/operation-manager-0.0.1-SNAPSHOT.jar:/operation.jar operation:latest
~~~



其中：
-p 映射端口8761 本机的端口 映射的容器的端口
-v 挂载目录/home/fxy/docker/service1/operation-manager-0.0.1-SNAPSHOT.jar:本地目录 /operation.jar容器目录，在创建前容器是没有software目录的，docker 容器会自己创建
–privileged=true 关闭安全权限，否则你容器操作文件夹没有权限
operation:latest 使用的镜像名称及版本

然后docker ps 看看你的容器有没有在运行即可，运行成功会出现以下内容：

docker logs --tail 300 -f operation查看启动日志（最后300行）

项目有更新时，只需将/home/fxy/docker/service1/下的jar替换掉，然后执行

docker stop operation
docker start operation

即可更新完毕，可以通过docker ps查看是否启动成功，或者调用接口验证



### 5.22 WebSoket

  WebSocket协议是基于TCP的一种新的网络协议。它实现了浏览器与服务器全双工(full-duplex)通信——允许服务器主动发送信息给客户端。

#### WebSocket和Socket的区别

#### 　　1.WebSocket:

1. 1. websocket通讯的建立阶段是依赖于http协议的。最初的握手阶段是http协议，握手完成后就切换到websocket协议，并完全与http协议脱离了。
   2. 建立通讯时，也是由客户端主动发起连接请求，服务端被动监听。
   3. 通讯一旦建立连接后，通讯就是“全双工”模式了。也就是说服务端和客户端都能在任何时间自由得发送数据，非常适合服务端要主动推送实时数据的业务场景。
   4. 交互模式不再是“请求-应答”模式，完全由开发者自行设计通讯协议。
   5. 通信的数据是基于“帧(frame)”的，可以传输文本数据，也可以直接传输二进制数据，效率高。当然，开发者也就要考虑封包、拆包、编号等技术细节。

#### 　　2.Socket:

1. 1. 服务端监听通讯，被动提供服务；客户端主动向服务端发起连接请求，建立起通讯。
   2. 每一次交互都是：客户端主动发起请求（request），服务端被动应答（response）。
   3. 服务端不能主动向客户端推送数据。
   4. 通信的数据是基于文本格式的。二进制数据（比如图片等）要利用base64等手段转换为文本后才能传输。

### 5.23 GitLab搭建

### 5.24 Memcache 搭建

Memcache缓存是个好软件，这里讲下在Linux下安装的方法：

服务器端主要是安装memcache服务器端，目前的最新版本是 memcached-1.3.0 。
下载：http://www.danga.com/memcached/dist/memcached-1.2.2.tar.gz
另外，Memcache用到了libevent这个库用于Socket的处理，所以还需要安装libevent，libevent的最新版本是libevent-1.3。（如果你的系统已经安装了libevent，可以不用安装）
官网：http://www.monkey.org/~provos/libevent/
下载：http://www.monkey.org/~provos/libevent-1.3.tar.gz

用wget指令直接下载这两个东西.下载回源文件后。
1.先安装libevent。这个东西在配置时需要指定一个安装路径，即./configure –prefix=/usr；然后make；然后make install；
2.再安装memcached，只是需要在配置时需要指定libevent的安装路径即./configure –with-libevent=/usr；然后make；然后make install；
这样就完成了Linux下Memcache服务器端的安装。详细的方法如下：

> 1.分别把memcached和libevent下载回来，放到 /tmp 目录下：
> \# cd /tmp
> \# wget http://www.danga.com/memcached/dist/memcached-1.2.0.tar.gz
> \# wget http://www.monkey.org/~provos/libevent-1.2.tar.gz
>
> 2.先安装libevent：
> \# tar zxvf libevent-1.2.tar.gz
> \# cd libevent-1.2
> \# ./configure –prefix=/usr
> \# make
> \# make install
>
> 3.测试libevent是否安装成功：
> \# ls -al /usr/lib | grep libevent
> lrwxrwxrwx 1 root root 21 11?? 12 17:38 libevent-1.2.so.1 -> libevent-1.2.so.1.0.3
> -rwxr-xr-x 1 root root 263546 11?? 12 17:38 libevent-1.2.so.1.0.3
> -rw-r–r– 1 root root 454156 11?? 12 17:38 libevent.a
> -rwxr-xr-x 1 root root 811 11?? 12 17:38 libevent.la
> lrwxrwxrwx 1 root root 21 11?? 12 17:38 libevent.so -> libevent-1.2.so.1.0.3
> 还不错，都安装上了。
>
> 4.安装memcached，同时需要安装中指定libevent的安装位置：
> \# cd /tmp
> \# tar zxvf memcached-1.2.0.tar.gz
> \# cd memcached-1.2.0
> \# ./configure –with-libevent=/usr
> \# make
> \# make install
> 如果中间出现报错，请仔细检查错误信息，按照错误信息来配置或者增加相应的库或者路径。
> 安装完成后会把memcached放到 /usr/local/bin/memcached ，
>
> 5.测试是否成功安装memcached：
> \# ls -al /usr/local/bin/mem*
> -rwxr-xr-x 1 root root 137986 11?? 12 17:39 /usr/local/bin/memcached
> -rwxr-xr-x 1 root root 140179 11?? 12 17:39 /usr/local/bin/memcached-debug

**安装Memcache的PHP扩展**
1.在http://pecl.php.net/package/memcache 选择相应想要下载的memcache版本。
2.安装PHP的memcache扩展

> tar vxzf memcache-2.2.1.tgz
> cd memcache-2.2.1
> /usr/local/php/bin/phpize
> ./configure –enable-memcache –with-php-config=/usr/local/php/bin/php-config –with-zlib-dir
> make
> make install

3.上述安装完后会有类似这样的提示：

> Installing shared extensions: /usr/local/php/lib/php/extensions/no-debug-non-zts-2007xxxx/

4.把php.ini中的extension_dir = “./”修改为

> extension_dir = “/usr/local/php/lib/php/extensions/no-debug-non-zts-2007xxxx/”

5.添加一行来载入memcache扩展：extension=memcache.so**memcached的基本设置** ：

1.启动Memcache的服务器端：
\# /usr/local/bin/memcached -d -m 10 -u root -l 192.168.0.200 -p 12000 -c 256 -P /tmp/memcached.pid

> -d选项是启动一个守护进程，
> -m是分配给Memcache使用的内存数量，单位是MB，我这里是10MB，
> -u是运行Memcache的用户，我这里是root，
> -l是监听的服务器IP地址，如果有多个地址的话，我这里指定了服务器的IP地址192.168.0.200，
> -p是设置Memcache监听的端口，我这里设置了12000，最好是1024以上的端口，
> -c选项是最大运行的并发连接数，默认是1024，我这里设置了256，按照你服务器的负载量来设定，
> -P是设置保存Memcache的pid文件，我这里是保存在 /tmp/memcached.pid，

2.如果要结束Memcache进程，执行：

> \# kill `cat /tmp/memcached.pid`

也可以启动多个守护进程，不过端口不能重复。

3.重启apache，service httpd restart

**Memcache环境测试** ：
运行下面的php文件，如果有输出This is a test!，就表示环境搭建成功。开始领略Memcache的魅力把！
< ?php
$mem = new Memcache;
$mem->connect(”127.0.0.1″, 11211);
$mem->set(’key’, ‘This is a test!’, 0, 60);
$val = $mem->get(’key’);
echo $val;
?>



### 5.25  Kafka

#### 一、简介

##### 1.1　概述

Kafka是最初由Linkedin公司开发，是一个分布式、分区的、多副本的、多订阅者，基于zookeeper协调的分布式日志系统（也可以当做MQ系统），常见可以用于web/nginx日志、访问日志，消息服务等等，Linkedin于2010年贡献给了Apache基金会并成为顶级开源项目。

主要应用场景是：日志收集系统和消息系统。

Kafka主要设计目标如下：

- 以时间复杂度为O(1)的方式提供消息持久化能力，即使对TB级以上数据也能保证常数时间的访问性能。
- 高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒100K条消息的传输。
- 支持Kafka Server间的消息分区，及分布式消费，同时保证每个partition内的消息顺序传输。
- 同时支持离线数据处理和实时数据处理。
- Scale out:支持在线水平扩展



##### 1.2　消息系统介绍

一个消息系统负责将数据从一个应用传递到另外一个应用，应用只需关注于数据，无需关注数据在两个或多个应用间是如何传递的。分布式消息传递基于可靠的消息队列，在客户端应用和消息系统之间异步传递消息。有两种主要的消息传递模式：**点对点传递模式、发布-订阅模式**。大部分的消息系统选用发布-订阅模式。**Kafka就是一种发布-订阅模式**。



##### 1.3　点对点消息传递模式

在点对点消息系统中，消息持久化到一个队列中。此时，将有一个或多个消费者消费队列中的数据。但是一条消息只能被消费一次。当一个消费者消费了队列中的某条数据之后，该条数据则从消息队列中删除。该模式即使有多个消费者同时消费数据，也能保证数据处理的顺序。这种架构描述示意图如下：

![img](https://images2018.cnblogs.com/blog/1228818/201805/1228818-20180507190326476-771565746.png)

**生产者发送一条消息到queue，只有一个消费者能收到**。



##### 1.4　发布-订阅消息传递模式

在发布-订阅消息系统中，消息被持久化到一个topic中。与点对点消息系统不同的是，消费者可以订阅一个或多个topic，消费者可以消费该topic中所有的数据，同一条数据可以被多个消费者消费，数据被消费后不会立马删除。在发布-订阅消息系统中，消息的生产者称为发布者，消费者称为订阅者。该模式的示例图如下：

![img](https://images2018.cnblogs.com/blog/1228818/201805/1228818-20180507190443404-1266011458.png)

**发布者发送到topic的消息，只有订阅了topic的订阅者才会收到消息**。

[回到顶部](https://www.cnblogs.com/qingyunzong/p/9004509.html#_labelTop)

#### 二、Kafka的优点



##### 2.1　解耦

在项目启动之初来预测将来项目会碰到什么需求，是极其困难的。消息系统在处理过程中间插入了一个隐含的、基于数据的接口层，两边的处理过程都要实现这一接口。这允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。

##### 2.2　冗余（副本）

有些情况下，处理数据的过程会失败。除非数据被持久化，否则将造成丢失。消息队列把数据进行持久化直到它们已经被完全处理，通过这一方式规避了数据丢失风险。许多消息队列所采用的"插入-获取-删除"范式中，在把一个消息从队列中删除之前，需要你的处理系统明确的指出该消息已经被处理完毕，从而确保你的数据被安全的保存直到你使用完毕。

##### 2.3　扩展性

因为消息队列解耦了你的处理过程，所以增大消息入队和处理的频率是很容易的，只要另外增加处理过程即可。不需要改变代码、不需要调节参数。扩展就像调大电力按钮一样简单。

##### 2.4　灵活性&峰值处理能力

在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量并不常见；如果为以能处理这类峰值访问为标准来投入资源随时待命无疑是巨大的浪费。使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃。

##### 2.5　可恢复性

系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理。

##### 2.6　顺序保证

在大多使用场景下，数据处理的顺序都很重要。大部分消息队列本来就是排序的，并且能保证数据会按照特定的顺序来处理。Kafka保证一个Partition内的消息的有序性。

##### 2.7　缓冲

在任何重要的系统中，都会有需要不同的处理时间的元素。例如，加载一张图片比应用过滤器花费更少的时间。消息队列通过一个缓冲层来帮助任务最高效率的执行———写入队列的处理会尽可能的快速。该缓冲有助于控制和优化数据流经过系统的速度。

##### 2.8　异步通信

很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们。

#### 三、常用Message Queue对比

##### 3.1　RabbitMQ

RabbitMQ是使用Erlang编写的一个开源的消息队列，本身支持很多的协议：AMQP，XMPP, SMTP, STOMP，也正因如此，它非常重量级，更适合于企业级的开发。同时实现了Broker构架，这意味着消息在发送给客户端时先在中心队列排队。对路由，负载均衡或者数据持久化都有很好的支持。

##### 3.2　Redis

Redis是一个基于Key-Value对的NoSQL数据库，开发维护很活跃。虽然它是一个Key-Value数据库存储系统，但它本身支持MQ功能，所以完全可以当做一个轻量级的队列服务来使用。对于RabbitMQ和Redis的入队和出队操作，各执行100万次，每10万次记录一次执行时间。测试数据分为128Bytes、512Bytes、1K和10K四个不同大小的数据。实验表明：入队时，当数据比较小时Redis的性能要高于RabbitMQ，而如果数据大小超过了10K，Redis则慢的无法忍受；出队时，无论数据大小，Redis都表现出非常好的性能，而RabbitMQ的出队性能则远低于Redis。

##### 3.3　ZeroMQ

ZeroMQ号称最快的消息队列系统，尤其针对大吞吐量的需求场景。ZeroMQ能够实现RabbitMQ不擅长的高级/复杂的队列，但是开发人员需要自己组合多种技术框架，技术上的复杂度是对这MQ能够应用成功的挑战。ZeroMQ具有一个独特的非中间件的模式，你不需要安装和运行一个消息服务器或中间件，因为你的应用程序将扮演这个服务器角色。你只需要简单的引用ZeroMQ程序库，可以使用NuGet安装，然后你就可以愉快的在应用程序之间发送消息了。但是ZeroMQ仅提供非持久性的队列，也就是说如果宕机，数据将会丢失。其中，Twitter的Storm 0.9.0以前的版本中默认使用ZeroMQ作为数据流的传输（Storm从0.9版本开始同时支持ZeroMQ和Netty作为传输模块）。

##### 3.4　ActiveMQ

ActiveMQ是Apache下的一个子项目。 类似于ZeroMQ，它能够以代理人和点对点的技术实现队列。同时类似于RabbitMQ，它少量代码就可以高效地实现高级应用场景。

##### 3.5　Kafka/Jafka

Kafka是Apache下的一个子项目，是一个高性能跨语言分布式发布/订阅消息队列系统，而Jafka是在Kafka之上孵化而来的，即Kafka的一个升级版。具有以下特性：快速持久化，可以在O(1)的系统开销下进行消息持久化；高吞吐，在一台普通的服务器上既可以达到10W/s的吞吐速率；完全的分布式系统，Broker、Producer、Consumer都原生自动支持分布式，自动实现负载均衡；支持Hadoop数据并行加载，对于像Hadoop的一样的日志数据和离线分析系统，但又要求实时处理的限制，这是一个可行的解决方案。Kafka通过Hadoop的并行加载机制统一了在线和离线的消息处理。Apache Kafka相对于ActiveMQ是一个非常轻量级的消息系统，除了性能非常好之外，还是一个工作良好的分布式系统。

[回到顶部](https://www.cnblogs.com/qingyunzong/p/9004509.html#_labelTop)

#### 四、Kafka中的术语解释

##### 4.1　概述

在深入理解Kafka之前，先介绍一下Kafka中的术语。下图展示了Kafka的相关术语以及之间的关系：

![img](https://images2018.cnblogs.com/blog/1228818/201805/1228818-20180507190731172-1317551019.png)

上图中一个topic配置了3个partition。Partition1有两个offset：0和1。Partition2有4个offset。Partition3有1个offset。副本的id和副本所在的机器的id恰好相同。

如果一个topic的副本数为3，那么Kafka将在集群中为每个partition创建3个相同的副本。集群中的每个broker存储一个或多个partition。多个producer和consumer可同时生产和消费数据。

##### 4.2　broker

Kafka 集群包含一个或多个服务器，服务器节点称为broker。

broker存储topic的数据。如果某topic有N个partition，集群有N个broker，那么每个broker存储该topic的一个partition。

如果某topic有N个partition，集群有(N+M)个broker，那么其中有N个broker存储该topic的一个partition，剩下的M个broker不存储该topic的partition数据。

如果某topic有N个partition，集群中broker数目少于N个，那么一个broker存储该topic的一个或多个partition。在实际生产环境中，尽量避免这种情况的发生，这种情况容易导致Kafka集群数据不均衡。

##### 4.3　Topic

每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。（物理上不同Topic的消息分开存储，逻辑上一个Topic的消息虽然保存于一个或多个broker上但用户只需指定消息的Topic即可生产或消费数据而不必关心数据存于何处）

类似于数据库的表名

##### 4.3　**Partition**

topic中的数据分割为一个或多个partition。每个topic至少有一个partition。每个partition中的数据使用多个segment文件存储。partition中的数据是有序的，不同partition间的数据丢失了数据的顺序。如果topic有多个partition，消费数据时就不能保证数据的顺序。在需要严格保证消息的消费顺序的场景下，需要将partition数目设为1。

##### 4.4　Producer

生产者即数据的发布者，该角色将消息发布到Kafka的topic中。broker接收到生产者发送的消息后，broker将该消息**追加**到当前用于追加数据的segment文件中。生产者发送的消息，存储到一个partition中，生产者也可以指定数据存储的partition。

##### 4.5　Consumer

消费者可以从broker中读取数据。消费者可以消费多个topic中的数据。

##### 4.6　Consumer Group

每个Consumer属于一个特定的Consumer Group（可为每个Consumer指定group name，若不指定group name则属于默认的group）。

##### 4.7　Leader

每个partition有多个副本，其中有且仅有一个作为Leader，Leader是当前负责数据的读写的partition。

##### 4.8　Follower

Follower跟随Leader，所有写请求都通过Leader路由，数据变更会广播给所有Follower，Follower与Leader保持数据同步。如果Leader失效，则从Follower中选举出一个新的Leader。当Follower与Leader挂掉、卡住或者同步太慢，leader会把这个follower从“in sync replicas”（ISR）列表中删除，重新创建一个Follower。

学习：https://www.cnblogs.com/qingyunzong/p/9004509.html

#### 1、介绍：

**kafka是一个分布式的信息流式处理的工具。**

**Kafka的特性:**

高吞吐量、低延迟每个topic可以分多个partition, consumer group 对partition进行consume操作。

可扩展性：kafka集群支持热扩展。

持久性、可靠性：消息被持久化到本地磁盘，并且支持数据备份防止数据丢失

容错性：允许集群中节点失败（若副本数量为n,则允许n-1个节点失败）。

高并发：支持数千个客户端同时读写。

**Kafka流程：**

Kafka中发布订阅的对象是topic。我们可以为每类数据创建一个topic，把向topic发布消息的客户端称作producer，从topic订阅消息的客户端称作consumer。Producers和consumers可以同时从多个topic读写数据。一个kafka集群由一个或多个broker服务器组成，它负责持久化和备份具体的kafka消息。

Producers往Brokers里面的指定Topic中写消息，Consumers从Brokers里面拉去指定Topic的消息，然后进行业务处理。

一个topic实际是由多个partition组成的，遇到瓶颈时，可以通过增加partition的数量来进行横向扩容。单个parition内是保证消息有序。

正常的topic相当于一个MQ的队列，发布者发送message必须指定topic，然后Kafka会根据接收到的message进行load balance，均匀的分布到topic的不同的partition上，一个消费者组要全部消费这个topic上的所有partition，所以一个消费者组如果多个消费者，那么这里面的消费者是不能消费到全部消息的。

订阅topic是以一个消费组来订阅的，一个消费组里面可以有多个消费者。同一个消费组中的两个消费者，不会同时消费一个partition。换句话来说，就是一个partition，只能被消费组里的一个消费者消费，但是可以同时被多个消费组消费。因此，如果消费组内的消费者如果比partition多的话，那么就会有个别消费者一直空闲。

**zookeeper作用：**

**zookeeper是为了解决分布式一致性问题的工具。**

kafka 很多说不需要安装zk的是因为他们都使用了kafka自带的zk，至于kafka为什么使用zk，你首先要知道zk的作用, 作为去中心化的集群模式。需要要消费者知道现在那些生产者（对于消费者而言，kafka就是生产者）是可用的。如果没了zk消费者如何知道呢？如果每次消费者在消费之前都去尝试连接生产者测试下是否连接成功，效率呢？所以kafka需要zk，在kafka的设计中就依赖了zk了。

安装kafka之前需要先安装zookeeper集群，虽然卡夫卡有自带的zk集群，但是建议还是使用单独的zk集群。

具体原因：

kafka使用zookeeper来实现动态的集群扩展，不需要更改客户端（producer和consumer）的配置。broker会在zookeeper注册并保持相关的元数据（topic，partition信息等）更新。而客户端会在zookeeper上注册相关的watcher。一旦zookeeper发生变化，客户端能及时感知并作出相应调整。这样就保证了添加或去除broker时，各broker间仍能自动实现负载均衡。这里的客户端指的是Kafka的消息生产端(Producer)和消息消费端(Consumer)·

Kafka使用zk的分布式协调服务，将生产者，消费者，消息储存（broker，用于存储信息，消息读写等）结合在一起。

同时借助zk，kafka能够将生产者，消费者和broker在内的所有组件在无状态的条件下建立起生产者和消费者的订阅关系，实现生产者的负载均衡。

\1. broker在zk中注册

kafka的每个broker（相当于一个节点，相当于一个机器）在启动时，都会在zk中注册，告诉zk其brokerid，在整个的集群中，[broker.id/brokers/ids，当节点失效时，zk就会删除该节点，就很方便的监控整个集群broker的变化，及时调整负载均衡。](https://link.zhihu.com/?target=http%3A//broker.id/brokers/ids%EF%BC%8C%E5%BD%93%E8%8A%82%E7%82%B9%E5%A4%B1%E6%95%88%E6%97%B6%EF%BC%8Czk%E5%B0%B1%E4%BC%9A%E5%88%A0%E9%99%A4%E8%AF%A5%E8%8A%82%E7%82%B9%EF%BC%8C%E5%B0%B1%E5%BE%88%E6%96%B9%E4%BE%BF%E7%9A%84%E7%9B%91%E6%8E%A7%E6%95%B4%E4%B8%AA%E9%9B%86%E7%BE%A4broker%E7%9A%84%E5%8F%98%E5%8C%96%EF%BC%8C%E5%8F%8A%E6%97%B6%E8%B0%83%E6%95%B4%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E3%80%82)

\2. topic在zk中注册

在kafka中可以定义很多个topic，每个topic又被分为很多个分区。一般情况下，每个分区独立在存在一个broker上，所有的这些topic和broker的对应关系都有zk进行维护

\3. consumer(消费者)在zk中注册

所以，Zookeeper作用：管理broker、consumer。

#### 2、kafka集群搭建

**环境：**

JDK：1.8.0_221

ZK：3.4.14

Kafka：0.11.0.0

Scala：2.11.8

1. **由于ZK、Kakfa运行需要依赖JVM环境，需要先安装JDK**（网上很多，不再描述）

[https://www.oracle.com/java/technologies/javase-downloads.htmlwww.oracle.com](https://link.zhihu.com/?target=https%3A//www.oracle.com/java/technologies/javase-downloads.html)

![img](https://pic3.zhimg.com/80/v2-6dd903b161c87c33f5e803eccea5cfea_720w.png)

**2.ZK安装**

zooKeeper是作为分布式协调服务，是不需要依赖于Hadoop的环境，也可以为其他的分布式环境提供服务。

[Index of /apache/zookeeper/zookeeper-3.4.14mirror.bit.edu.cn](https://link.zhihu.com/?target=https%3A//mirror.bit.edu.cn/apache/zookeeper/zookeeper-3.4.14/)

解压：

```bash
gunzip zookeeper-3.4.14.tar.gz
tar -zxvf zookeeper-3.4.14.tar
```

配置：

由于是单点模式，所以配置server.1=本地IP,或者不配置server默认localhost

```text
进入conf文件夹
mv zoo_sample.cfg zoo.cfg

修改zoo.cfg的配置

#tickTime: zookeeper中使用的基本时间单位, 毫秒值.
#dataDir: 数据目录. 可以是任意目录.
#initLimit: 配置leader节点和follower节点启动并且完成数据同步的时间.
#syncLimit:leader节点和follower节点心跳检测的最大延迟时间.
#clientPort: 监听client连接的端口号.
#server.x中的“x”表示ZooKeeper Server进程的标识   
例如：
clientPort=2181

server.1=localhost:2888:3888

server.2=localhost:2889:3889

server.3=localhost:2890:3890
```

![img](https://pic3.zhimg.com/80/v2-625e46a3edf7ea2fea5953a1e2751792_720w.jpg)

启动：

./zkServer.sh start

![img](https://pic4.zhimg.com/80/v2-60ec593e8b32855cddaa699fb2363473_720w.png)

验证：

./zkServer.sh status

![img](https://pic4.zhimg.com/80/v2-a63b480123c5cc41b8e3fac9598008e3_720w.png)

连接：

./zkCli.sh -server localhost

![img](https://pic2.zhimg.com/80/v2-d54278e3193492c5a3789ed374091dc1_720w.jpg)

**3、Kafka集群搭建**

](https://link.zhihu.com/?target=http%3A//kafka.apache.org/downloads)

![img](https://pic1.zhimg.com/80/v2-e5afeb42f584f79b90feba738166bc48_720w.jpg)

修改配置：

```bash
log.dirs=/Users/gaowei/Package/kafka_2.11-0.11.0.0/log
zookeeper.connect=自己的IP(或者localhost):2181
listeners=PLAINTEXT://自己的IP(或者localhost):9092
advertised.listeners=PLAINTEXT://自己的IP(或者localhost):9092
```

![img](https://pic1.zhimg.com/80/v2-4e6d09263d716571ff3336499720aecc_720w.jpg)

启动

```text
./kafka-server-start.sh ./../config/server.properties &
```

![img](https://pic2.zhimg.com/80/v2-5e3d1d6ba2b86ec5cec0073023975775_720w.jpg)

后台启动

~~~shell
首先进入kafka的bin内
然后运行

sh kafka-server-start.sh -daemon ../config/server.properties

就可以使kafka后台运行了
~~~



测试：

```text
1.创建topic:
bin/kafka-topics.sh  --create  --zookeeper localhost:2181  --replication-factor 1  --partitions 1  --topic test
2.查看topic列表：
bin/kafka-topics.sh  --list  --zookeeper localhost:2181  
3.生成消息：
bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test 
4.消费消息(从头消费)：
bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic test  --from-beginning
```

创建topic:

![img](https://pic4.zhimg.com/80/v2-0ca942b28cc666fb959606ac0519aa03_720w.png)

生产者：

![img](https://pic2.zhimg.com/80/v2-99b4c0e510a4fd9298208a33d70c5365_720w.png)

消费者：

![img](https://pic1.zhimg.com/80/v2-352f62c3fe19440e6d76d33e72a71230_720w.jpg)

出现报错原因：

kafka_2.11-0.10.2.1升级了消费者命令，新版本采用bootstrap-server参数，而不是之前的zookeeper参数。其实报错里面已经很清楚了(新版本指的是kafka 0.8.0之后的版本)。

修改消费者命令：

```bash
./kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning
```

![img](https://pic2.zhimg.com/80/v2-118dfcb114dc39d7d65d1ae120a98c95_720w.jpg)



3. #### windows 下配置 kafka 

   https://www.cnblogs.com/shej123/p/10277653.html

### 5.26  Kubernetes（K8S）

[**Kubernetes**](https://www.kubernetes.org.cn/)是一个开源的，用于管理云平台中多个主机上的容器化的应用，Kubernetes的目标是让部署容器化的应用简单并且高效（powerful）,Kubernetes提供了应用部署，规划，更新，维护的一种机制。

Kubernetes一个核心的特点就是能够自主的管理容器来保证云平台中的容器按照用户的期望状态运行着（比如用户想让apache一直运行，用户不需要关心怎么去做，Kubernetes会自动去监控，然后去重启，新建，总之，让apache一直提供服务），管理员可以加载一个微型服务，让规划器来找到合适的位置，同时，Kubernetes也系统提升工具以及人性化方面，让用户能够方便的部署自己的应用（就像canary deployments）。

现在Kubernetes着重于不间断的服务状态（比如web服务器或者缓存服务器）和原生云平台应用（Nosql）,在不久的将来会支持各种生产云平台中的各种服务，例如，分批，工作流，以及传统数据库。

在Kubenetes中，所有的容器均在[**Pod**](https://www.kubernetes.org.cn/tags/pod)中运行,一个Pod可以承载一个或者多个相关的容器，在后边的案例中，同一个Pod中的容器会部署在同一个物理机器上并且能够共享资源。一个Pod也可以包含O个或者多个磁盘卷组（volumes）,这些卷组将会以目录的形式提供给一个容器，或者被所有Pod中的容器共享，对于用户创建的每个Pod,系统会自动选择那个健康并且有足够容量的机器，然后创建类似容器的容器,当容器创建失败的时候，容器会被node agent自动的重启,这个node agent叫kubelet,但是，如果是Pod失败或者机器，它不会自动的转移并且启动，除非用户定义了 replication controller。

用户可以自己创建并管理Pod,Kubernetes将这些操作简化为两个操作：基于相同的Pod配置文件部署多个Pod复制品；创建可替代的Pod当一个Pod挂了或者机器挂了的时候。而Kubernetes API中负责来重新启动，迁移等行为的部分叫做“replication controller”，它根据一个模板生成了一个Pod,然后系统就根据用户的需求创建了许多冗余，这些冗余的Pod组成了一个整个应用，或者服务，或者服务中的一层。一旦一个Pod被创建，系统就会不停的监控Pod的健康情况以及Pod所在主机的健康情况，如果这个Pod因为软件原因挂掉了或者所在的机器挂掉了，replication controller 会自动在一个健康的机器上创建一个一摸一样的Pod,来维持原来的Pod冗余状态不变，一个应用的多个Pod可以共享一个机器。

我们经常需要选中一组Pod，例如，我们要限制一组Pod的某些操作，或者查询某组Pod的状态，作为Kubernetes的基本机制，用户可以给Kubernetes Api中的任何对象贴上一组 key:value的标签，然后，我们就可以通过标签来选择一组相关的Kubernetes Api 对象，然后去执行一些特定的操作，每个资源额外拥有一组（很多） keys 和 values,然后外部的工具可以使用这些keys和vlues值进行对象的检索，这些Map叫做annotations（注释）。

Kubernetes支持一种特殊的网络模型，Kubernetes创建了一个地址空间，并且不动态的分配端口，它可以允许用户选择任何想使用的端口，为了实现这个功能，它为每个Pod分配IP地址。

现代互联网应用一般都会包含多层服务构成，比如web前台空间与用来存储键值对的内存服务器以及对应的存储服务，为了更好的服务于这样的架构，Kubernetes提供了服务的抽象，并提供了固定的IP地址和DNS名称，而这些与一系列Pod进行动态关联，这些都通过之前提到的标签进行关联，所以我们可以关联任何我们想关联的Pod，当一个Pod中的容器访问这个地址的时候，这个请求会被转发到本地代理（kube proxy）,每台机器上均有一个本地代理，然后被转发到相应的后端容器。Kubernetes通过一种轮训机制选择相应的后端容器，这些动态的Pod被替换的时候,Kube proxy时刻追踪着，所以，服务的 IP地址（dns名称），从来不变。

所有Kubernetes中的资源，比如Pod,都通过一个叫URI的东西来区分，这个URI有一个UID,URI的重要组成部分是：对象的类型（比如pod），对象的名字，对象的命名空间，对于特殊的对象类型，在同一个命名空间内，所有的名字都是不同的，在对象只提供名称，不提供命名空间的情况下，这种情况是假定是默认的命名空间。UID是时间和空间上的唯一。

官方网站:https://www.kubernetes.org.cn/



k8s全称kubernetes，这个名字大家应该都不陌生，k8s是为容器服务而生的一个可移植容器的编排管理工具，越来越多的公司正在拥抱k8s，并且当前k8s已经主导了云业务流程，推动了微服务架构等热门技术的普及和落地，正在如火如荼的发展。那么称霸容器领域的k8s究竟是有什么魔力呢？

首先，我们从容器技术谈起，在容器技术之前，大家开发用虚拟机比较多，比如vmware和openstack，我们可以使用虚拟机在我们的操作系统中模拟出多台子电脑（Linux），子电脑之间是相互隔离的，但是虚拟机对于开发和运维人员而言，存在启动慢，占用空间大，不易迁移的缺点。举一个我亲身经历过的场景吧，之前在vmware中开发了一个线下平台，为了保证每次能够顺利使用，我们就把这个虚拟机导出为OVF，然后随身携带，用的时候在服务器中部署，这里就充分体现了虚拟机的缺点。

接着，容器化技术应运而生，它不需要虚拟出整个操作系统，只需要虚拟一个小规模的环境即可，而且启动速度很快，除了运行其中应用以外，基本不消耗额外的系统资源。Docker是应用最为广泛的容器技术，通过打包镜像，启动容器来创建一个服务。但是随着应用越来越复杂，容器的数量也越来越多，由此衍生了管理运维容器的重大问题，而且随着云计算的发展，云端最大的挑战，容器在漂移。在此业务驱动下，k8s问世，提出了一套全新的基于容器技术的分布式架构领先方案，在整个容器技术领域的发展是一个重大突破与创新。

那么，K8S实现了什么？

从架构设计层面，我们关注的可用性，伸缩性都可以结合k8s得到很好的解决，如果你想使用微服务架构，搭配k8s，真的是完美，再从部署运维层面，服务部署，服务监控，应用扩容和故障处理，k8s都提供了很好的解决方案。

具体来说，主要包括以下几点：

1. 服务发现与调度
2. 负载均衡
3. 服务自愈
4. 服务弹性扩容
5. 横向扩容
6. 存储卷挂载

总而言之，k8s可以使我们应用的部署和运维更加方便。

最后，我们看下k8s的架构：

![preview](https://pic2.zhimg.com/v2-499cc023903440be0fee5cf63b689c89_r.jpg)

k8s集群由Master节点和Node（Worker）节点组成。

**Master节点**

Master节点指的是集群控制节点，管理和控制整个集群，基本上k8s的所有控制命令都发给它，它负责具体的执行过程。在Master上主要运行着：

1. Kubernetes Controller Manager（kube-controller-manager）：k8s中所有资源对象的自动化控制中心，维护管理集群的状态，比如故障检测，自动扩展，滚动更新等。
2. Kubernetes Scheduler（kube-scheduler）： 负责资源调度，按照预定的调度策略将Pod调度到相应的机器上。
3. etcd：保存整个集群的状态。

**Node节点**

除了master以外的节点被称为Node或者Worker节点，可以在master中使用命令 `kubectl get nodes`查看集群中的node节点。每个Node都会被Master分配一些工作负载（Docker容器），当某个Node宕机时，该节点上的工作负载就会被Master自动转移到其它节点上。在Node上主要运行着：

1. kubelet：负责Pod对应的容器的创建、启停等任务，同时与Master密切协作，实现集群管理的基本功能
2. kube-proxy：实现service的通信与负载均衡
3. docker（Docker Engine）：Docker引擎，负责本机的容器创建和管理

### 5.27  ElasticSearch

##### windows 下安装elasticsearch

ElasticSearch，简称ES， 是一个基于Lucene的分布式全文搜索服务器，和SQL Server的全文索引（Fulltext Index）有点类似，都是基于分词和分段的全文搜索引擎，具有分词，同义词，词干查询的功能，但是ES天生具有分布式和实时的属性。

 

##### **一，安装Java SE环境**

安装Java JDK和配置JAVA_HOME环境变量：

1，从[Java Se Download](http://www.oracle.com/technetwork/java/javase/downloads/index.html)下载和安装Java SE开发包，当前最新版本是Java SE 10.0.2

2，安装完成之后，需要在服务器上创建**JAVA_HOME**环境变量，设置变量值是：D:\Program Files\Java\jdk-10.0.2

3， 禁用Java JDK的自动更新，避免ElasticSearch收到JRE版本影响。

在控制面板（Control Panel）上点击Java图标，打开Java控制面板，切换到Update 选项卡（tab），取消选择“Check for Updates Automatically”，禁止系统自动进行JDR的自动更新。

切换到Advanced选项卡，设置Application Installation为Never install.

 

##### **二，安装ElasticSearch**

**1，从官方下载中心 [ElasticSearch Download](https://www.elastic.co/downloads/elasticsearch) 下载ElasticSearch安装包，当前最新版本是6.3.1**

2，将zip文件解压到D盘，进入 **D:\elasticsearch-6.3.1\bin** 目录，双击执行 **elasticsearch.bat，该**脚本文件执行 ElasticSearch 启动程序

3，打开浏览器，输入 **http://localhost:9200** ，显式以下画面，说明ES安装成功。

​    

   ![img](https://images2018.cnblogs.com/blog/1420905/201807/1420905-20180718110729431-393253622.png)

##### **三，安装head插件**

为了便于管理ES，可使用head插件，这是最初级的管理工具，在浏览器中显示ES集群，索引等信息，十分简便好用。 

1, 首先要安装Ｎodejs，下载地址：https://nodejs.org/en/

2, 解压  [elasticsearch-head-master](https://codeload.github.com/mobz/elasticsearch-head/zip/master) 到 **D:\elasticsearch-6.3.1****\elasticsearch-head-master**, 

3, 配置 elasticsearch-6.3.1\config\**elasticsearch.yml**

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

```
# 设成0.0.0.0让任何人都可以访问，线上服务不要这样设置。
#
network.host: 0.0.0.0
http.port: 9200
# 解决elasticsearch-head 集群健康值: 未连接问题
http.cors.enabled: true
http.cors.allow-origin: "*"
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

4, 在elasticsearch-head-master目录下执行 **npm install -g grunt-cli**

grunt 是基于Node.js的项目构建工具，可以进行打包压缩、测试、执行等等的工作，head插件就是通过grunt启动。

5, 在elasticsearch-head-master目录下执行**npm install** 安装依赖

6, 修改elasticsearch-head-master配置。

修改服务器监听地址:**Gruntfile.js** 

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

```
        connect: {
            server: {
                options: {
                    port: 9100,
                    base: '.',
                    keepalive: true,
                    hostname: '*'
                }
            }
        }
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

7, 启动运行head服务, 执行 **grunt server** 命令。

8, 访问head管理页面，地址:http://localhost:9100/ 

![img](https://images2018.cnblogs.com/blog/1420905/201807/1420905-20180718113012464-410609290.png)

 **四， 配置EalsticSearch为Windows服务**

切换到ElasticSearch的bin目录执行相应命令：

安装   elasticsearch-service.bat **install**

**删除   elasticsearch-service.bat** **remove**

启动   elasticsearch-service.bat ***\*start\****

停止   elasticsearch-service.bat **stop**

###### 

#####  *** Keep learning and growing. ***



#### Elasticsearch+kibana安装windows+ liunx

什么是Kibana?
Kibana 是一个设计出来用于和 Elasticsearch 一起使用的开源的分析与可视化平台，可以用 kibana 搜索、查看、交互存放在Elasticsearch 索引里的数据，使用各种不同的图表、表格、地图等展示高级数据分析与可视化，基于浏览器的接口使你能快速创建和分享实时展现Elasticsearch查询变化的动态仪表盘，让大量数据变得简单，容易理解。

##### Kibana 7.* 安装条件

（适用windows 10 ，64位）

1. 保证安装了JDK
2. 保证安装node
3. 保证安装了Elasticsearch

##### JDK的安装：

点击[JDK官网下载](https://www.oracle.com/technetwork/java/javase/downloads/)

选择对应系统的安装包下载安装

（window10*64位操作系统）下载的版本如下图所示：

![img](https://img2018.cnblogs.com/i-beta/1432988/201912/1432988-20191203111223307-1146501561.png)

下载完毕之后双击安装，安装完毕之后进行环境变量的配置。

右键“我的电脑”---“属性”---“高级系统设置”---“环境变量”，进入环境变量的配置界面：

（2）在系统变量中“新建”环境变量 JAVA_HOME

![img](https://img-blog.csdn.net/2018072514432882?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNDcyNzIzOA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

（3）向PATH(在系统目录中找到PATH并双击)中添加 

![img](https://img2018.cnblogs.com/i-beta/1432988/201912/1432988-20191203112834878-1799079018.png)

（4）检查是否安装成功，同时按下键盘win+R键，打开运行窗口。在窗口中输入“cmd”，按“回车键（Enter）”或点击“确定”，进行测试。

- 输入java见如下显示：

![img](https://img2020.cnblogs.com/i-beta/1432988/202003/1432988-20200326102301039-999608260.png)

 

则代表成功安装。

node的安装：
点击[node官网下载](https://nodejs.org/en/)

![img](https://img2018.cnblogs.com/i-beta/1432988/201912/1432988-20191203140022816-1957030942.png)

下载双击安装

确保安装成功：输入 

node -v

![img](https://img2018.cnblogs.com/i-beta/1432988/201912/1432988-20191203140131283-106987478.png)

##### Elasticsearch的安装：

- 点击[Elasticsearch官网下载](https://www.elastic.co/cn/downloads/elasticsearch) 
- 注意这个版本号！！！
- 值得注意的是，elasticsearch的版本和kibana的版本必须一致，才可以正确运行。

![img](https://img2018.cnblogs.com/i-beta/1432988/201912/1432988-20191203140303871-680797916.png)

- 解压
- 进入bin目录，双击elasticsearch.bat（第一种方式）：等待启动
- 通过cmd的方式进入bin目录，运行elasticsearch.bat install 安装服务（第二种方式）：打开elasticsearch服务
- 配置文件可以自定义可先用默认启动，跳过
- 打开http://localhost:9200/，如果发现显示下图内容，则启动成功。

![img](https://img2018.cnblogs.com/i-beta/1432988/201912/1432988-20191203144136921-1785245649.png)

##### Kibana 的安装：

- 点击

  kibana官网下载

   ![img](https://img2018.cnblogs.com/i-beta/1432988/201912/1432988-20191203144847871-1905674228.png)

   图为下载的版本7.5.0，kibana的版本和elasticsearch的版本和必须一致。

- 修改配置（可以省略）

- 打开下图的路径文件kibana.yml（可以通过记事本方式） 

   ![img](https://img2018.cnblogs.com/i-beta/1432988/201912/1432988-20191203145040523-528876499.png)

- 设置elasticsearch.url为启动的elasticsearch（http://localhost:9200/）（其实按照默认可以不用修改配置文件）  

- ![img](https://img2018.cnblogs.com/i-beta/1432988/201912/1432988-20191203145131967-790174406.png)

- 进入kibana的bin目录，双击kibana.bat（第一种方式）

- 通过cmd的方式进入kibana的bin目录，运行kibana.bat（第二种方式）；

- 访问：http://localhost:5601，出现以下界面即完成安装。

- ![img](https://img2018.cnblogs.com/i-beta/1432988/201912/1432988-20191203145223648-935452405.png)

##### liunx安装

过程基本上一致，只记录下关键点

###### 1.1 选择 liunx包 并解压缩安装

```
https://www.elastic.co/cn/downloads/elasticsearch
tar -xzvf elasticsearch-7.5.0-linux-x86_64.tar.gz
mv  elasticsearch-7.5.0   elasticsearch
```

###### 1.2 修改jvm配置

```
cd  elasticsearch/config
vim  jvm.options  # 修改为内存的一半  机器为32 我就配置了16
```

　　-Xms16g
　　-Xmx16g

###### 1.3 配置集群设置

vim elasticsearch.yml

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

```
cluster.name: es    集群名称，相同名称为一个集群
node.name: node_1   节点名称，集群模式下每个节点名称唯一
node.master: true     当前节点是否可以被选举为master节点，是：true、否：false
node.data: true   当前节点是否用于存储数据，是：true、否：false  
path.data: /data,/data1    索引数据存放的位置
path.logs: /usr/local/elasticsearch/logs  日志文件存放的位置
network.host: 0.0.0.0   监听地址，用于访问该es
http.port: 9190  es对外提供的http端口，默认 9200
discovery.seed_hosts: ["x.x.x.x", "x.x.x.x","x.x.x.x"]   写入候选主节点的设备地址，在开启服务后可以被选为主节点
cluster.initial_master_nodes: ["x.x.x.x", "x.x.x.x", "x.x.x.x"] 初始化一个新的集群时需要此配置来选举master 或者写入节点名字
http.cors.enabled: true   是否支持跨域，是：true，在使用head插件时需要此配置
http.cors.allow-origin: "*"  "*" 表示支持所有域名indices.fielddata.cache.size: 16g
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

###### 1.4 创建用户 不能用root启动es

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

```
useradd  elasticsearch 
passwd   elasticsearch

# 添加权限
chown -R elasticsearch:elasticsearch  /usr/local/elasticsearch  
chown -R elasticsearch:elasticsearch  /data
chown -R elasticsearch:elasticsearch  /data1
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

###### 1.5 系统优化

etc/security/limits.conf，增加最大线程个数

```
vim /etc/security/limits.conf
* soft nofile 65536
* hard nofile 65536
* soft nproc 32000
* hard nproc 32000
* hard memlock unlimited
* soft memlock unlimited
```

vim /etc/systemd/system.conf

```
DefaultLimitNOFILE=65536
DefaultLimitNPROC=32000
DefaultLimitMEMLOCK=infinity
/bin/systemctl daemon-reload    # 使其生效
```

vim /etc/sysctl.conf

```
vm.max_map_count=655360
sysctl -p
```

###### 1.6 kibana

下载压缩

```
tar -xzvf kibana-7.5.0-linux-x86_64.tar.gz
mv kibana-7.5.0-linux-x86_64 kibana
```

配置文件

vim kibana.yml

```
server.port: 9191   
server.host: "0.0.0.0"
# es服务器集群链接和端口
elasticsearch.hosts: ["http://x.17.75.37:x", "http://x.17.75.38:x", "http://x.17.75.36:x"]
# 中文设置
i18n.locale: "zh-CN" 
```

权限设置或者直接用root启动

```
chown -R elasticsearch:elasticsearch /usr/local/kibana

nohup ./kibana --allow-root &
```

##### 集群密码添加

###### 2.1 创建证书文件

主节点一台操作

cd /usr/local/elasticsearch/

./bin/elasticsearch-certutil ca
两次回车
./bin/elasticsearch-certutil cert --ca elastic-stack-ca.p12
三次回车

```
mkdir config/certs        # 放置证书位置
mv elastic-*.p12 config/certs/      
chown -R elasticsearch:elasticsearch config/certs/
```

再把证书文件 elastic-certificates.p12 复制到其他master节点并赋予权限。
scp或者ftp等

###### 2.2 修改配置

所有节点配置完后重启 elasticsearch 

vim elasticsearch.yml  

```
xpack.security.enabled: true
xpack.security.transport.ssl.enabled: true
xpack.security.transport.ssl.verification_mode: certificate
xpack.security.transport.ssl.keystore.path: certs/elastic-certificates.p12
xpack.security.transport.ssl.truststore.path: certs/elastic-certificates.p12
```

###### 2.3 生成客户端证书

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

cd /usr/local/elasticsearch

bin/elasticsearch-certutil cert --ca \
config/certs/elastic-stack-ca.p12 \
-name "CN=esuser,OU=dev,DC=weqhealth,DC=com"

回车
client.p12
回车

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

拆分证书

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

```
mv client.p12 config/certs/
cd config/certs/

openssl pkcs12 -in client.p12 -nocerts -nodes > client-key.pem
openssl pkcs12 -in client.p12 -clcerts -nokeys  > client.crt
openssl pkcs12 -in client.p12 -cacerts -nokeys -chain > client-ca.crt

chown elasticsearch:elasticsearch client*
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

###### 2.4 设置默认密码

主节点一台操作(启动es的账户)

注：如果之前运行的集群，请删掉elasticsearch.keystore 再启动后初始化密码

```
bin/elasticsearch-setup-passwords interactive
```

分别设置 elastic、apm_system、kibana、logstash_system、beats_system、remote_monitoring_user账号的密码。（密码设置最好相同）

###### 2.5 kibana中添加配置

修改 kibana.yml 文件

```
elasticsearch.username: "kibana"
elasticsearch.password: "password"
```

然后用超级管理员账号 elastic 登入到 kibana。在kibana中设置角色和账号，也可以修改账号密码。

###### 2.6 验证

head  kibana curl 都可验证

#### 禁止使用虚拟内存设置

3.1 禁止系统虚拟内存

```
swapoff -a 　　关闭虚拟内存（释放）
swapon -a 　　 打开虚拟内存
swapon    /path/file   开启swapoff   /path/file    关闭
```

3.2 添加es配置

```
bootstrap.memory_lock: true
```

这个配置的意义：锁定物理内存地址，防止es内存被交换出去，也就是避免es使用swap交换分区，频繁的交换，会导致IOPS变高。



### 5.28 LogStash

最新在研究elastic stack (elk) ：

logstash 安装，下载最新版本的logstash: [点击打开链接](https://www.elastic.co/fr/downloads/logstash)

解压到磁盘根目录下：在logstash>bin 

1、目录下创建：logstash.conf

2、输入内容:



```html
input {
    stdin{
    }
} 

output {
    stdout{
    }
}

```

logstash -f logstash.conf

![img](https://img-blog.csdn.net/20180203095617388?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveHV5YW5odWl3ZWxjb21l/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)



![img](https://img-blog.csdn.net/20180203095649180?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveHV5YW5odWl3ZWxjb21l/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)





——

### 5.29 RockerMQ

1.介绍

[RocketMQ](https://rocketmq.apache.org/) 是一款开源的分布式消息系统，基于高可用分布式集群技术，提供低延时的、高可靠的消息发布与订阅服务。同时，广泛应用于多个领域，包括异步通信解耦、企业解决方案、金融支付、电信、电子商务、快递物流、广告营销、社交、即时通信、移动应用、手游、视频、物联网、车联网等。

具有以下特点：

- 能够保证严格的消息顺序
- 提供丰富的消息拉取模式
- 高效的订阅者水平扩展能力
- 实时的消息订阅机制
- 亿级消息堆积能力

### RocketMQ 基本使用

- 下载 RocketMQ

下载 [RocketMQ最新的二进制文件](https://www.apache.org/dyn/closer.cgi?path=rocketmq/4.3.2/rocketmq-all-4.3.2-bin-release.zip)，并解压

解压后的目录结构如下：

~~~conf
apache-rocketmq
├── LICENSE
├── NOTICE
├── README.md
├── benchmark
├── bin
├── conf
└── lib
~~~

- 启动 NameServer

```
nohup sh bin/mqnamesrv &
tail -f ~/logs/rocketmqlogs/namesrv.log
```

- 启动 Broker

```
nohup sh bin/mqbroker -n localhost:9876 &
tail -f ~/logs/rocketmqlogs/broker.log
```

- 发送、接收消息

发送消息：

```
sh bin/tools.sh org.apache.rocketmq.example.quickstart.Producer
```

发送成功后显示：`SendResult [sendStatus=SEND_OK, msgId= …`

接收消息：

```
sh bin/tools.sh org.apache.rocketmq.example.quickstart.Consumer
```

接收成功后显示：`ConsumeMessageThread_%d Receive New Messages: [MessageExt…`

- 关闭 Server

```
sh bin/mqshutdown broker
sh bin/mqshutdown namesrv
```

官方文档：https://github.com/alibaba/spring-cloud-alibaba/wiki/RocketMQ

## 六：底层学习

### 6.1 HashMap底层学习

### 6.2 Spring 源码学习

### 6.3 Mybatis源码学习

### 6.4  SpringBoot源码学习

## 七：算法学习

### 算法的定义及特性

在数学和计算机科学/算学之中，算法/演算法/算则法（algorithm）为一个计算的具体步骤，常用于计算、数据处理和自动推理。精确而言，算法是一个表示为有限长列表的有效方法。算法应包含清晰定义的指令用于计算函数。

算法中的指令描述的是一个计算，当其运行时能从一个初始状态和初始输入（可能为空）开始，经过一系列有限而清晰定义的状态最终产生输出并停止于一个终态。一个状态到另一个状态的转移不一定是确定的。随机化算法在内的一些算法，包含了一些随机输入。

形式化算法的概念部分源自尝试解决希尔伯特提出的判定问题，并在其后尝试定义有效可计算性或者有效方法中成形。这些尝试包括库尔特·哥德尔、雅克·埃尔布朗和斯蒂芬·科尔·克莱尼分别于1930年、1934年和1935年提出的递归函数，阿隆佐·邱奇于1936年提出的λ演算，1936年埃米尔·莱昂·珀斯特的Formulation 1和艾伦·图灵1937年提出的图灵机。即使在当前，依然常有直觉想法难以定义为形式化算法的情况。

一个算法应该具有以下五个重要的特征：

有穷性（Finiteness）算法的有穷性是指算法必须能在执行有限个步骤之后终止；

确切性(Definiteness)算法的每一步骤必须有确切的定义；

输入项(Input)一个算法有0个或多个输入，以刻画运算对象的初始情况，所谓0个输入是指算法本身定出了初始条件；

输出项(Output)一个算法有一个或多个输出，以反映对输入数据加工后的结果。没有输出的算法是毫无意义的；

可行性(Effectiveness)算法中执行的任何计算步骤都是可以被分解为基本的可执行的操作步，即每个计算步都可以在有限时间内完成（也称之为有效性）。

02算法的设计

**设计原则**

正确性算法的正确性是指算法至少应该具有输入，输出和加工处理无歧义，能正确反映问题的需求，能够得到问题的正确答案。

算法正确大体分为四个层次：

\1. 算法程序没有语法的错误。

\2. 算法程序对于合法的输入数据能够产生满足要求的输出的结果。

\3. 算法程序对于非法的输入数据能够得出满足规格说明的结果。

\4. 算法程序对于精心选择的，甚至刁难的测试数据都有满足要求的输出结果。

可读性可读性：算法设计的另一个目的是为了便于阅读，理解和交流。

写代码的目的一是为了计算机执行，另一个为了便于他人阅读，让人理解和交流。

键壮性当输入数据不合法时，算法也能做出相关处理，而不是产生异常或莫名其妙的结果。

时间效率高和存储量低**设计方法**

1）、递归和递推。递归和递推是学习算法设计的第一步。递归算法是把大问题分解成相对较小的问题的过程，而递推就是从小问题逐步推导出大问题的过程。无论递归还是递推，都应该有初始状态。

2）、搜索、枚举及优化剪枝。搜索在所有算法中既是最简单也是最复杂的算法。说它简单，是因为算法本身并不复杂，实现容易；说它最复杂，是因为要对搜索的范围进行一定的控制，不然就会出现超时等问题。搜索技术主要包括广度优先搜索和深度优先搜索。当其余算法都无法对问题进行求解时，搜索或许是唯一可用的方法。搜索是对问题的解空间进行遍历的过程。有时问题解空间相当庞大，完全遍历解空间是不现实的，此时就必须充分发掘问题所包含的约束条件，在搜索过程中应用这些条件进行剪枝，从而减少搜索量。

3）、动态规划（简称DP）。动态规划的特点是能够把很复杂的问题分解成一个个阶段来处理的递推方法，动态规划必须符合两个特点：无后效性（一个状态的抉择不会影响到更大问题的状态的抉择）及最优化原理（一个大问题的最优性必须建立在其子问题的最优性之上）。动态规划是竞赛中经常出现的的类型，而且变化很大（有线性DP，环形DP，树形DP等），难易跨度大，技巧性强，甚至还有DP的优化等问题。

4）、贪心。贪心算法是所谓的“只顾眼前利益”的算法。其具体策略是并不从整体最优上加以考虑，而是选取某种意义下的局部最优解。当然使用贪心算法时，要使得到的结果也是整体最优的。

5）、分治、构造等。分治就是把问题分成若干子问题，然后“分而治之”；构造是指按照一定的规则产生解决问题的方法。这两种算法都是在合理的分析题目后，通过一定的规律性推导，从而解决问题。快速排序可以认为是利用了分治法。

03算法效率的度量方法

**事后统计方法**

这种方法主要是通过设计好的测试程序和数据,利用计算机对不同算法编制的程序的运行时间进行时间比较,从而确定算法效率的高低。

缺陷必须根据算法提前编写好测试程序,花费时间精力较大。

运行时间严重依赖硬件以及软件等环境因素,可能会影响算法本身的优劣。

算法的测试数据设计困难,并且程序的运行时间和测试数据的规模有很大关系。

总结事后统计法虽然直观,但是实际困难且缺陷多,很少使用。

事前分析估算方法

在计算机程序编程前，依据统计方法对算法进行估算。

一个用高级程序语言编写的程序在计算机上运行时所消耗的时间取决于下列因素：

算法采用的策略，方法(算法优劣的根本)

编译产生的代码质量(软件)

问题的输入规模

机器执行指令的速度(硬件)

一个程序的运行时间依赖于算法的好坏和问题的输入规模,所谓问题输入规模的是指输入量的多少。

在分析程序的分析时间时，最重要的是把程序看成是独立于程序设计语言的算法或者是一系列步骤。

分析一个算法的运行时间时，重要的是把基本操作的数量与输入规模关联起来，即基本操作的数量必须表示成输入规模的函数。随着问题输入规模（n）越来越大，它们在时间效率上的差异也就越来越大.

\#include <stdio.h>

/**

\* 1-100求和

\* @param end

\* @return

*/

int sum(int end){

int result = 0;

for (int i=1;i<=end;i++){

result += i;

}

return result;

}

/**

\* 高斯算法

\* @param end

\* @return

*/

int simpleSum(int end){

int result = (1+end)*end/2;

return result;

}

int main() {

int res = sum(100);

printf("1+2+3+...+100=%d\n",res);

int res2 = simpleSum(100);

printf("1+2+3+...+100=%d\n",res2);

return 0;

}

这两种求1-100以内和的算法随着end数值的增大(不考虑int溢出),算法优劣不言而喻。

04算法的渐进增长

先看几组算法的变化:

A

![img](http://pics7.baidu.com/feed/dbb44aed2e738bd4ea892f0675e3bbd0267ff9c8.jpeg?token=d671def4663dcfd42cbf05f2d77e6308&s=58883472190B504D5EF5F1DA0300C0B1)

当n=1时, C要优于A(C的执行次数要比A少),随着n的增加,A要优于C.所以，综上来说A要优于C.

函数的渐近增长：给定两个函数f(n)和g(n)，如果存在一个整数N，使得对于所有的n > N，f(n)总是比g(n)大，那么，我们说f(n)的渐近增长快于g(n)。

随着n的不断增大，A,B,C,D算法的常数对总体的执行次数影响可以忽略。

B

![img](http://pics4.baidu.com/feed/86d6277f9e2f070850308de13b4c849fa801f28d.jpeg?token=417697b272b548115ab03591c583f739&s=58883C721312546D1EDD91CA0300E0B1)

C

![img](http://t11.baidu.com/it/u=3458919514,3676025012&fm=173&app=25&f=JPG?w=516&h=627&s=5AA83462491B664F1E5D94DA0300E0B1)

观察发现,最高次幂大的函数,随着n的增大,n的最高次幂大的结果的变化也大。

**时间复杂度**

一般情况下，算法中基本操作重复执行的次数是问题规模n的某个函数，用T(n)表示，若有某个辅助函数f(n),使得当n趋近于无穷大时，T(n)/f(n)的极限值为不等于零的常数，则称f(n)是T(n)的同数量级函数。记作T(n)=Ｏ(f(n)),称Ｏ(f(n)) 为算法的渐进时间复杂度，简称时间复杂度。

渐近记号（Asymptotic Notation）通常有 O、 Θ 和 Ω 记号法。Θ 记号渐进地给出了一个函数的上界和下界，当只有渐近上界时使用 O 记号，当只有渐近下界时使用 Ω 记号。尽管技术上 Θ 记号较为准确，但通常仍然使用 O 记号表示。

一般情况下,随着n的增大,T(n)增长最慢的算法为最优算法.

推导大O阶

用常数1取代运行时间中的所有加法常数

在修改后的运行次数函数中，只保留最高项

如果最高项存在且不是1，则去除与这个项相乘的常数。

**常数阶**以经典的高斯算法求和为例,

/**

\* 高斯方法

\* @param end

\* @return

*/

int simpleSum(int end){

int result = (1+end)*end/2;

printf("result=%d\n",result);

return result;

}

程序执行两步便获取到结果,所以时间复杂度为T(n)=2,按照推导大O阶方法,时间复杂度为O(1).

**线性阶**以1-100 求和为例:

/**

\* 1-100求和

\* @param end

\* @return

*/

int sum(int end){

int result = 0;

for (int i=1;i<=end;i++){

result += i;

}

return result;

}

for 循环中共执行的次数取决于end的值,所以时间复杂度为T(n)=n ,按照推导大O阶的方法,记做O(n)。

**对数阶**void logFunc(int n){

int count = 1;

while(count<n){

count = count * 2 ;

}

printf("count=%d\n",count);

}

设循环x次后退出循环(count>=n),即 2^x = n,则：x= logn 。所以时间复杂度为O(logn);

**平方阶**void square(int n){

int sum = 0;

for (int i=0;i<n;i++){

for (int j=0;j<n;j++){

sum = i+j;

}

}

printf("sum=%d\n",sum);

}

内层循环执行n^2次, 时间复杂度为:O(n^2);

常用时间复杂度，如下表所示：

![img](http://pics6.baidu.com/feed/8601a18b87d6277f8c1ef2d2fb502336e824fcbf.jpeg?token=a37d1c1d7ff0f64a9a2c1c08d72707a5&s=5A2834621FD348434AFDF1CA0300C0B1)

常见的时间复杂度消耗时间的大小排列:

O(1)< O(logn)< O(n)< O(nlogn)< O(n^2)< O(n^3)< O(2^n)< O(n!)< O(n^n)

**时间复杂度练习**

分析下列各程序段的时间复杂度

(1)

void main() {

int i=1,k=0,n=10;

while (i<=n-1) {

k+=10*i;i++;

}

}

(2)

void main() {

int i=1,k=0,n=100; do {

k+=10*i;i++;

}while (i==n)

}

(3)

void main() {

int i=1,j=0,n=10;

while (i+j<=n)

if (i>j)

j++;

else

i++;

}

(4)

void main() {

int n=10,x=n,y=0;

while (x>=(y+1)*(y+1))

y++;

}

(5)

void main() {

int n=9,i=1; while (i<=n)

i=i*3;

}

(6)

计算斐波拉契数列的时间复杂度。F(n)=f(n-1)+f(n-2)

(7)计算该函数的时间复杂度。F(n)=6f(n-1)-9f(n-2) 即fn=6fn-1-9fn-2 (8)求多项式A(x)的值的算法可直接根据下列两个公式之一来设计：(1)A(x)=anxn+ an-1xn-1 +……+ a1x + a0 (2)A(x)=(…(anx+ an-1)x+…. a1)x)+ a0 根据算法的时间复杂性比较这两种算法的优劣。

答案：(1) O(n)

(2) O(1)

(3) O(n)

(4) O(√n)

(5)O(log3n)

(6)方法：假设F(n)的时间复杂度为T(n),有 t(n)=t(n-1)+t(n-2)<2t(n-1)<2*2t(n-2)<2*2*2t(n-3)<....<2nt(0)=O(2n)

即t(n)<O(2n) 又 t(n)=t(n-1)+t(n-2)>2t(n-2)<2*2t(n-4)<2*2*2t(n-8)>....>2n/2t

(1)(n为奇数时，或2n/2t(0),n为偶数时) 即：t(n)>O(2n/2) 所以O(2n/2)<t(n)<O(2n) 取最坏情况上限，即t(n)≈O(2n)

（7）解：令fn=rn，则原式变为rn-6rn-1+9rn-2=0 同除以rn-2 则原式为r2-6r+9=0 如果解出来的是重根的话，则第一个根以rn代入，第2个重根以nrn代入，第3个重根以n2rn代入，第4个重根以n3rn代入，依此类推。解出的两个根为重根，均为3 所以，tn=c1*3n+c2*n*3n 依题意知t0=0,t1=1,代入后得：t0=c1*30+c2*0*30=0 t1=c1*31+c2*1*31=1 解得：c1=0,c2=1/3 则 tn=1/3*n*3n

(8)解：

(1)A(x)=anxn+ an-1xn-1 +……+ a1x + a0

(2)A(x)=(…(anx+ an-1)x+…. a1)x)+ a0 公式一：假设有一专门的子程序用于计算xn ，则x2需运乘法2次，x3需运行乘法3次，xn需运行乘法n次。由此可知，使用公式一时，子程序被调用的次数为n+(n-1)+(n-2)+….+1=n(n+1)/2。公式二：使用一个简单的循环运行n-1次即可。

**最坏情况和平均情况**

算法(Algorithms)的复杂度(Complexity)是指运行一个算法所需消耗的资源(时间或者空间)。同一个算法处理不同的输入数据所消耗的资源也可能不同，所以分析一个算法的复杂度时，主要有三种情况可以考虑，最差情况(Worst Case)下的，平均情况(Average Case)的， 最好情况(Best Case)下的。

算法的分析也是类似，我们查找一个有n个随机数字数组中的某个数字，最好的情况是第一个数字就是，那么算法的时间复杂度为O(1)，但也有可能这个数字就在最后一个位置上待着，那么算法的时间复杂度就是O(n)，这是最坏的一种情况了。

最坏情况运行时间是一种保证，那就是运行时间将不会再坏了。在应用中，这是一种最重要的需求，通常，除非特别指定，我们提到的运行时间都是最坏情况的运行时间。

而平均运行时间也就是从概率的角度看，这个数字在每一个位置的可能性是相同的，所以平均的查找时间为n/2次后发现这个目标元素。平均情况更能反映大多数情况下算法的表现。平均情况分析就是对所有输入尺寸为n的输入，让算法运转一遍，然后取它们的平均值。当然，实际中不可能将所有可能的输入都运行一遍，因此平均情况通常指的是一种数学期望值，而计算数学期望值则需要对输入的分布情况进行假设。

平均运行时间是所有情况中最有意义的，因为它是期望的运行时间。也就是说，我们运行一段程序代码时，是希望看到平均运行时间的。可现实中，平均运行时间很难通过分析得到，一般都是通过运行一定数量的实验数据后估算出来的。

有时候我们还需要知道最好情况是什么，这有两层意义：一是我们想知道如果运气好，能好到什么程度；二是如果我们能够证明好运气与我们同在，当然需要知道运气好的时候算法表现如何。这种最好分析就是在给定输入规模的时候，看看哪种输入能使算法的运行最有效率。当然，有人认为这种最好情况分析有点假：我们可以操控输入来使一个本来很慢的算法表现得很快，从而达到蒙蔽人的效果。

对算法的分析，一种方法是计算所有情况的平均值，这种时间复杂度的计算方法称为平均时间复杂度。另一种方法是计算最坏情况下的时间复杂度，这种方法称为最坏时间复杂度。一般在没有特殊说明的情况下，都是指最坏时间复杂度。

为什么要分析最坏情况下的算法时间复杂性？

最差情况下的复杂度是所有可能的输入数据所消耗的最大资源，如果最差情况下的复杂度符合我们的要求， 我们就可以保证所有的情况下都不会有问题。

某些算法经常遇到最差情况。比如一个查找算法，经常需要查找一个不存在的值。

也许你觉得平均情况下的复杂度更吸引你，可是平均情况也有几点问题。

第一，难计算，多数算法的最差情况下的复杂度要比平均情况下的容易计算的多，

第二，有很多算法的平均情况和最差情况的复杂度是一样的.

第三，什么才是真正的平均情况？如果你假设所有可能的输入数据出现的概率是一样的话，也是不合理的。其实多数情况是不一样的。而且输入数据的分布函数很可能是你没法知道。

考虑最好情况的复杂度更是没有意义。几乎所有的算法你都可以稍微修改一下，以获得很好的最好情况下的复杂度(要看输入数据的结构，可以是O(1))。怎样修改呢?

预先计算好某一输入的答案，在算法的开始部分判断输入，如果符合，给出答案。

**空间复杂度**

空间复杂度(Space Complexity)是对一个算法在运行过程中临时占用存储空间大小的量度，记做S(n)=O(f(n))。比如直接插入排序的时间复杂度是O(n^2),空间复杂度是O(1) 。而一般的递归算法就要有O(n)的空间复杂度了，因为每次递归都要存储返回信息。一个算法的优劣主要从算法的执行时间和所需要占用的存储空间两个方面衡量。

类似于时间复杂度的讨论，一个算法的空间复杂度S(n)定义为该算法所耗费的存储空间，它也是问题规模n的函数。渐近空间复杂度也常常简称为空间复杂度。空间复杂度(SpaceComplexity)是对一个算法在运行过程中临时占用存储空间大小的量度。一个算法在计算机存储器上所占用的存储空间，包括存储算法本身所占用的存储空间，算法的输入输出数据所占用的存储空间和算法在运行过程中临时占用的存储空间这三个方面。算法的输入输出数据所占用的存储空间是由要解决的问题决定的，是通过参数表由调用函数传递而来的，它不随本算法的不同而改变。

存储算法本身所占用的存储空间与算法书写的长短成正比，要压缩这方面的存储空间，就必须编写出较短的算法。算法在运行过程中临时占用的存储空间随算法的不同而异，有的算法只需要占用少量的临时工作单元，而且不随问题规模的大小而改变，我们称这种算法是“就地\”进行的，是节省存储的算法，有的算法需要占用的临时工作单元数与解决问题的规模n有关，它随着n的增大而增大，当n较大时，将占用较多的存储单元，例如快速排序和归并排序算法就属于这种情况。

分析一个算法所占用的存储空间要从各方面综合考虑。如对于递归算法来说，一般都比较简短，算法本身所占用的存储空间较少，但运行时需要一个附加堆栈，从而占用较多的临时工作单元；若写成非递归算法，一般可能比较长，算法本身占用的存储空间较多，但运行时将可能需要较少的存储单元。一个算法的空间复杂度只考虑在运行过程中为局部变量分配的存储空间的大小，它包括为参数表中形参变量分配的存储空间和为在函数体中定义的局部变量分配的存储空间两个部分。

若一个算法为递归算法，其空间复杂度为递归所使用的堆栈空间的大小，它等于一次调用所分配的临时存储空间的大小乘以被调用的次数(即为递归调用的次数加1，这个1表示开始进行的一次非递归调用)。算法的空间复杂度一般也以数量级的形式给出。如当一个算法的空间复杂度为一个常量，即不随被处理数据量n的大小而改变时，可表示为O(1)；当一个算法的空间复杂度与以2为底的n的对数成正比时，可表示为O(log2n)；当一个算法的空间复杂度与n成线性比例关系时，可表示为O(n).若形参为数组，则只需要为它分配一个存储由实参传送来的一个地址指针的空间，即一个机器字长空间；若形参为引用方式，则也只需要为其分配存储一个地址的空间，用它来存储对应实参变量的地址，以便由系统自动引用实参变量。

### 7.1 红黑树



概念：自平衡，左旋，右旋

红黑树也是二叉查找树，我们知道，二叉查找树这一数据结构并不难，而红黑树之所以难是难在它是自平衡的二叉查找树，在进行插入和删除等可能会破坏树的平衡的操作时，需要重新自处理达到平衡状态。现在在脑海想下怎么实现？是不是太多情景需要考虑了？啧啧，先别急，通过本文的学习后，你会觉得，其实也不过如此而已

#### 红黑树定义和性质

红黑树是一种含有红黑结点并能自平衡的二叉查找树。它必须满足下面性质：

- 性质1：每个节点要么是黑色，要么是红色。
- 性质2：根节点是黑色。
- 性质3：每个叶子节点（NIL）是黑色。
- 性质4：每个红色结点的两个子结点一定都是黑色。
- **性质5：任意一结点到每个叶子结点的路径都包含数量相同的黑结点。**



![img](https://upload-images.jianshu.io/upload_images/2392382-4996bbfb4017a3b2.png?imageMogr2/auto-orient/strip|imageView2/2/w/526/format/webp)

红黑树并不是一个*完美*平衡二叉查找树，从图1可以看到，根结点P的左子树显然比右子树高，但左子树和右子树的黑结点的层数是相等的，也即任意一个结点到到每个叶子结点的路径都包含数量相同的黑结点(性质5)。所以我们叫红黑树这种平衡为**黑色完美平衡**。



![img](https://upload-images.jianshu.io/upload_images/2392382-abedf3ecc733ccd5.png?imageMogr2/auto-orient/strip|imageView2/2/w/772/format/webp)

我们把正在处理(遍历)的结点叫做当前结点，如图2中的D，它的父亲叫做父结点，它的父亲的另外一个子结点叫做兄弟结点，父亲的父亲叫做祖父结点。

前面讲到红黑树能自平衡，它靠的是什么？三种操作：左旋、右旋和变色。

- **左旋**：以某个结点作为支点(旋转结点)，其右子结点变为旋转结点的父结点，右子结点的左子结点变为旋转结点的右子结点，左子结点保持不变。如图3。
- **右旋**：以某个结点作为支点(旋转结点)，其左子结点变为旋转结点的父结点，左子结点的右子结点变为旋转结点的左子结点，右子结点保持不变。如图4。
- **变色**：结点的颜色由红变黑或由黑变红。



细：https://www.jianshu.com/p/e136ec79235c

### 7.2 堆 栈 方法区

### 7.3 冒泡排序

### 7.4  排序二叉树

### 7.5 平衡二叉树

### 7.6 B+树

### 7.7 递归

### 7.8 快速排序

　快速排序（Quicksort）是对冒泡排序的一种改进。在大学学过之后现在基本忘了，最近在好多地方都看到说快速排序在面试会问到，于是自己也准备重新拾起以前忘记的东西来，慢慢的积累自己的基础知识。fighting

**算法概念**

　　快速排序由C. A. R. Hoare在1962（50多年了呢）年提出，它的基本思想是：通过一趟排序将要排序的数据分割成独立的两部分，其中一部分的所有数据都比另外一部分的所有数据都要小，然后再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列（摘自百度百科）。

　　快速排序采用了一种分治的策略，所以有时候我们也称为分治算法。

**算法思想**

　　1．先从数列中取出一个数作为基准数，一般会取第一个数做为基准数。

　　2．然后对数列进行分区，首先将比这个基准数大的数全放到它的右边，小于或等于基准数的数全放到它的左边（一刀切，左边小于基准数，右边大于基准数）。

　　3．再对划分的左右区间重复第二步，直到各区间只剩一个数就完成了排序。

　　下面画一个详细的大图，只画了第一趟排序的过程，知道第一躺怎么排序，后面都是一样的。

　快速排序（Quicksort）是对冒泡排序的一种改进。在大学学过之后现在基本忘了，最近在好多地方都看到说快速排序在面试会问到，于是自己也准备重新拾起以前忘记的东西来，慢慢的积累自己的基础知识。fighting

**算法概念**

　　快速排序由C. A. R. Hoare在1962（50多年了呢）年提出，它的基本思想是：通过一趟排序将要排序的数据分割成独立的两部分，其中一部分的所有数据都比另外一部分的所有数据都要小，然后再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列（摘自百度百科）。

　　快速排序采用了一种分治的策略，所以有时候我们也称为分治算法。

**算法思想**

　　1．先从数列中取出一个数作为基准数，一般会取第一个数做为基准数。

　　2．然后对数列进行分区，首先将比这个基准数大的数全放到它的右边，小于或等于基准数的数全放到它的左边（一刀切，左边小于基准数，右边大于基准数）。

　　3．再对划分的左右区间重复第二步，直到各区间只剩一个数就完成了排序。

　　下面画一个详细的大图，只画了第一趟排序的过程，知道第一躺怎么排序，后面都是一样的。

![img](https://images2015.cnblogs.com/blog/717907/201610/717907-20161029164601609-707252512.png)



算法如下：

~~~java
package com.roc.Quicksort;

/**
 * 快速排序
 * 
 * @author liaowp
 * 
 */
public class Quicksort {
    static void sort(int value[], int left, int right) {
        if (left < right) {// 判断左边的下标是小于右
            int i = left, j = right;// i为小值，j为大值
            int temp = value[left];// 默认中间数为temp，即最左边的数
            while (i < j) {// 如果i<j
                while (i < j && value[j] >= temp) {// 从右往左比较,如果i<j且value[j]>=temp
                    j--;
                }
                if (i < j) {// 如果i<j，找到有比中间数大的
                    value[i] = value[j];// 左边的数放右边的数
                    i++;// 左移一位
                }
                while (i < j && value[i] < temp) {// 从左往右找
                    i++;
                }
                if (i < j) {// 找到有比中间数小的，替换到右边
                    value[j] = value[i];
                    j--;
                }
            }
            value[i] = temp;
            for (int n = 0; n < value.length; n++) {
                System.out.print(value[n] + " ");
            }
            System.out.println();
            sort(value, left, i - 1);// 左边的重复
            sort(value, i + 1, right);// 右边的重复
        }
    }

    public static void main(String[] args) {
        int value[] = { 5, 1, 8, 4, 15 };
        System.out.print("原始数据：");
        for (int i = 0; i < value.length; i++) {
            System.out.print(value[i] + " ");
        }
        System.out.println();
        sort(value, 0, 4);
        System.out.print("排序结果：");
        for (int i = 0; i < value.length; i++) {
            System.out.print(value[i] + " ");
        }
    }

}
~~~

执行结果如下：

~~~
原始数据：5 1 8 4 15 
4 1 5 8 15 
1 4 5 8 15 
1 4 5 8 15 
排序结果：1 4 5 8 15 
~~~

注意：第一遍快速排序不会直接得到最终结果，只会把比基准数大和比基准数小的数分到基准数的两边。为了得到最后结果，需要再次对基准数两边的数组分别执行此步骤，然后再分解数组，直到数组不能再分解为止（只有一个数据），才能得到正确结果。

## 八：综合学习

### 8.1 Vmware 虚拟机

####   8.1.1 CenterOs7.0的安装 （Linux环境搭建）

  ![image-20201114225507277](C:\Users\lei41\AppData\Roaming\Typora\typora-user-images\image-20201114225507277.png)

####  8.1.2 Linux环境下安装 FastDfs 文件服务器

##### 8.1.2.1 安装GCC

```shell
[root@localhost ~]# yum -y install gcc-c++
```

*ps:检查gcc-c++是否已经安装(如果已安装，执行 yum -y install gcc-c++ 也会提示)*

```shell
[root@localhost src]# whereis gcc   
gcc:[root@localhost src]#        # 未安装输出
gcc: /usr/bin/gcc /usr/lib/gcc /usr/libexec/gcc /usr/share/man/man1/gcc.1.gz        #已安装输出
```



##### 8.1.2.1 安装libevent

FastDFS依赖libevent库，需要安装:

```shell
[root@localhost ~]# yum -y install libevent
```

```shell
[root@localhost ~]# cd /usr/local/src/    #切换到下载目录
[root@localhost src]# wget -O libfastcommon-1.0.39.tar.gz  https://codeload.github.com/happyfish100/libfastcommon/tar.gz/V1.0.39 #下载（如果下载慢 可以将下载好的文件上传到此目录)
[root@localhost src]# tar -zxvf libfastcommon-1.0.39.tar.gz      #解压
[root@localhost src]# cd libfastcommon-1.0.39/
# 安装
[root@localhost libfastcommon-1.0.39]# ./make.sh 

[root@localhost libfastcommon-1.0.39]# ./make.sh  install
```



##### 8.1.2.1 安装libfastcommon

 libfastcommon是FastDFS官方提供的，libfastcommon包含了FastDFS运行所需要的一些基础库。

下载地址： https://github.com/happyfish100/libfastcommon/releases 选择合适的版本



##### 8.1.2.1 安装FastDFS

下载地址：https://github.com/happyfish100/fastdfs/releases 选择合适的版本	

```shell
[root@localhost libfastcommon-1.0.39]# cd /usr/local/src/      #切换到下载目录

#下载（如果下载慢 可以将下载好的文件上传到此目录)
[root@localhost src]# wget -O fastdfs-5.11.tar.gz https://codeload.github.com/happyfish100/fastdfs/tar.gz/V5.11
[root@localhost src]# tar -zxvf fastdfs-5.11.tar.gz   #解压
[root@localhost src]# cd fastdfs-5.11/
#安装
[root@localhost fastdfs-5.11]# ./make.sh 
[root@localhost fastdfs-5.11]# ./make.sh  install
```

![image-20201115001750705](C:\Users\lei41\AppData\Roaming\Typora\typora-user-images\image-20201115001750705.png)



Linux重启防火墙  systemctl restart iptables.service



tracker

​       /etc/init.d/fdfs_tracker start  #启动tracker

​      /etc/init.d/fdfs_tracker stop #关闭tracker

storaged

​     /etc/init.d/fdfs_storaged start  #启动storaged 

​      /etc/init.d/fdfs_storaged stop #关闭storaged

### 8.2 开发辅助操作

#### 8.2.1md转html

#####  安装

```
npm install -g i5ting_toc
```

##### 用法

###### 进入 markdown 文件所在的文件夹

举个栗子:
 你的`sample.md`文件放在桌面上
 `cd /Users/dora/Desktop/`

###### 进入 md 文件所在的文件夹后, 输入命令:

```
i5ting_toc -f sample.md -o
```

#### 8.2.2 html转pdf

#####  安装

###### linux版本

~~~
rpm -ivh wkhtmltox-0.12.5-1.centos7.x86_64.rpm 安装
~~~

~~~
rpm -q wkhtmltox    查看是否安装成功
~~~

~~~
wkhtmltopdf https://www.baidu.com baidu.pdf { 要生成图片的的网址（例：https://www.baidu.com）baidu.pdf是生成的图片格式}
~~~

~~~
wkhtmltopdf --grayscale --disable-smart-shrinking --header-html head.html www.baidu.com baidu.pdf
[         1       ][        2      ] [                 3                  ] [                 4                 ] [               5                       ]

从左到右依次是：1命令开始、2使用灰度模式、3禁止智能缩放、4设置页眉为html文件、5生成pdf的页面网址、5生成的pdf文件名称

~~~

###### windows版本

~~~
下载地址：http://wkhtmltopdf.org/downloads.html 
~~~

~~~
设置环境变量后 如上所示输入对应指令
~~~



### 8.3 Linux环境

#### 8.3.1 Linux下部署下 安装jdk tomcat  mysql

https://www.cnblogs.com/shenjianping/p/10984540.html mysql

JDK环境配置  用文本编辑器打开/etc/profile，在profile文件末尾加入：

~~~java
JAVA_HOME=/usr/share/jdk1.5.0_05
PATH=$JAVA_HOME/bin:$PATH
CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
export JAVA_HOME
export PATH
export CLASSPATH

~~~

重新加载 source /etc/profile



Tomcat 环境配置 

~~~java
export  CATALINA_HOME=/usr/local/tomcat/apache-tomcat-9.0.43
export  PATH=$CATALINA_HOME/bin:$PATH
~~~



#### 8.3.2 Linux 部署宝塔 （快速部署环境）

##### 安装宝塔面板只需要一句话命令：

> yum install -y wget && wget -O install.sh http://download.bt.cn/install/install_6.0.sh && sh install.sh

宝塔下 可安装nginx、部署站点、redis、mysql、mongodb、memcache



#### 8.3.3 unzip和zip命令安装

~~~shell
yum install -y unzip zip
~~~



#### 8.3.4 集群搭建

##### 1.nginx集群

upstream配置集群

首先，docker中存在nginx 镜像。
其次，实例化生成三个容器。(实例化nginx )
三台容器的IP地址并不需要修改，在生成容器之初不需要指定bridge和sub等选项。其中一台容器为主节点需要端口映射，而其他容器并不需要端口映射。
部署过程
docker pull nginx

docker pull daocloud.io/nginx

拉取镜像使用这两条命令中的任意一个，速度第二个快。



实例化容器，注意镜像名需要更换。

docker run -itd --name nginx1 -p 8080:80 centos_nginx /bin/bash

返回容器ID64位， 在'docker ps'中可以查到，ID为实例化时[:12]

docker run -itd --name nginx2 centos_nginx /bin/bash

docker run -itd --name nginx3 centos_nginx /bin/bash

创建三台nginx容器，主节点为第一台名为'nginx1'，因为拥有端口映射。其余nginx容器作为负载均衡。


用另外一个终端去检查docker的虚拟网卡bridge



根据反馈结果，可以看出来bridge 中的存在nginx1-3它们的网卡信息。



接下来的步骤是nginx1节点的步骤

进入容器的方式

docker exec -it [nginx1节点的ID] /bin/bash


三台容器都需要的步骤如下

apt update

apt install vim 


nginx1需要做的

cd /etc/nginx/ 
vim nginx.conf



相比于没有修改的nginx.conf 文件，现在多了upstream 172.17.0.2和server两个字典。

在upstream中，可以指定域名，同样可以指定Ip，但是不需要加端口。因为server中已经开始监听80端口了。如果需要，可以修改80端口。

upstream中，填写三台容器中另外两台子节点。因为它们是负载节点，所以分配它们权重值。

重启nginx服务

service nginx restart

这一步执行之后，容器将会关闭。因为当前容器依赖的镜像是nginx镜像

然后在外部用docker指令将nginx1启动

docker start [nginx1ID]

接下来的步骤是nginx2节点的步骤

进入容器的方式

docker exec -it [nginx2节点的ID] /bin/bash

apt

apt update

apt install vim 

然后只需要修改nginx所使用的默认html文件就可以了。

cd /usr/share/nginx/html/

vim index.html



仅仅只是在<h1>标签中写了一句From 172.16.0.2:80!当然，主节点nginx1不需要修改html文件。但是nginx2和nginx3需要修改html文件。在nginx2的html文件中，别写成主机点nginx1的IP地址。

nginx3节点和nginx2节点步骤一样，只需要将html中的添加一下当前所处容器的IP+port即可（port可加可不加）


##### 2.redis集群

环境：Docker + ( Redis:5.0.5 * 3 )

###### 1、拉取镜像

```
docker  pull  redis:5.0.5
```

![img](https://gitee.com/niceyoo/blog/raw/master/img/image-20200531101955906.png)

###### 2、创建Redis容器

创建三个 redis 容器：

- redis-node1：6379
- redis-node2：6380
- redis-node3：6381

```
docker create --name redis-node1 -v /data/redis-data/node1:/data -p 6379:6379 redis:5.0.5 --cluster-enabled yes --cluster-config-file nodes-node-1.conf

docker create --name redis-node2 -v /data/redis-data/node2:/data -p 6380:6379 redis:5.0.5 --cluster-enabled yes --cluster-config-file nodes-node-2.conf

docker create --name redis-node3 -v /data/redis-data/node3:/data -p 6381:6379 redis:5.0.5 --cluster-enabled yes --cluster-config-file nodes-node-3.conf
```

![img](https://gitee.com/niceyoo/blog/raw/master/img/image-20200531103114409.png)

###### 3、启动并组建集群

启动容器

首先通过命令`docker start`来启动3个Redis容器：

![img](https://gitee.com/niceyoo/blog/raw/master/img/image-20200531104809850.png)

执行完运行命令后检查一下容器的启动情况：

![img](https://gitee.com/niceyoo/blog/raw/master/img/image-20200531105644785.png)

如果出现上图情况，`Exited (1) 3 seconds ago`，可以通过 `docker logs` 查看：

![img](https://gitee.com/niceyoo/blog/raw/master/img/image-20200531105938546.png)

如上提示的是权限问题，我们尝试修改一下权限：

```
chmod -R  777 /data
```

启动成功后如下图所示：

![img](https://gitee.com/niceyoo/blog/raw/master/img/image-20200531115746286.png)

###### 组建集群

查看3个Redis在Docker中分配的ip结点信息：

```
执行「docker inspect redis-node1」得到 redis-node1 ip 信息为：172.17.0.4 
执行「docker inspect redis-node2」得到 redis-node2 ip 信息为：172.17.0.3 
执行「docker inspect redis-node3」得到 redis-node3 ip 信息为：172.17.0.2
```

![img](https://gitee.com/niceyoo/blog/raw/master/img/image-20200531115950259.png)

拿到 ip 信息后（每个人的ip信息可能不一样），接下来进入某一个容器进行组建集群：

```
# 这里以进入 node1 为例
docker exec -it redis-node1 /bin/bash

# 接着执行组建集群命令（请根据自己的ip信息进行拼接）
redis-cli --cluster create 172.17.0.2:6379  172.17.0.3:6379  172.17.0.4:6379 --cluster-replicas 0
```

![img](https://gitee.com/niceyoo/blog/raw/master/img/image-20200531125547420.png)

ok，此时集群搭建完了，我们接下来测试一下。

###### 测试集群

使用 `redis-cli -c` 命令连接到集群结点，然后 set 值，set 值之后会自动重定向到 0.2 ip地址，然后通过 get 获取一下，获取成功证明集群有效。

![img](https://gitee.com/niceyoo/blog/raw/master/img/image-20200531130002028.png)

###### 4、存在的问题

按照如上的步骤，虽然集群搭建成功了，但其实还是有点问题的，由于集群结点中的 `ip地址` 是docket内部分配的，如：`172.17.0.2` 等，如果使用 `redis集群` 的项目跟集群不在一台服务器上，那么项目是没法使用集群的，因为是访问不通的。

![img](https://gitee.com/niceyoo/blog/raw/master/img/image-20200531135356244.png)

一种解决方案是让**Docker**使用 `host模式` 的网络连接类型，**Docker**在使用`host模式`下创建的容器是没有自己独立的网络命名空间的，是跟物理机共享一个网络空间，进而可以共享物理机的所有**端口与IP**，这样就可以让公共网络直接访问容器了，尽管这种方式有安全隐患，但目前来说还没找到其他可行性模式。

就存在的问题我们重新采用 `host模式`，重新创建一下容器：

###### 1、停止已运行的容器

```
docker stop redis-node1 redis-node2 redis-node3
```

###### 2、删除之前创建的容器

```
docker rm redis-node1 redis-node2 redis-node3

# 清空上面创建的配置文件
rm -rf /data/redis-data/node*
```

###### 3、重新基于host模式创建

```
docker create --name redis-node1 --net host -v /data/redis-data/node1:/data redis:5.0.5 --cluster-enabled yes --cluster-config-file nodes-node-1.conf --port 6379

docker create --name redis-node2 --net host -v /data/redis-data/node2:/data redis:5.0.5 --cluster-enabled yes --cluster-config-file nodes-node-2.conf --port 6380

docker create --name redis-node3 --net host -v /data/redis-data/node3:/data redis:5.0.5 --cluster-enabled yes --cluster-config-file nodes-node-3.conf --port 6381
```

跟之前创建命令不同，一是指定了 `--net` 网络类型为 `host`，二是这种情况下就不需要端口映射了，比如 `-p 6379:6379`，因为此时需要对外共享容器端口服务，所以只需要指定对外暴露的端口 `-p 6379`、`-p 6380` 等。

![img](https://gitee.com/niceyoo/blog/raw/master/img/image-20200531141150532.png)

###### 4、启动容器并组建集群

```
# 启动命令
docker start redis-node1 redis-node2 redis-node3

# 进入某一个容器
docker exec -it redis-node1 /bin/bash

# 组建集群,10.211.55.4为当前物理机的ip地址
redis-cli --cluster create 10.211.55.4:6379  10.211.55.4:6380  10.211.55.4:6381 --cluster-replicas 0
```

![img](https://gitee.com/niceyoo/blog/raw/master/img/image-20200531141853380.png)

###### 5、查看集群信息

```
root@CentOS7:/data# redis-cli
127.0.0.1:6379> cluster nodes
72c291c32815194b64d1f6d0fdf771f5cc04e14a 10.211.55.4:6380@16380 master - 0 1590905997358 2 connected 5461-10922
6a595b67bbff15c94e5874c2d2cd556d6a6a6c17 10.211.55.4:6381@16381 master - 0 1590905998362 3 connected 10923-16383
4e3dbdc8f835dcbc38291c88f08165ee51d53d3d 10.211.55.4:6379@16379 myself,master - 0 1590905997000 1 connected 0-5460
127.0.0.1:6379>
```

###### 6、测试集群

使用 `redis-cli -c` 连接到集群上，`set`一个值，然后从其他节点再获取值查看是否成功：

```
root@CentOS7:/data# redis-cli -c
127.0.0.1:6379> set wxiaowei 123
-> Redirected to slot [7515] located at 10.211.55.4:6380
OK
10.211.55.4:6380> get wxiaowei
"123"
```

![img](https://gitee.com/niceyoo/blog/raw/master/img/image-20200531142541229.png)

至此，本次基于Docker的Redis集群`单副本模式`算是搭建好了，文中3个redis都是用的主节点，关于多副本、主从架构高可用在后文补充。

**你们要的主从集群**：https://www.cnblogs.com/niceyoo/p/14118146.html



#### 8.3.5  Linux 安装 supervised 进程守护根据 

##### 一、supervisor简介

Supervisor是用Python开发的一套通用的进程管理程序，能将一个普通的命令行进程变为后台daemon，并监控进程状态，异常退出时能自动重启。它是通过fork/exec的方式把这些被管理的进程当作supervisor的子进程来启动，这样只要在supervisor的配置文件中，把要管理的进程的可执行文件的路径写进去即可。也实现当子进程挂掉的时候，父进程可以准确获取子进程挂掉的信息的，可以选择是否自己启动和报警。supervisor还提供了一个功能，可以为supervisord或者每个子进程，设置一个非root的user，这个user就可以管理它对应的进程。

*注：本文以centos7为例，supervisor版本3.4.0。*

##### 二、supervisor安装

1. 配置好yum源后，可以直接安装

   

   ```undefined
   yum install supervisor
   ```

2. Debian/Ubuntu可通过apt安装

   

   ```csharp
   apt-get install supervisor
   ```

3. pip安装

   

   ```undefined
   pip install supervisor
   ```

4. easy_install安装

   

   ```undefined
   easy_install supervisor
   ```

##### 三、supervisor使用

##### supervisor配置文件：`/etc/supervisord.conf`

*注：supervisor的配置文件默认是不全的，不过在大部分默认的情况下，上面说的基本功能已经满足。*

##### 子进程配置文件路径：`/etc/supervisord.d/`

*注：默认子进程配置文件为ini格式，可在supervisor主配置文件中修改。*

##### 四、配置文件说明

###### supervisor.conf配置文件说明：



```cpp
[unix_http_server]
file=/tmp/supervisor.sock   ;UNIX socket 文件，supervisorctl 会使用
;chmod=0700                 ;socket文件的mode，默认是0700
;chown=nobody:nogroup       ;socket文件的owner，格式：uid:gid
 
;[inet_http_server]         ;HTTP服务器，提供web管理界面
;port=127.0.0.1:9001        ;Web管理后台运行的IP和端口，如果开放到公网，需要注意安全性
;username=user              ;登录管理后台的用户名
;password=123               ;登录管理后台的密码
 
[supervisord]
logfile=/tmp/supervisord.log ;日志文件，默认是 $CWD/supervisord.log
logfile_maxbytes=50MB        ;日志文件大小，超出会rotate，默认 50MB，如果设成0，表示不限制大小
logfile_backups=10           ;日志文件保留备份数量默认10，设为0表示不备份
loglevel=info                ;日志级别，默认info，其它: debug,warn,trace
pidfile=/tmp/supervisord.pid ;pid 文件
nodaemon=false               ;是否在前台启动，默认是false，即以 daemon 的方式启动
minfds=1024                  ;可以打开的文件描述符的最小值，默认 1024
minprocs=200                 ;可以打开的进程数的最小值，默认 200
 
[supervisorctl]
serverurl=unix:///tmp/supervisor.sock ;通过UNIX socket连接supervisord，路径与unix_http_server部分的file一致
;serverurl=http://127.0.0.1:9001 ; 通过HTTP的方式连接supervisord
 
; [program:xx]是被管理的进程配置参数，xx是进程的名称
[program:xx]
command=/opt/apache-tomcat-8.0.35/bin/catalina.sh run  ; 程序启动命令
autostart=true       ; 在supervisord启动的时候也自动启动
startsecs=10         ; 启动10秒后没有异常退出，就表示进程正常启动了，默认为1秒
autorestart=true     ; 程序退出后自动重启,可选值：[unexpected,true,false]，默认为unexpected，表示进程意外杀死后才重启
startretries=3       ; 启动失败自动重试次数，默认是3
user=tomcat          ; 用哪个用户启动进程，默认是root
priority=999         ; 进程启动优先级，默认999，值小的优先启动
redirect_stderr=true ; 把stderr重定向到stdout，默认false
stdout_logfile_maxbytes=20MB  ; stdout 日志文件大小，默认50MB
stdout_logfile_backups = 20   ; stdout 日志文件备份数，默认是10
; stdout 日志文件，需要注意当指定目录不存在时无法正常启动，所以需要手动创建目录（supervisord 会自动创建日志文件）
stdout_logfile=/opt/apache-tomcat-8.0.35/logs/catalina.out
stopasgroup=false     ;默认为false,进程被杀死时，是否向这个进程组发送stop信号，包括子进程
killasgroup=false     ;默认为false，向进程组发送kill信号，包括子进程
 
;包含其它配置文件
[include]
files = relative/directory/*.ini    ;可以指定一个或多个以.ini结束的配置文件
```

##### 子进程配置文件说明：

给需要管理的子进程(程序)编写一个配置文件，放在`/etc/supervisor.d/`目录下，以`.ini`作为扩展名（每个进程的配置文件都可以单独分拆也可以把相关的脚本放一起）。如任意定义一个和脚本相关的项目名称的选项组（/etc/supervisord.d/test.conf）：



```ruby
#项目名
[program:blog]
#脚本目录
directory=/opt/bin
#脚本执行命令
command=/usr/bin/python /opt/bin/test.py

#supervisor启动的时候是否随着同时启动，默认True
autostart=true
#当程序exit的时候，这个program不会自动重启,默认unexpected，设置子进程挂掉后自动重启的情况，有三个选项，false,unexpected和true。如果为false的时候，无论什么情况下，都不会被重新启动，如果为unexpected，只有当进程的退出码不在下面的exitcodes里面定义的
autorestart=false
#这个选项是子进程启动多少秒之后，此时状态如果是running，则我们认为启动成功了。默认值为1
startsecs=1

#脚本运行的用户身份 
user = test

#日志输出 
stderr_logfile=/tmp/blog_stderr.log 
stdout_logfile=/tmp/blog_stdout.log 
#把stderr重定向到stdout，默认 false
redirect_stderr = true
#stdout日志文件大小，默认 50MB
stdout_logfile_maxbytes = 20MB
#stdout日志文件备份数
stdout_logfile_backups = 20
```

##### 子进程配置示例：



```bash
#说明同上
[program:test] 
directory=/opt/bin 
command=/opt/bin/test
autostart=true 
autorestart=false 
stderr_logfile=/tmp/test_stderr.log 
stdout_logfile=/tmp/test_stdout.log 
#user = test  
```

##### 五、supervisor命令说明

##### 常用命令



```cpp
supervisorctl status        //查看所有进程的状态
supervisorctl stop es       //停止es
supervisorctl start es      //启动es
supervisorctl restart       //重启es
supervisorctl update        //配置文件修改后使用该命令加载新的配置
supervisorctl reload        //重新启动配置中的所有程序
```

注：把`es`换成`all`可以管理配置中的所有进程。直接输入`supervisorctl`进入supervisorctl的shell交互界面，此时上面的命令不带supervisorctl可直接使用。

##### 注意事项

使用supervisor进程管理命令之前先启动supervisord，否则程序报错。
 使用命令`supervisord -c /etc/supervisord.conf`启动。
 若是centos7：



```cpp
systemctl start supervisord.service     //启动supervisor并加载默认配置文件
systemctl enable supervisord.service    //将supervisor加入开机启动项
```

##### 常见问题

1. unix:///var/run/supervisor.sock no such file
    问题描述：安装好supervisor没有开启服务直接使用supervisorctl报的错
    解决办法：`supervisord -c /etc/supervisord.conf`
2. command中指定的进程已经起来，但supervisor还不断重启
    问题描述：command中启动方式为后台启动，导致识别不到pid，然后不断重启，这里使用的是elasticsearch，command指定的是`$path/bin/elasticsearch -d`                    
    解决办法：supervisor无法检测后台启动进程的pid，而supervisor本身就是后台启动守护进程，因此不用担心这个
3. 启动了多个supervisord服务，导致无法正常关闭服务
    问题描述：在运行`supervisord -c /etc/supervisord.conf`之前，直接运行过`supervisord -c /etc/supervisord.d/xx.conf`导致有些进程被多个superviord管理，无法正常关闭进程。
    解决办法：使用`ps -fe | grep supervisord`查看所有启动过的supervisord服务，kill相关的进程。

###### 更多信息请移步Supervisor官网：[http://supervisord.org](https://links.jianshu.com/go?to=http%3A%2F%2Fsupervisord.org)



### 8.3.6 Linux 安装 Keepalived（高可用）

#### [Linux下Keepalived 安装与配置](https://www.cnblogs.com/dcrq/p/5642680.html)

一、环境说明

 

1、操作系统内核版本：2.6.9-78.ELsmp

  2、Keepalived软件版本：keepalived-1.1.20.tar.gz

 

二、环境配置

 

1、主Keepalived服务器IP地址 192.168.111.223

2、备Keepalived服务器IP地址 192.168.111.100

3、Keepalived虚拟IP地址 192.168.111.150

 

三、软件下载地址

 

   http://www.keepalived.org/software/keepalived-1.1.20.tar.gz

 

四、安装流程

 

  1、上传Keepalived至/home/目录

  2、解压Keepalived软件

   [root@localhost home]# tar -zxvf keepalived-1.1.20.tar.gz 

   [root@localhost home]# cd keepalived-1.1.20

   [root@localhost keepalived-1.1.20]# ln -s /usr/src/kernels/2.6.9-78.EL-i686/usr/src//linux

   [root@localhost keepalived-1.1.20]# ./configure 

 

　　遇到错误提示：configure: error: Popt libraries is required

　　这个错误是因为没有安装popt的开发包导致的，解决方法也很简单，只要yum install popt-devel 就可以安装好popt的开发包了。

　　重新./configure

　　没有遇到跳过这一步

  3、提示

​     ![img](https://images2015.cnblogs.com/blog/971251/201609/971251-20160911132315044-327292328.png)

 

  4、编译以及编译安装

   [root@localhost keepalived-1.1.20]# make && make install

![img](https://images2015.cnblogs.com/blog/971251/201609/971251-20160911132338937-1524470999.png)

   5、将types.h调用的部分注释掉即可解决4出现的问题

   vi/usr/src/kernels/2.6.9-78.EL-i686/include/linux/types.h 

   到158行操作如下

   

  \#endif 

  

  

 6、重新编译以及编译安装

   [root@localhost keepalived-1.1.20]# make && make install

​    ![img](https://images2015.cnblogs.com/blog/971251/201609/971251-20160911132406501-1039410226.png)

  7、修改配置文件路径

​    [[root@localhostkeepalived-1.1.20\]#cp/usr/local/etc/rc.d/init.d/keepalived/etc/rc.d/init.d/](mailto:[root@localhostkeepalived-1.1.20]#cp/usr/local/etc/rc.d/init.d/keepalived/etc/rc.d/init.d/)

​    [root@localhostkeepalived-1.1.20]# cp /usr/local/etc/sysconfig/keepalived /etc/sysconfig/

​    [root@localhost keepalived-1.1.20]# mkdir /etc/keepalived

​    [[root@localhostkeepalived-1.1.20\]#cp](mailto:[root@localhostkeepalived-1.1.20]#cp) /usr/local/etc/keepalived/keepalived.conf/etc/keepalived/              

​    [root@localhost keepalived-1.1.20]# cp /usr/local/sbin/keepalived /usr/sbin/

  8、设置为服务，开机启动

​    [root@localhost keepalived-1.1.20]# vi /etc/rc.local 

​    ![img](https://images2015.cnblogs.com/blog/971251/201609/971251-20160911132438425-2092407419.png)

 

五、主Keepalived配置

   1、修改配置文件

​    [root@localhost keepalived-1.1.20]# vi /etc/keepalived/keepalived.conf 

​    ![img](https://images2015.cnblogs.com/blog/971251/201609/971251-20160911132507333-1046966779.png)

六、备Keepalived配置

​    1、修改配置文件

​    ![img](https://images2015.cnblogs.com/blog/971251/201609/971251-20160911132530632-10532484.png)

七、启动服务

  ![img](https://images2015.cnblogs.com/blog/971251/201609/971251-20160911132551633-1820977883.png)

八、查看网卡信息

 1、主Keepalived网卡信息

![img](https://images2015.cnblogs.com/blog/971251/201609/971251-20160911132624651-125190919.png)

九、验证测试

 1、在主服务器上新建一个网页，内容为 192.168.111.223

 2、在备用服务器上新建一个网页，内容为 192.168.111.100

 3、启动主备服务器的http服务和Keepalived服务

 4、通过浏览数，输入虚拟IP地址 192.168.111.150

​    页面显示为 192.168.111.223

5、关闭主服务器的Keepalived服务，通过浏览器输入IP地址192.168.111.150

​    页面显示为 192.168.111.100

6、再次启动主服务器的Keepalived服务，通过浏览器输入IP地址192.168.111.150

​    页面显示为 192.168.111.223



配置介绍

~~~makefile
全局定义块
1、email通知（notification_email、smtp_server、smtp_connect_timeout）：用于服务有故障时发送邮件报警，可选项，不建议用。需要系统开启sendmail服务，建议用第三独立监控服务，如用nagios全面监控代替。
2、lvs_id：lvs负载均衡器标识，在一个网络内，它的值应该是唯一的。
3、router_id：用户标识本节点的名称，通常为hostname
4、花括号｛｝：用来分隔定义块，必须成对出现。如果写漏了，keepalived运行时不会得到预期的结果。由于定义块存在嵌套关系，因此很容易遗漏结尾处的花括号，这点需要特别注意。

VRRP实例定义块
vrrp_sync_group：同步vrrp级，用于确定失败切换（FailOver）包含的路由实例个数。即在有2个负载均衡器的场景，一旦某个负载均衡器失效，需要自动切换到另外一个负载均衡器的实例是哪
group：至少要包含一个vrrp实例，vrrp实例名称必须和vrrp_instance定义的一致
vrrp_instance：vrrp实例名
1> state：实例状态，只有MASTER 和 BACKUP两种状态，并且需要全部大写。抢占模式下，其中MASTER为工作状态，BACKUP为备用状态。当MASTER所在的服务器失效时，BACKUP所在的服务会自动把它的状态由BACKUP切换到MASTER状态。当失效的MASTER所在的服务恢复时，BACKUP从MASTER恢复到BACKUP状态。
2> interface：对外提供服务的网卡接口，即VIP绑定的网卡接口。如：eth0，eth1。当前主流的服务器都有2个或2个以上的接口（分别对应外网和内网），在选择网卡接口时，一定要核实清楚。
3> mcast_src_ip：本机IP地址
4> virtual_router_id：虚拟路由的ID号，每个节点设置必须一样，可选择IP最后一段使用，相同的 VRID 为一个组，他将决定多播的 MAC 地址。
5> priority：节点优先级，取值范围0～254，MASTER要比BACKUP高
6> advert_int：MASTER与BACKUP节点间同步检查的时间间隔，单位为秒
7> lvs_sync_daemon_inteface：负载均衡器之间的监控接口,类似于 HA HeartBeat 的心跳线。但它的机制优于 Heartbeat，因为它没有“裂脑”这个问题,它是以优先级这个机制来规避这个麻烦的。在 DR 模式中，lvs_sync_daemon_inteface与服务接口interface使用同一个网络接口
8> authentication：验证类型和验证密码。类型主要有 PASS、AH 两种，通常使用PASS类型，据说AH使用时有问题。验证密码为明文，同一vrrp 实例MASTER与BACKUP使用相同的密码才能正常通信。
9> smtp_alert：有故障时是否激活邮件通知
10> nopreempt：禁止抢占服务。默认情况，当MASTER服务挂掉之后，BACKUP自动升级为MASTER并接替它的任务，当MASTER服务恢复后，升级为MASTER的BACKUP服务又自动降为BACKUP，把工作权交给原MASTER。当配置了nopreempt，MASTER从挂掉到恢复，不再将服务抢占过来。
11> virtual_ipaddress：虚拟IP地址池，可以有多个IP，每个IP占一行，不需要指定子网掩码。注意：这个IP必须与我们的设定的vip保持一致。
虚拟服务器virtual_server定义块
virtual_server：定义一个虚拟服务器，这个ip是virtual_ipaddress中定义的其中一个，后面一个空格，然后加上虚拟服务的端口号。
1> delay_loop：健康检查时间间隔，单位：秒
2> lb_algo：负载均衡调度算法，互联网应用常用方式为wlc或rr
3> lb_kind：负载均衡转发规则。包括DR、NAT、TUN 3种，一般使用路由（DR）转发规则。
4> persistence_timeout：http服务会话保持时间，单位：秒
5> protocol：转发协议，分为TCP和UDP两种
real_server：真实服务器IP和端口，可以定义多个
1> weight：负载权重，值越大，转发的优先级越高
2> notify_down：服务停止后执行的脚本
3> TCP_CHECK：服务有效性检测
* connect_port：服务连接端口
* connect_timeout：服务连接超时时长，单位：秒
* nb_get_retry：服务连接失败重试次数
* delay_before_retry：重试连接间隔，单位：秒
~~~







## 九：工具

~~~java
package com.tongrong.utils;

import java.util.Collection;
import java.util.Map;
import java.util.regex.Matcher;
import java.util.regex.Pattern;

import org.apache.commons.lang.StringUtils;

/**
 * Java表单验证工具类
 * 
 * @author jiqinlin
 * 
 */
@SuppressWarnings("unchecked")
public class RegexUtil {

    public static void main(String[] args) {
//        System.out.println("过滤中英文特殊字符: "+RegexUtil.stringFilter("中国~~!#$%%."));
//        System.out.println("是否包含中英文特殊字符: "+RegexUtil.isContainsSpecialChar("12"));
//        System.out.println("过滤html代码: "+RegexUtil.htmltoText("<JAVASCRIPT>12</JAVASCRIPT>DDDDD"));
//        System.out.println("判断中文字符: "+RegexUtil.isChineseChar("中国！"));
        System.out.println("匹配汉字: "+RegexUtil.isChinese("中国！"));
//        System.out.println("判断英文字符: "+RegexUtil.isEnglish("abc!"));
//        System.out.println("判断合法字符: "+RegexUtil.isRightfulString("abc_-11AAA"));
//        System.out.println("邮政编码验证: "+RegexUtil.isZipCode("162406"));
//        System.out.println("身份证号码验证: "+RegexUtil.isIdCardNo("35052419880210133e"));
//        System.out.println("手机号码验证: "+RegexUtil.isMobile("18918611111"));
//        System.out.println("电话号码验证: "+RegexUtil.isPhone("8889333"));
//        System.out.println("电话号码验证: "+RegexUtil.isNumeric("888.9333"));
//        System.out.println("匹配密码: "+RegexUtil.isPwd("d888d_ddddd"));
//        System.out.println("匹配密码: "+RegexUtil.isUrl("http://baidu.com"));
        System.out.println("验证字符: "+RegexUtil.stringCheck("中文aabc001_-"));
//        System.out.println(isEmail("416501600@qq.com"));
        //http://baidu.com www.baidu.com baidu.com
//        System.out.println(NumberUtils.toInt("-0000000002"));
    }
    
    public final static boolean isNull(Object[] objs){
        if(objs==null||objs.length==0) return true;
        return false;
    }
    
    public final static boolean isNull(Integer integer){
        if(integer==null||integer==0) return true;
        return false;
    }
    
    public final static boolean isNull(Collection collection){
        if(collection==null||collection.size()==0) return true;
        return false;
    }
    
    public final static boolean isNull(Map map){
        if(map==null||map.size()==0) return true;
        return false;
    }
    
    public final static boolean isNull(String str){
        return str == null || "".equals(str.trim()) || "null".equals(str.toLowerCase());
    }
    
    
    public final static boolean isNull(Long longs){
        if(longs==null||longs==0) return true;
        return false;
    }
    
    public final static boolean isNotNull(Long longs){
        return !isNull(longs);
    }
    
    public final static boolean isNotNull(String str){
        return !isNull(str);
    }
    
    public final static boolean isNotNull(Collection collection){
        return !isNull(collection);
    }
    
    public final static boolean isNotNull(Map map){
        return !isNull(map);
    }
    
    public final static boolean isNotNull(Integer integer){
        return !isNull(integer);
    }
    
    public final static boolean isNotNull(Object[] objs){
        return !isNull(objs);
    }
    
    /**
     * 匹配URL地址
     * 
     * @param str
     * @return
     * @author jiqinlin
     */
    public final static boolean isUrl(String str) {
        return match(str, "^http://([\\w-]+\\.)+[\\w-]+(/[\\w-./?%&=]*)?$");
    }
    
    /**
     * 匹配密码，以字母开头，长度在6-12之间，只能包含字符、数字和下划线。
     * 
     * @param str
     * @return
     * @author jiqinlin
     */
    public final static boolean isPwd(String str) {
        return match(str, "^[a-zA-Z]\\w{6,12}$");
    }
    
    /**
     * 验证字符，只能包含中文、英文、数字、下划线等字符。
     * 
     * @param str
     * @return
     * @author jiqinlin
     */
    public final static boolean stringCheck(String str) {
        return match(str, "^[a-zA-Z0-9\u4e00-\u9fa5-_]+$");
    }
    
    /**
     * 匹配Email地址
     * 
     * @param str
     * @return
     * @author jiqinlin
     */
    public final static boolean isEmail(String str) {
        return match(str, "^\\w+([-+.]\\w+)*@\\w+([-.]\\w+)*\\.\\w+([-.]\\w+)*$");
    }
    
    /**
     * 匹配非负整数（正整数+0）
     * 
     * @param str
     * @return
     * @author jiqinlin
     */
    public final static boolean isInteger(String str) {
        return match(str, "^[+]?\\d+$");
    }
    
    /**
     * 判断数值类型，包括整数和浮点数
     * 
     * @param str
     * @return
     * @author jiqinlin
     */
    public final static boolean isNumeric(String str) { 
        if(isFloat(str) || isInteger(str)) return true;
        return false;
    }
    
    /**
     * 只能输入数字
     * 
     * @param str
     * @return
     * @author jiqinlin
     */
    public final static boolean isDigits(String str) {
        return match(str, "^[0-9]*$");
    }
    
    /**
     * 匹配正浮点数
     * 
     * @param str
     * @return
     * @author jiqinlin
     */
    public final static boolean isFloat(String str) {
        return match(str, "^[-\\+]?\\d+(\\.\\d+)?$");
    }
    
    /**
     * 联系电话(手机/电话皆可)验证   
     * 
     * @param text
     * @return
     * @author jiqinlin
     */
    public final static boolean isTel(String text){
        if(isMobile(text)||isPhone(text)) return true;
        return false;
    }
    
    /**
     * 电话号码验证  
     * 
     * @param text
     * @return
     * @author jiqinlin
     */
    public final static boolean isPhone(String text){
        return match(text, "^(\\d{3,4}-?)?\\d{7,9}$");
    }
    
    /**
     * 手机号码验证   
     * 
     * @param text
     * @return
     * @author jiqinlin
     */
    public final static boolean isMobile(String text){
        if(text.length()!=11) return false;
        return match(text, "^(((13[0-9]{1})|(15[0-9]{1})|(18[0-9]{1}))+\\d{8})$");
    }
    
    /**
     * 身份证号码验证 
     * 
     * @param text
     * @return
     * @author jiqinlin
     */
    public final static boolean isIdCardNo(String text){
        return match(text, "^(\\d{6})()?(\\d{4})(\\d{2})(\\d{2})(\\d{3})(\\w)$");
    }
    
    /**
     * 邮政编码验证 
     * 
     * @param text
     * @return
     * @author jiqinlin
     */
    public final static boolean isZipCode(String text){
        return match(text, "^[0-9]{6}$");
    }
    
    /**
     * 判断整数num是否等于0
     * 
     * @param num
     * @return
     * @author jiqinlin
     */
    public final static boolean isIntEqZero(int num){ 
         return num==0;
    }
    
    /**
     * 判断整数num是否大于0
     * 
     * @param num
     * @return
     * @author jiqinlin
     */
    public final static boolean isIntGtZero(int num){ 
         return num>0;
    }
    
    /**
     * 判断整数num是否大于或等于0
     * 
     * @param num
     * @return
     * @author jiqinlin
     */
    public final static boolean isIntGteZero(int num){ 
        return num>=0;
    }
    
    /**
     * 判断浮点数num是否等于0
     * 
     * @param num 浮点数
     * @return
     * @author jiqinlin
     */
    public final static boolean isFloatEqZero(float num){ 
         return num==0f;
    }
    
    /**
     * 判断浮点数num是否大于0
     * 
     * @param num 浮点数
     * @return
     * @author jiqinlin
     */
    public final static boolean isFloatGtZero(float num){ 
         return num>0f;
    }
    
    /**
     * 判断浮点数num是否大于或等于0
     * 
     * @param num 浮点数
     * @return
     * @author jiqinlin
     */
    public final static boolean isFloatGteZero(float num){ 
        return num>=0f;
    }
    
    /**
     * 判断是否为合法字符(a-zA-Z0-9-_)
     * 
     * @param text
     * @return
     * @author jiqinlin
     */
    public final static boolean isRightfulString(String text){
        return match(text, "^[A-Za-z0-9_-]+$"); 
    }
    
    /**
     * 判断英文字符(a-zA-Z)
     * 
     * @param text
     * @return
     * @author jiqinlin
     */
    public final static boolean isEnglish(String text){
        return match(text, "^[A-Za-z]+$"); 
    }
    
    /**
     * 判断中文字符(包括汉字和符号)
     * 
     * @param text
     * @return
     * @author jiqinlin
     */
    public final static boolean isChineseChar(String text){
        return match(text, "^[\u0391-\uFFE5]+$");
    }
    
    /**
     * 匹配汉字
     * 
     * @param text
     * @return
     * @author jiqinlin
     */
    public final static boolean isChinese(String text){
        return match(text, "^[\u4e00-\u9fa5]+$");
    }
    
    /**
     * 是否包含中英文特殊字符，除英文"-_"字符外
     * 
     * @param str
     * @return
     */
    public static boolean isContainsSpecialChar(String text) {
        if(StringUtils.isBlank(text)) return false;
        String[] chars={"[","`","~","!","@","#","$","%","^","&","*","(",")","+","=","|","{","}","'",
                ":",";","'",",","[","]",".","<",">","/","?","~","！","@","#","￥","%","…","&","*","（","）",
                "—","+","|","{","}","【","】","‘","；","：","”","“","’","。","，","、","？","]"};
        for(String ch : chars){
            if(text.contains(ch)) return true;
        }
        return false;
    }
    
    /**
     * 过滤中英文特殊字符，除英文"-_"字符外
     * 
     * @param text
     * @return
     */
    public static String stringFilter(String text) {
        String regExpr="[`~!@#$%^&*()+=|{}':;',\\[\\].<>/?~！@#￥%……&*（）——+|{}【】‘；：”“’。，、？]";  
        Pattern p = Pattern.compile(regExpr);
        Matcher m = p.matcher(text);
        return m.replaceAll("").trim();     
    }
    
    /**
     * 过滤html代码
     * 
     * @param inputString 含html标签的字符串
     * @return
     */
    public static String htmlFilter(String inputString) {
        String htmlStr = inputString; // 含html标签的字符串
        String textStr = "";
        java.util.regex.Pattern p_script;
        java.util.regex.Matcher m_script;
        java.util.regex.Pattern p_style;
        java.util.regex.Matcher m_style;
        java.util.regex.Pattern p_html;
        java.util.regex.Matcher m_html;
        java.util.regex.Pattern p_ba;
        java.util.regex.Matcher m_ba;

        try {
            String regEx_script = "<[\\s]*?script[^>]*?>[\\s\\S]*?<[\\s]*?\\/[\\s]*?script[\\s]*?>"; // 定义script的正则表达式{或<script[^>]*?>[\\s\\S]*?<\\/script>
            // }
            String regEx_style = "<[\\s]*?style[^>]*?>[\\s\\S]*?<[\\s]*?\\/[\\s]*?style[\\s]*?>"; // 定义style的正则表达式{或<style[^>]*?>[\\s\\S]*?<\\/style>
            // }
            String regEx_html = "<[^>]+>"; // 定义HTML标签的正则表达式
            String patternStr = "\\s+";

            p_script = Pattern.compile(regEx_script, Pattern.CASE_INSENSITIVE);
            m_script = p_script.matcher(htmlStr);
            htmlStr = m_script.replaceAll(""); // 过滤script标签

            p_style = Pattern.compile(regEx_style, Pattern.CASE_INSENSITIVE);
            m_style = p_style.matcher(htmlStr);
            htmlStr = m_style.replaceAll(""); // 过滤style标签

            p_html = Pattern.compile(regEx_html, Pattern.CASE_INSENSITIVE);
            m_html = p_html.matcher(htmlStr);
            htmlStr = m_html.replaceAll(""); // 过滤html标签

            p_ba = Pattern.compile(patternStr, Pattern.CASE_INSENSITIVE);
            m_ba = p_ba.matcher(htmlStr);
            htmlStr = m_ba.replaceAll(""); // 过滤空格

            textStr = htmlStr;

        } catch (Exception e) {
            System.err.println("Html2Text: " + e.getMessage());
        }
        return textStr;// 返回文本字符串
    }
    
    /**
     * 正则表达式匹配
     * 
     * @param text 待匹配的文本
     * @param reg 正则表达式
     * @return
     * @author jiqinlin
     */
    private final static boolean match(String text, String reg) {
        if (StringUtils.isBlank(text) || StringUtils.isBlank(reg))
            return false;
        return Pattern.compile(reg).matcher(text).matches();
    }
    
    

// 参考地址：http://www.cnblogs.com/yansheng/archive/2010/05/07/1730188.html    

// 附 ： 常用的正则表达式：
//    匹配特定数字：
//    ^[1-9]d*$　 　 //匹配正整数
//    ^-[1-9]d*$ 　 //匹配负整数
//    ^-?[1-9]d*$　　 //匹配整数
//    ^[1-9]d*|0$　 //匹配非负整数（正整数 + 0）
//    ^-[1-9]d*|0$　　 //匹配非正整数（负整数 + 0）
//    ^[1-9]d*.d*|0.d*[1-9]d*$　　 //匹配正浮点数
//    ^-([1-9]d*.d*|0.d*[1-9]d*)$　 //匹配负浮点数
//    ^-?([1-9]d*.d*|0.d*[1-9]d*|0?.0+|0)$　 //匹配浮点数
//    ^[1-9]d*.d*|0.d*[1-9]d*|0?.0+|0$　　 //匹配非负浮点数（正浮点数 + 0）
//    ^(-([1-9]d*.d*|0.d*[1-9]d*))|0?.0+|0$　　//匹配非正浮点数（负浮点数 + 0）
//    评注：处理大量数据时有用，具体应用时注意修正
//
//    匹配特定字符串：
//    ^[A-Za-z]+$　　//匹配由26个英文字母组成的字符串
//    ^[A-Z]+$　　//匹配由26个英文字母的大写组成的字符串
//    ^[a-z]+$　　//匹配由26个英文字母的小写组成的字符串
//    ^[A-Za-z0-9]+$　　//匹配由数字和26个英文字母组成的字符串
//    ^w+$　　//匹配由数字、26个英文字母或者下划线组成的字符串
//
//    在使用RegularExpressionValidator验证控件时的验证功能及其验证表达式介绍如下:
//
//    只能输入数字：“^[0-9]*$”
//    只能输入n位的数字：“^d{n}$”
//    只能输入至少n位数字：“^d{n,}$”
//    只能输入m-n位的数字：“^d{m,n}$”
//    只能输入零和非零开头的数字：“^(0|[1-9][0-9]*)$”
//    只能输入有两位小数的正实数：“^[0-9]+(.[0-9]{2})?$”
//    只能输入有1-3位小数的正实数：“^[0-9]+(.[0-9]{1,3})?$”
//    只能输入非零的正整数：“^+?[1-9][0-9]*$”
//    只能输入非零的负整数：“^-[1-9][0-9]*$”
//    只能输入长度为3的字符：“^.{3}$”
//    只能输入由26个英文字母组成的字符串：“^[A-Za-z]+$”
//    只能输入由26个大写英文字母组成的字符串：“^[A-Z]+$”
//    只能输入由26个小写英文字母组成的字符串：“^[a-z]+$”
//    只能输入由数字和26个英文字母组成的字符串：“^[A-Za-z0-9]+$”
//    只能输入由数字、26个英文字母或者下划线组成的字符串：“^w+$”
//    验证用户密码:“^[a-zA-Z]\\w{5,17}$”正确格式为：以字母开头，长度在6-18之间，
//
//    只能包含字符、数字和下划线。
//    验证是否含有^%&’,;=?$”等字符：“[^%&’,;=?$x22]+”
//    只能输入汉字：“^[u4e00-u9fa5],{0,}$”
//    验证Email地址：“^w+[-+.]w+)*@w+([-.]w+)*.w+([-.]w+)*$”
//    验证InternetURL：“^http://([\\w-]+\\.)+[\\w-]+(/[\\w-./?%&=]*)?$”
//    验证电话号码：“^((d{3,4})|d{3,4}-)?d{7,8}$”
//
//    正确格式为：“XXXX-XXXXXXX”，“XXXX-XXXXXXXX”，“XXX-XXXXXXX”，
//
//    “XXX-XXXXXXXX”，“XXXXXXX”，“XXXXXXXX”。
//    验证身份证号（15位或18位数字）：“^d{15}|d{}18$”
//    验证一年的12个月：“^(0?[1-9]|1[0-2])$”正确格式为：“01”-“09”和“1”“12”
//    验证一个月的31天：“^((0?[1-9])|((1|2)[0-9])|30|31)$” 正确格式为：“01”“09”和“1”“31”。
//
//    匹配中文字符的正则表达式： [u4e00-u9fa5]
//    匹配双字节字符(包括汉字在内)：[^x00-xff]
//    匹配空行的正则表达式：n[s| ]*r
//    匹配HTML标记的正则表达式：/< (.*)>.*|< (.*) />/
//    匹配首尾空格的正则表达式：(^s*)|(s*$)
//    匹配Email地址的正则表达式：w+([-+.]w+)*@w+([-.]w+)*.w+([-.]w+)*
//    匹配网址URL的正则表达式：^http://([\\w-]+\\.)+[\\w-]+(/[\\w-./?%&=]*)?$
}
~~~