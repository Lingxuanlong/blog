
# Java学习计划

[TOC]



## 一：基础类

### 1.1 IO流

####    1.1.1  输入输出流

####    1.2.1 文件上传 文件批量上传/下载 

#####     文件上传

```java
/*
    *  文件上传
    */
    @RequestMapping(value = "/upload",method = RequestMethod.POST)
    public CposResult Upload(HttpServletRequest request, HttpServletResponse response){

        CposResult cposResult = new CposResult();

        //获取请求体的Requst的文件流
        MultipartHttpServletRequest fileMap = (MultipartHttpServletRequest) request;


        if(!fileMap.equals(null)){
            Map<String, MultipartFile> forMap = fileMap.getFileMap();

            for (Map.Entry<String, MultipartFile> multipartFile : forMap.entrySet()) {
                MultipartFile file = multipartFile.getValue();
                //传入文件名
                String filename = file.getName();
                //获取文件的后缀名
                String extFileName = file.getOriginalFilename().toString().split("\\.")[1];

                //创建新文件名称
                String newName = System.currentTimeMillis()+"."+extFileName;

                //上传文件地址
                String upUrl = UploadPath+"//"+newName;

                File newFile = new File(upUrl);
                //判断文件夹是否存在
                if(!newFile.exists()){
                    newFile.mkdir();
                }

                try {
                    file.transferTo(newFile);
                } catch (IOException e) {
                    e.printStackTrace();
                    cposResult.setMsg("文件上传失败");
                    cposResult.setCode(500);
                    return cposResult;
                }
                cposResult.setData(upUrl);
            }
        }


        return cposResult;
    }
```

#####   下载

####    1.2.2  文件上传/下载 到FTP服务器

​    

```tex
 实现思路：首先需要创建一个FtpConfig的配置类  然后在FileUtil 里面编写连接Ftp以及下载/上传 ftp图片的接口 
```

​    

####    1.2.3   文件上传/下载 到FastDFS

####    1.2.4  文件上传/下载 到七牛云

配置七牛云秘钥

```
#千牛云 文件配置
qnos:
    access_key: i6AzZs1eIHKYPqpERENt4LdHe2NCJw-LHXpFND3J
    secret_key: 4vccePk3qZD9gg2HuHuydzQZDw4cFEfB2gGPkksx
    backet_name: cpos-files
```

```java
    //获取请求体的Requst的文件流
        MultipartHttpServletRequest fileMap = (MultipartHttpServletRequest) request;

        Config.ACCESS_KEY = accessKey;
        Config.SECRET_KEY = secretKey;
        Config.UP_HOST = "http://up-z2.qiniup.com";
        Mac mac = new Mac(Config.ACCESS_KEY, Config.SECRET_KEY);
        // 请确保该bucket已经存在
        String bucketName = backetName;
        PutPolicy putPolicy = new PutPolicy(bucketName);
        String uptoken = null;


        if(!fileMap.equals(null)){
            Map<String, MultipartFile> forMap = fileMap.getFileMap();

            for (Map.Entry<String, MultipartFile> multipartFile : forMap.entrySet()) {
                MultipartFile file = multipartFile.getValue();
                //传入文件名
                String filename = file.getName();
                //获取文件的后缀名
                String extFileName = file.getOriginalFilename().toString().split("\\.")[1];

                //创建新文件名称
                String key = System.currentTimeMillis()+"."+extFileName;

                //上传文件地址
                String localFile = UploadPath+"//"+key;

                File newFile = new File(localFile);
                //判断文件夹是否存在
                if(!newFile.exists()){
                    newFile.mkdir();
                }

                try {
                    file.transferTo(newFile);

                    try {
                        uptoken = putPolicy.token(mac);
                    } catch (AuthException e) {
                        e.printStackTrace();
                    } catch (JSONException e) {
                        e.printStackTrace();
                    }
                    PutExtra extra = new PutExtra();
                    PutRet ret = IoApi.putFile(uptoken, key, localFile, extra);
                    // http://qkg9ehwva.hn-bkt.clouddn.com
                    cposResult.setData(ret);
                } catch (IOException e) {
                    e.printStackTrace();
                }

            }
        }
```



### 1.2 线程

#### 1.2.1 线程概念

线程的状态：

  新建 就绪 运行 阻塞  死亡

阻塞： 等待阻塞  同步阻塞 其他阻塞

#### 1.2.2 多线程实践

 多线程的概念：合理化分配CPU资源，使得程序被最大程度优化

1、吞吐量：你做WEB，容器帮你做了多线程，但是他只能帮你做请求层面的。简单的说，可能就是一个请求一个线程。或多个请求一个线程。如果是单线程，那同时只能处理一个用户的请求。

2、伸缩性：也就是说，你可以通过增加CPU核数来提升性能。如果是单线程，那程序执行到死也就利用了单核，肯定没办法通过增加CPU核数来提升性能。



线程方式： Thread / Runnable

```java
    public void thread() {
        Thread thread = new Thread(){
            @Override
            public void run() {
                super.run();
                log.debug("starting....");
            }
        };
        thread.setName("t1");
        thread.start();
        log.debug("starting....");
    }

    public void runnable(){
        Runnable runnable = () ->   log.debug("runnable...");

        Thread t2 = new Thread(runnable);
        log.debug("runnable...");
        t2.start();
    }
```



#### 1.2.3 并发编程

##### 并发队列

   并发队列：最常见的业务场景就是多个线程共享同一个队列中的所有资源，就拿我们公司的业务场景来说，当用户通过多个渠道下单后，然后就会有多个不同的客户端通道同时去获取订单并处理订单，为了加快订单处理速度我们使用并发队列来充当任务源头，为了加快处理订单速度，结合多线程并发来满足需求。

~~~java
/**
 *  并发队列ConcurrentLinkedQueue的使用
 */

public class ConcurrentQueue {

    public static void main(String[] args){
        ToyotaYQ yq = new ToyotaYQ();
        new Thread(yq,"ToyotaYQ_001").start();
        new Thread(yq,"ToyotaYQ_002").start();
        new Thread(yq,"ToyotaYQ_003").start();
    }

}

/**
 * 任务来源
 */
class MQ{
    private static Queue<String> queue = null;    //并发队列(线程安全)

    /**
     * 初始化并发队列
     */
    public static Queue<String> initQueue(){
        if(queue == null){
            queue = new ConcurrentLinkedQueue<String>();
        }
        String tasklist = "JF1GH78F18G036149,JF1SH95F6AG110830,JF1SJ94D7DG010387,JF1SH92F9CG269249,JF1SH92F5BG215090,JF1SH92F5BG222556,JF1SH92F4CG279994,JF1BR96D7CG114298,JF1BR96D0BG078632,JF1SH95F9AG094011,JF1SH98FXAG186997,JF1BM92D8BG022510,JF1BM92DXAG013855,JF1BM94D8EG036618";
        String[] split = tasklist.split(",");
        List<String> task = Arrays.asList(split);    //数组转集合
        queue.addAll(task);        //按照集合中元素的顺序将集合中全部元素放进队列

        return queue;
    }
}

/**
 * 制单客户端
 */
class ToyotaYQ implements Runnable{

    private static final Object lock = new Object();
    private static Queue<String> queueYQ = MQ.initQueue();

    @Override
    public void run() {
        while(true){
            synchronized (lock){    //尽量减小锁的粒度和范围
                String thisVIN = queueYQ.poll();
                if(thisVIN == null){
                    break;
                }
                System.out.println(Thread.currentThread().getName() + "成功制单：" + thisVIN + "。剩余：" + queueYQ.size() + "个任务");
            }
        }
    }
}
~~~



##### 阻塞队列

​     阻塞队列：最常见的业务场景就是生产者不断生产任务放进阻塞队列中，消费者不断从阻塞队列中获取任务；当阻塞队列中填满数据时，所有生产者端的线程自动阻塞，当阻塞队列中数据为空时，所有消费端的线程自动阻塞。这些操作BlockingQueue都已经包办了，不用我们程序员去操心了。

阻塞队列我们常用的有：**LinkedBlockingQueue**和**ArrayBlockingQueue**，它们在各方面还是很大的区别的；**ArrayBlockingQueue在put,take操作使用了同一个锁，两者操作不能同时进行，而LinkedBlockingQueue使用了不同的锁，put操作和take操作可同时进行，以此来提高整个队列的并发性能。**

作为开发者，使用阻塞队列需要注意的一点是：**如果构造一个LinkedBlockingQueue对象，而没有指定其容量大小，LinkedBlockingQueue会默认一个类似无限大小的容量（Integer.MAX_VALUE），这样的话，如果生产者的速度一旦大于消费者的速度，也许还没有等到队列满阻塞产生，系统内存就有可能已被消耗殆尽了。**

###### **阻塞队列的一些常用方法**

![img](https://images2017.cnblogs.com/blog/855612/201711/855612-20171109132701591-272802014.png)

~~~java
public class BlockQueueDemo {

    public static void main(String[] args){
        BlockingQueue<Integer> queue = new LinkedBlockingQueue<Integer>(2); //定长为2的阻塞队列
        //ExecutorService：真正的线程池接口
        ExecutorService service = Executors.newCachedThreadPool();  //缓存线程池
        //创建3个生产者：
        ProducerDemo p1 = new ProducerDemo("车鉴定web端",queue);
        ProducerDemo p2 = new ProducerDemo("车鉴定APP端",queue);
        ProducerDemo p3 = new ProducerDemo("车鉴定接口端",queue);
        ProducerDemo p4 = new ProducerDemo("车鉴定M栈",queue);
        //创建三个消费者：
        ConsumerDemo c1 = new ConsumerDemo("ToyotaYQ_001",queue);
        ConsumerDemo c2 = new ConsumerDemo("ToyotaYQ_002",queue);
        ConsumerDemo c3 = new ConsumerDemo("ToyotaYQ_003",queue);

        //启动线程
        service.execute(p1);
        service.execute(p2);
        service.execute(p3);
        service.execute(p4);
        service.execute(c1);
        service.execute(c2);
        service.execute(c3);

    }
}

/**
 * 生产者
 */
class ProducerDemo implements Runnable {
    private String producerName;
    private BlockingQueue queue;//阻塞队列
    private Random r = new Random();

    //构造函数,传入生产者名称和操作的阻塞队列
    public ProducerDemo(String producerName,BlockingQueue queue) {
        this.producerName = producerName;
        this.queue = queue;
    }

    @Override
    public void run() {
        while(true){
            try {
                int task = r.nextInt(100);  //产生随机数
                System.out.println(producerName + "开始生产任务：" + task);
                queue.put(task);  //生产者向队列中放入一个随机数
                Thread.sleep(5000);  //减缓生产者生产的速度，如果队列为空，消费者就会阻塞不会进行消费直到有数据被生产出来
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }
    }
}

class ConsumerDemo implements Runnable{
    private String consumerName;
    private BlockingQueue queue;//阻塞队列

    //构造函数,传入消费者名称和操作的阻塞队列
    public ConsumerDemo(String consumerName,BlockingQueue queue) {
        this.consumerName = consumerName;
        this.queue = queue;
    }

    @Override
    public void run() {
        while(true){
            try {
                System.out.println(consumerName + "开始消费任务---" + queue.take());//消费者从阻塞队列中消费一个随机数
                //Thread.sleep(500);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }
    }
}
~~~

开发中各位最常用最熟悉的不过也是集合了，但是前几天在设计中突然想自己控制任务的分配和修改，这就需要用到灵活操作集合中的内容了，其它也没什么，但是删除集合中的元素这一点我们还是必须要很熟练的，虽然是需要借助迭代器来删除的，但是还是记录一下吧，方便以后copy。

删除List集合中的某元素：

~~~java
public class ListDemo {

    public static void main(String[] args){
        ArrayList<String> arrList = new ArrayList<String>();
        String[] arr = {"一丰","广丰","宝马","奥迪","保时捷","沃尔沃","悍马","路虎","凯迪拉克"};
        arrList.addAll(Arrays.asList(arr));     //将数组转成集合

        //删除前：
        for (String thisItem:arrList){
            System.out.println("---"+thisItem);
        }
        System.out.println("#########################");

        //使用迭代器删除集合中的元素
        Iterator it = arrList.iterator();
        while(it.hasNext()){    //it.hasNext()判断是否还有下一个元素
            if("悍马".equals(it.next())){     //it.next()代表下一个元素
                it.remove();        //【记得：remove()方法一定要调用迭代器的，不能调用List集合的】
            }
        }

        //删除后：
        for (String thisItem:arrList){
            System.out.println("---"+thisItem);
        }

    }
}
~~~



### 1.3 反射机制

#### 原理：

Class对象的由来是将.class文件读入内存，并为之创建一个Class对象。

#### 反射优缺点

1、优点：

​     在运行时获得类的各种内容，进行反编译，对于Java这种先编译再运行的语言，能够让我们很方便的创建灵活的代码，这些代码可以在运行时装配，无需在组件之间进行源代码的链接，更加容易实现面向对象。

2、缺点：

（1）反射会消耗一定的系统资源，因此，如果不需要动态地创建一个对象，那么就不需要用反射；

（2）反射调用方法时可以忽略权限检查，因此可能会破坏封装性而导致安全问题。

#### 反射的用途

1、反编译：.class-->.java

2、通过反射机制访问java对象的属性，方法，构造方法等

3、当我们在使用IDE,比如Ecplise时，当我们输入一个对象或者类，并想调用他的属性和方法是，一按点号，编译器就会自动列出他的属性或者方法，这里就是用到反射。

4、反射最重要的用途就是开发各种通用框架。比如很多框架（Spring）都是配置化的（比如通过XML文件配置Bean），为了保证框架的通用性，他们可能需要根据配置文件加载不同的类或者对象，调用不同的方法，这个时候就必须使用到反射了，运行时动态加载需要的加载的对象。

5、例如，在使用Strut2框架的开发过程中，我们一般会在struts.xml里去配置Action，比如

~~~xml
<action name="login" class="org.ScZyhSoft.test.action.SimpleLoginAction" method="execute">       <result>/shop/shop-index.jsp</result>               <result name="error">login.jsp</result>       </action>
~~~

比如我们请求login.action时，那么StrutsPrepareAndExecuteFilter就会去解析struts.xml文件，从action中查找出name为login的Action，并根据class属性创建SimpleLoginAction实例，并用Invoke方法来调用execute方法，这个过程离不开反射。配置文件与Action建立了一种映射关系，当View层发出请求时，请求会被StrutsPrepareAndExecuteFilter拦截，然后StrutsPrepareAndExecuteFilter会去动态地创建Action实例。

比如，加载数据库驱动的，用到的也是反射。

```java
Class.forName("com.mysql.jdbc.Driver"); // 动态加载mysql驱动
```

#### 反射机制常用的类

~~~java
Java.lang.Class;Java.lang.reflect.Constructor;Java.lang.reflect.Field;Java.lang.reflect.Method;Java.lang.reflect.Modifier;
~~~

#### 反射的基本使用

**1、获得Class：主要有三种方法：**

（1）Object-->getClass

（2）任何数据类型（包括基本的数据类型）都有一个“静态”的class属性

（3）通过class类的静态方法：forName(String className)（最常用）

~~~java
package fanshe; public class Fanshe {	public static void main(String[] args) {		//第一种方式获取Class对象  		Student stu1 = new Student();//这一new 产生一个Student对象，一个Class对象。		Class stuClass = stu1.getClass();//获取Class对象		System.out.println(stuClass.getName());				//第二种方式获取Class对象		Class stuClass2 = Student.class;		System.out.println(stuClass == stuClass2);//判断第一种方式获取的Class对象和第二种方式获取的是否是同一个				//第三种方式获取Class对象		try {			Class stuClass3 = Class.forName("fanshe.Student");//注意此字符串必须是真实路径，就是带包名的类路径，包名.类名			System.out.println(stuClass3 == stuClass2);//判断三种方式是否获取的是同一个Class对象		} catch (ClassNotFoundException e) {			e.printStackTrace();		}			}}
~~~

注意，在运行期间，一个类，只有一个Class对象产生，所以打印结果都是true；

三种方式中，常用第三种，第一种对象都有了还要反射干什么，第二种需要导入类包，依赖太强，不导包就抛编译错误。一般都使用第三种，一个字符串可以传入也可以写在配置文件中等多种方法。

**2、判断是否为某个类的示例：**

一般的，我们使用instanceof 关键字来判断是否为某个类的实例。同时我们也可以借助反射中Class对象的isInstance()方法来判断时候为某个类的实例，他是一个native方法。

~~~java
public native boolean isInstance(Object obj);
~~~

**3、创建实例：通过反射来生成对象主要有两种方法：**

（1）使用Class对象的newInstance()方法来创建Class对象对应类的实例。

~~~java
Class<?> c = String.class;Object str = c.newInstance();
~~~



（2）先通过Class对象获取指定的Constructor对象，再调用Constructor对象的newInstance()方法来创建对象，这种方法可以用指定的构造器构造类的实例。

~~~java
//获取String的Class对象Class<?> str = String.class;//通过Class对象获取指定的Constructor构造器对象Constructor constructor=c.getConstructor(String.class);//根据构造器创建实例：Object obj = constructor.newInstance(“hello reflection”);
~~~




**4、通过反射获取构造方法并使用：**

（1）批量获取的方法：

~~~java
public Constructor[] getConstructors()：所有"公有的"构造方法public Constructor[] getDeclaredConstructors()：获取所有的构造方法(包括私有、受保护、默认、公有)
~~~



（2）单个获取的方法，并调用：

~~~java
public Constructor getConstructor(Class... parameterTypes):获取单个的"公有的"构造方法：public Constructor getDeclaredConstructor(Class... parameterTypes):获取"某个构造方法"可以是私有的，或受保护、默认、公有；
~~~



（3） 调用构造方法：

Constructor-->newInstance(Object... initargs)

newInstance是 Constructor类的方法（管理构造函数的类）

api的解释为：newInstance(Object... initargs) ，使用此 Constructor 对象表示的构造方法来创建该构造方法的声明类的新实例，并用指定的初始化参数初始化该实例。

它的返回值是T类型，所以newInstance是创建了一个构造方法的声明类的新实例对象，并为之调用。

例子：

Student类：共六个构造方法。

~~~java
package fanshe;public class Student {	//---------------构造方法-------------------	//（默认的构造方法）	Student(String str){		System.out.println("(默认)的构造方法 s = " + str);	}	//无参构造方法	public Student(){		System.out.println("调用了公有、无参构造方法执行了。。。");	}	//有一个参数的构造方法	public Student(char name){		System.out.println("姓名：" + name);	}	//有多个参数的构造方法	public Student(String name ,int age){		System.out.println("姓名："+name+"年龄："+ age);//这的执行效率有问题，以后解决。	}	//受保护的构造方法	protected Student(boolean n){		System.out.println("受保护的构造方法 n = " + n);	}	//私有构造方法	private Student(int age){		System.out.println("私有的构造方法   年龄："+ age);	}}
~~~



测试类：

~~~java
package fanshe;import java.lang.reflect.Constructor;/* * 通过Class对象可以获取某个类中的：构造方法、成员变量、成员方法；并访问成员； *  * 1.获取构造方法： * 1).批量的方法： * public Constructor[] getConstructors()：所有"公有的"构造方法      public Constructor[] getDeclaredConstructors()：获取所有的构造方法(包括私有、受保护、默认、公有) * 2).获取单个的方法，并调用： * public Constructor getConstructor(Class... parameterTypes):获取单个的"公有的"构造方法： * public Constructor getDeclaredConstructor(Class... parameterTypes):获取"某个构造方法"可以是私有的，或受保护、默认、公有； 		 * 3).调用构造方法： * Constructor-->newInstance(Object... initargs)    */   public class Constructors {   public static void main(String[] args) throws Exception {   	//1.加载Class对象   	Class clazz = Class.forName("fanshe.Student");   	   	//2.获取所有公有构造方法   	System.out.println("**********************所有公有构造方法*********************************");   	Constructor[] conArray = clazz.getConstructors();   	for(Constructor c : conArray){   		System.out.println(c);   	}   	   	System.out.println("************所有的构造方法(包括：私有、受保护、默认、公有)***************");   	conArray = clazz.getDeclaredConstructors();   	for(Constructor c : conArray){   		System.out.println(c);   	}   	   	System.out.println("*****************获取公有、无参的构造方法*******************************");   	Constructor con = clazz.getConstructor(null);   	//1>、因为是无参的构造方法所以类型是一个null,不写也可以：这里需要的是一个参数的类型，切记是类型   	//2>、返回的是描述这个无参构造函数的类对象。   	System.out.println("con = " + con);   	    	//调用构造方法   	Object obj = con.newInstance();   //	System.out.println("obj = " + obj);   //	Student stu = (Student)obj;   	   	System.out.println("******************获取私有构造方法，并调用*******************************");   	con = clazz.getDeclaredConstructor(char.class);   	System.out.println(con);   	//调用构造方法   	con.setAccessible(true);//暴力访问(忽略掉访问修饰符)   	obj = con.newInstance('男');   }   }
~~~



控制台输出：

**********************所有公有构造方法*********************************
public fanshe.Student(java.lang.String,int)
public fanshe.Student(char)
public fanshe.Student()
************所有的构造方法(包括：私有、受保护、默认、公有)***************
private fanshe.Student(int)
protected fanshe.Student(boolean)
public fanshe.Student(java.lang.String,int)
public fanshe.Student(char)
public fanshe.Student()
fanshe.Student(java.lang.String)
*****************获取公有、无参的构造方法*******************************
con = public fanshe.Student()
调用了公有、无参构造方法执行了。。。
******************获取私有构造方法，并调用*******************************
public fanshe.Student(char)
姓名：男


5、获取成员变量并调用：

Student类：

~~~java
package fanshe.field;public class Student {	public Student(){			}	//**********字段*************//	public String name;	protected int age;	char sex;	private String phoneNum;		@Override	public String toString() {		return "Student [name=" + name + ", age=" + age + ", sex=" + sex				+ ", phoneNum=" + phoneNum + "]";	}}
~~~



测试类：

package fanshe.field;
import java.lang.reflect.Field;
/*

 * 获取成员变量并调用：

 * 

 * 1.批量的

 * 1).Field[] getFields():获取所有的"公有字段"

 * 2).Field[] getDeclaredFields():获取所有字段，包括：私有、受保护、默认、公有；

 * 2.获取单个的：

 * 1).public Field getField(String fieldName):获取某个"公有的"字段；

 * 2).public Field getDeclaredField(String fieldName):获取某个字段(可以是私有的)

 * 

 * 设置字段的值：

 * Field --> public void set(Object obj,Object value):

 * 参数说明：

 * 1.obj:要设置的字段所在的对象；

 * 2.value:要为字段设置的值；
   */

   ~~~java
   public class Fields {	public static void main(String[] args) throws Exception {		//1.获取Class对象		Class stuClass = Class.forName("fanshe.field.Student");		//2.获取字段		System.out.println("************获取所有公有的字段********************");		Field[] fieldArray = stuClass.getFields();		for(Field f : fieldArray){			System.out.println(f);		}		System.out.println("************获取所有的字段(包括私有、受保护、默认的)********************");		fieldArray = stuClass.getDeclaredFields();		for(Field f : fieldArray){			System.out.println(f);		}		System.out.println("*************获取公有字段**并调用***********************************");		Field f = stuClass.getField("name");		System.out.println(f);		//获取一个对象		Object obj = stuClass.getConstructor().newInstance();//产生Student对象--》Student stu = new Student();		//为字段设置值		f.set(obj, "刘德华");//为Student对象中的name属性赋值--》stu.name = "刘德华"		//验证		Student stu = (Student)obj;		System.out.println("验证姓名：" + stu.name);​				System.out.println("**************获取私有字段****并调用********************************");		f = stuClass.getDeclaredField("phoneNum");		System.out.println(f);		f.setAccessible(true);//暴力反射，解除私有限定		f.set(obj, "18888889999");		System.out.println("验证电话：" + stu);			}}
   ~~~

   

   控制台输出：

************获取所有公有的字段********************
public java.lang.String fanshe.field.Student.name
************获取所有的字段(包括私有、受保护、默认的)********************
public java.lang.String fanshe.field.Student.name
protected int fanshe.field.Student.age
char fanshe.field.Student.sex
private java.lang.String fanshe.field.Student.phoneNum
*************获取公有字段**并调用***********************************
public java.lang.String fanshe.field.Student.name
验证姓名：刘德华
**************获取私有字段****并调用********************************
private java.lang.String fanshe.field.Student.phoneNum
验证电话：Student [name=刘德华, age=0, sex=


6、获取成员方法并调用：

Student类：

~~~java
package fanshe.method;public class Student {	//**************成员方法***************//	public void show1(String s){		System.out.println("调用了：公有的，String参数的show1(): s = " + s);	}	protected void show2(){		System.out.println("调用了：受保护的，无参的show2()");	}	void show3(){		System.out.println("调用了：默认的，无参的show3()");	}	private String show4(int age){		System.out.println("调用了，私有的，并且有返回值的，int参数的show4(): age = " + age);		return "abcd";	}}
~~~



测试类：

~~~java
package fanshe.method;import java.lang.reflect.Method;/* * 获取成员方法并调用： *  * 1.批量的： * public Method[] getMethods():获取所有"公有方法"；（包含了父类的方法也包含Object类） * public Method[] getDeclaredMethods():获取所有的成员方法，包括私有的(不包括继承的) * 2.获取单个的： * public Method getMethod(String name,Class<?>... parameterTypes): * 参数： * name : 方法名； * Class ... : 形参的Class类型对象 * public Method getDeclaredMethod(String name,Class<?>... parameterTypes) *  * 调用方法： * Method --> public Object invoke(Object obj,Object... args): * 参数说明： * obj : 要调用方法的对象； * args:调用方式时所传递的实参；   ):    */   public class MethodClass {   public static void main(String[] args) throws Exception {   	//1.获取Class对象   	Class stuClass = Class.forName("fanshe.method.Student");   	//2.获取所有公有方法   	System.out.println("***************获取所有的”公有“方法*******************");   	stuClass.getMethods();   	Method[] methodArray = stuClass.getMethods();   	for(Method m : methodArray){   		System.out.println(m);   	}   	System.out.println("***************获取所有的方法，包括私有的*******************");   	methodArray = stuClass.getDeclaredMethods();   	for(Method m : methodArray){   		System.out.println(m);   	}   	System.out.println("***************获取公有的show1()方法*******************");   	Method m = stuClass.getMethod("show1", String.class);   	System.out.println(m);   	//实例化一个Student对象   	Object obj = stuClass.getConstructor().newInstance();   	m.invoke(obj, "刘德华");   	   	System.out.println("***************获取私有的show4()方法******************");   	m = stuClass.getDeclaredMethod("show4", int.class);   	System.out.println(m);   	m.setAccessible(true);//解除私有限定   	Object result = m.invoke(obj, 20);//需要两个参数，一个是要调用的对象（获取有反射），一个是实参   	System.out.println("返回值：" + result);	   }   }
~~~



控制台输出：

***************获取所有的”公有“方法*******************
public void fanshe.method.Student.show1(java.lang.String)
public final void java.lang.Object.wait(long,int) throws java.lang.InterruptedException
public final native void java.lang.Object.wait(long) throws java.lang.InterruptedException
public final void java.lang.Object.wait() throws java.lang.InterruptedException
public boolean java.lang.Object.equals(java.lang.Object)
public java.lang.String java.lang.Object.toString()
public native int java.lang.Object.hashCode()
public final native java.lang.Class java.lang.Object.getClass()
public final native void java.lang.Object.notify()
public final native void java.lang.Object.notifyAll()
***************获取所有的方法，包括私有的*******************
public void fanshe.method.Student.show1(java.lang.String)
private java.lang.String fanshe.method.Student.show4(int)
protected void fanshe.method.Student.show2()
void fanshe.method.Student.show3()
***************获取公有的show1()方法*******************
public void fanshe.method.Student.show1(java.lang.String)
调用了：公有的，String参数的show1(): s = 刘德华
***************获取私有的show4()方法******************
private java.lang.String fanshe.method.Student.show4(int)
调用了，私有的，并且有返回值的，int参数的show4(): age = 20
返回值：abcd


7、反射main方法：

Student类：

package fanshe.main;

public class Student {
	public static void main(String[] args) {
		System.out.println("main方法执行了。。。");
	}
}
测试类：

~~~java
package fanshe.main;import java.lang.reflect.Method;/** * 获取Student类的main方法、不要与当前的main方法搞混了   */   public class Main {   public static void main(String[] args) {   	try {   		//1、获取Student对象的字节码   		Class clazz = Class.forName("fanshe.main.Student");   		   		//2、获取main方法   		 Method methodMain = clazz.getMethod("main", String[].class);//第一个参数：方法名称，第二个参数：方法形参的类型，   		//3、调用main方法   		// methodMain.invoke(null, new String[]{"a","b","c"});   		 //第一个参数，对象类型，因为方法是static静态的，所以为null可以，第二个参数是String数组，这里要注意在jdk1.4时是数组，jdk1.5之后是可变参数   		 //这里拆的时候将  new String[]{"a","b","c"} 拆成3个对象。。。所以需要将它强转。   		 methodMain.invoke(null, (Object)new String[]{"a","b","c"});//方式一   		// methodMain.invoke(null, new Object[]{new String[]{"a","b","c"}});//方式二			   	} catch (Exception e) {   		e.printStackTrace();   	}   }}
~~~



控制台输出：

main方法执行了。。。


8、利用反射创建数值：

数组在Java里是比较特殊的一种类型，它可以赋值给一个Object Reference。

public static void testArray() throws ClassNotFoundException {
        Class<?> cls = Class.forName("java.lang.String");
        Object array = Array.newInstance(cls,25);
        //往数组里添加内容
        Array.set(array,0,"golang");
        Array.set(array,1,"Java");
        Array.set(array,2,"pytho");
        Array.set(array,3,"Scala");
        Array.set(array,4,"Clojure");
        //获取某一项的内容
        System.out.println(Array.get(array,3));
    }


9、反射方法的其他使用--通过反射运行配置文件内容：

Student类：

public class Student {
	public void show(){
		System.out.println("is show()");
	}
}
配置文件以txt文件为例子：

className = cn.fanshe.Student
methodName = show
测试类：

~~~java
import java.io.FileNotFoundException;import java.io.FileReader;import java.io.IOException;import java.lang.reflect.Method;import java.util.Properties;/* * 我们利用反射和配置文件，可以使：应用程序更新时，对源码无需进行任何修改 * 我们只需要将新类发送给客户端，并修改配置文件即可   */   public class Demo {   public static void main(String[] args) throws Exception {   	//通过反射获取Class对象   	Class stuClass = Class.forName(getValue("className"));//"cn.fanshe.Student"   	//2获取show()方法   	Method m = stuClass.getMethod(getValue("methodName"));//show   	//3.调用show()方法   	m.invoke(stuClass.getConstructor().newInstance());   	   }   //此方法接收一个key，在配置文件中获取相应的value   public static String getValue(String key) throws IOException{   	Properties pro = new Properties();//获取配置文件的对象   	FileReader in = new FileReader("pro.txt");//获取输入流   	pro.load(in);//将流加载到配置文件对象中   	in.close();   	return pro.getProperty(key);//返回根据key获取的value值   }   }
~~~



控制台输出：

~~~java
is show()
~~~



需求：

当我们升级这个系统时，不要Student类，而需要新写一个Student2的类时，这时只需要更改pro.txt的文件内容就可以了。代码就一点不用改动。

~~~java
public class Student2 {	public void show2(){		System.out.println("is show2()");	}}
~~~



配置文件更改为：

~~~java
className = cn.fanshe.Student2methodName = show2
~~~



10、反射方法的其他使用--通过反射越过泛型检查：

泛型用在编译期，编译过后泛型擦除（消失掉），所以是可以通过反射越过泛型检查的

测试类：

```java
import java.lang.reflect.Method;import java.util.ArrayList;/* * 通过反射越过泛型检查 * 例如：有一个String泛型的集合，怎样能向这个集合中添加一个Integer类型的值？   */   public class Demo {   public static void main(String[] args) throws Exception{   	ArrayList<String> strList = new ArrayList<>();   	strList.add("aaa");   	strList.add("bbb");   	   //	strList.add(100);   	//获取ArrayList的Class对象，反向的调用add()方法，添加数据   	Class listClass = strList.getClass(); //得到 strList 对象的字节码 对象   	//获取add()方法   	Method m = listClass.getMethod("add", Object.class);   	//调用add()方法   	m.invoke(strList, 100);   	        //遍历集合        for(Object obj : strList){            System.out.println(obj);        }    }}		
```

控制台输出：

~~~
aaabbb100
~~~



### 1.4 JVM虚拟机

### 1.5 GC回收机制



## 二：进阶类

### 2.1 设计模式

### 2.2 业务实战

#### 2.2.1 秒杀业务实现

所需使用pom-jar包

~~~xml
<!--    集成Redis服务    --><dependency>    <groupId>org.springframework.boot</groupId>    <artifactId>spring-boot-starter-redis</artifactId>    <version>1.4.1.RELEASE</version></dependency><!--   etttuce作为redis的桥接工具     --><dependency>    <groupId>redis.clients</groupId>    <artifactId>jedis</artifactId></dependency>
~~~



  1.模拟并发500 秒杀服务类

~~~java
 /**     *  集成秒杀抽象类     */    @Override    public ResultCc secKill(String json, HttpServletRequest request) {        if(CheckUtil.checkIsNullAndEmpty(json)){            //获取到json内对应的信息            JSONObject jsonObject = JSONObject.parseObject(json);            //获取用户信息            jsonObject.getString("userId");            //获取商品ID            String seckillId = jsonObject.getString("seckillId");            String methodType = jsonObject.getString("methodType");            try {                for (int i = 0; i < 500; i++) {                    Runnable runnable = new Runnable() {                        @Override                        public void run() {                            //秒杀                            cpSeckillService.miaoshaGoods(jsonObject);                        }                    };                    threadPoolExecutor.execute(runnable);                }            }catch (Exception e){                e.printStackTrace();                return ResultCc.error("抢购失败", "当前抢购的人数太多了！");            }            return ResultCc.succes();        }else{           return ResultCc.errorOfParamUnValid();        }    }
~~~

2. 业务底层实现类

   ~~~java
    /**    *@Description:  处理秒杀业务    *@Parameter:[methodType, id]    *@Return:com.cpos.cposconcurrent.entiry.ResultCc    *@Author:leiwenlong    *@Date:2021/6/17    **/    @Override    public ResultCc miaoshaGoods(JSONObject jsonObject) {        String seckillId = jsonObject.getString("seckillId");        int seckillIdInt = Integer.parseInt(seckillId);        String methodType = jsonObject.getString("methodType");        int methodTypeInt = Integer.parseInt(methodType);        //校验参数是否全        if(CheckUtil.checkIsNullAndEmpty(methodType) && CheckUtil.checkIsNullAndEmpty(seckillIdInt)){            int countSuc=0;            ResultCc error = ResultCc.error("抢购失败");            //通过方法实现不同业务            switch (methodTypeInt){                //普通无处理秒杀处理                case 1:                    if (toSeckill(seckillIdInt)){ return error;}                    break;                case 2:                    //乐观锁处理的高并发秒杀实现                    break;                case 3:                    //悲观锁处理的高并发秒杀实现                    break;                case 4:                    //线程同步锁处理的高并发秒杀实现                    synchronized (this){                        if (toSeckill(seckillIdInt)){ return error;}                    }                    break;                case 5:                    //线程可重入锁处理的高并发秒杀实现                    lock.lock();                    if (toSeckill(seckillIdInt)){ return error;}                    lock.unlock();                    break;                case 6:                    //redis实现秒杀                    CpSeckill seckill = cpSeckillMapper.selectById(seckillIdInt);                    //增量计算剩余库存(利用redis的单线程特性)                    //redisTemplate.opsForValue().increment(seckill.getName()+":goodsSum",-1);                    //采用分布式集群方式                    HostAndPort hostAndPort = new HostAndPort("101.37.145.206", 6379);                    Set<HostAndPort> hostAndPortSet = new HashSet<>();                    hostAndPortSet.add(hostAndPort);                    JedisCluster jedis = new JedisCluster(hostAndPortSet);                    double goodsSurplusSum = jedis.incrBy(seckill.getName()+":goodsSum",-1);                    if(goodsSurplusSum>=0){                        if (toSeckill(seckillIdInt)){ return error;}                        System.out.println("秒杀成功！");                    }else{                        System.out.println("秒杀失败！");                    }                    break;                case 7:                    //使用线程池来限定秒杀次数 以此来确保秒杀精准性                    break;            }        }else{            return ResultCc.error("参数不足");        }        return null;    }    private boolean toSeckill(Integer id) {        int countSuc;//1.获取秒杀商品        CpSeckill seckill = cpSeckillMapper.selectById(id);        //获取库存        Integer seckillNum = seckill.getSeckillNum();        if(seckillNum > 0 ){            //减去库存            seckill.setSeckillNum(seckillNum - 1);            //执行修改方法            countSuc = cpSeckillMapper.updateById(seckill);            outMethod(countSuc);        }else{            return true;        }        return false;    }    private void outMethod(int countSuc) {        if(countSuc==1){            System.out.println("秒杀成功！");        }else{            System.out.println("秒杀失败！");        }    }
   ~~~

   

## 三：框架类

### 3.1  Spring 

#### 3.1.1 概述

   Spring 框架是一个开源的 Java 平台，它最初是由 Rod Johnson 编写的，并且于 2003 年 6 月首次在 Apache 2.0 许可下发布。

  Spring 是轻量级的框架，其基础版本只有 2 MB 左右的大小。

#### 3.1.2 Spring 架构

- A 表现层  web层  MVC是表现层的一个设计模型 

- B 业务层 service层

- C 持久层 dao层

#### 3.1.3  Spring 特效

- 非侵入式：基于Spring开发的应用中的对象可以不依赖于Spring的API
- 控制反转：IOC——Inversion of Control，指的是将对象的创建权交给 Spring 去创建。使用 Spring 之前，对象的创建都是由我们自己在代码中new创建。而使用 Spring 之后。对象的创建都是给了 Spring 框架。
- 依赖注入：DI——Dependency Injection，是指依赖的对象不需要手动调用 setXX 方法去设置，而是通过配置赋值。
- 面向切面编程：Aspect Oriented Programming——AOP
- 容器：Spring 是一个容器，因为它包含并且管理应用对象的生命周期
- 组件化：Spring 实现了使用简单的组件配置组合成一个复杂的应用。在 Spring 中可以使用XML和Java注解组合这些对象。
- 一站式：在 IOC 和 AOP 的基础上可以整合各种企业应用的开源框架和优秀的第三方类库（实际上 Spring 自身也提供了表述层的 SpringMVC 和持久层的 Spring JDBC）

#### 3.1.4 Spring 核心

##### 3.1.4.1 AOP面向切面

```
Spring 框架的一个关键组件是面向切面的程序设计（AOP）框架。一个程序中跨越多个点的功能被称为横切关注点，这些横切关注点在概念上独立于应用程序的业务逻辑。有各种各样常见的很好的关于方面的例子，比如日志记录、声明性事务、安全性，和缓存等等。方便解耦
```

##### 3.1.4.2 DI 依赖注入

```xml
Spring 最认同的技术是控制反转的依赖注入（DI）模式。控制反转（IoC）是一个通用的概念，它可以用许多不同的方式去表达，依赖注入仅仅是控制反转的一个具体的例子。当编写一个复杂的 Java 应用程序时，应用程序类应该尽可能的独立于其他的 Java 类来增加这些类可重用可能性，当进行单元测试时，可以使它们独立于其他类进行测试。依赖注入（或者有时被称为配线）有助于将这些类粘合在一起，并且在同一时间让它们保持独立。
```

#### 3.1.5 Sprig组件

![Spring 体系结构](https://atts.w3cschool.cn/attachments/image/20181023/1540290875453691.png)

#### 3.1.6 数据访问/集成

数据访问/集成层包括 JDBC，ORM，OXM，JMS 和事务处理模块，它们的细节如下：

（注：JDBC=Java Data Base Connectivity，ORM=Object Relational Mapping，OXM=Object XML Mapping，JMS=Java Message Service）

- **JDBC** 模块提供了 JDBC 抽象层，它消除了冗长的 JDBC 编码和对数据库供应商特定错误代码的解析。
- **ORM** 模块提供了对流行的对象关系映射 API 的集成，包括 JPA、JDO 和 Hibernate 等。通过此模块可以让这些 ORM 框架和 spring的其它功能整合，比如前面提及的事务管理。
- **OXM** 模块提供了对 OXM 实现的支持，比如 JAXB、Castor、XML Beans、JiBX、XStream 等。
- **JMS** 模块包含生产（produce）和消费（consume）消息的功能。从 Spring 4.1 开始，集成了 spring-messaging 模块。
- **事务**模块为实现特殊接口类及所有的 POJO 支持编程式和声明式事务管理。（注：编程式事务需要自己写 beginTransaction()、commit()、rollback() 等事务管理方法，声明式事务是通过注解或配置由 spring 自动处理，编程式事务力度更细）

https://www.w3cschool.cn/wkspring/

### 3.2  Mybatis

### 3.3  Spring mvc

### 3.4  Hibernate

### 3.5  SpringBoot

#### 3.5.1 SpringBoot 配置

```yaml
server:  port: 8080  servlet:    context-path: /cpos    compression:      enabled: true      mime-types: application/javascript,application/json,application/xml,text/html,text/xml,text/plain,text/css,image/*spring:  resources:    static-locations: classpath:/static/  servlet:    multipart:      max-file-size: 10MB      max-request-size: 100MB  datasource:    driver-class-name:    #本地数据库    url: jdbc:mysql://127.0.0.1:3306/cpos?useUnicode=true&characterEncoding=utf-8&serverTimezone=UTC    username: root    password: lwl135    type:
```

#### 3.5.2 环境搭建

  https://start.spring.io/      搭建Springboot demo项目

![image-20201129232723081](C:\Users\lei41\AppData\Roaming\Typora\typora-user-images\image-20201129232723081.png)

 IDEA创建 SpringBoot项目

![image-20201129232844361](C:\Users\lei41\AppData\Roaming\Typora\typora-user-images\image-20201129232844361.png)



#### 3.5.3 SpringBoot 格式统一

  RestFul风格  例如： localhost:8080/cpos/api/test/con1

#### 3.5.4 SpringBoot 统一拦截器

https://www.w3cschool.cn/springboot

#### 3.5.5 SpringBoot 常用注解详解

##### @ControllerAdvice

很多初学者可能都没有听说过这个注解，实际上，这是一个非常有用的注解，顾名思义，这是一个增强的 Controller。使用这个 Controller ，可以实现三个方面的功能：

1. 全局异常处理
2. 全局数据绑定
3. 全局数据预处理

灵活使用这三个功能，可以帮助我们简化很多工作，需要注意的是，这是 SpringMVC 提供的功能，在 Spring Boot 中可以直接使用，下面分别来看

###### 全局异常处理

使用 @ControllerAdvice 实现全局异常处理，只需要定义类，添加该注解即可定义方式如下：

~~~java
@ControllerAdvicepublic class MyGlobalExceptionHandler {    @ExceptionHandler(Exception.class)    public ModelAndView customException(Exception e) {        ModelAndView mv = new ModelAndView();        mv.addObject("message", e.getMessage());        mv.setViewName("myerror");        return mv;    }}
~~~

在该类中，可以定义多个方法，不同的方法处理不同的异常，例如专门处理空指针的方法、专门处理数组越界的方法...，也可以直接向上面代码一样，在一个方法中处理所有的异常信息。

@ExceptionHandler 注解用来指明异常的处理类型，即如果这里指定为 NullpointerException，则数组越界异常就不会进到这个方法中来。

###### 全局数据绑定

全局数据绑定功能可以用来做一些初始化的数据操作，我们可以将一些公共的数据定义在添加了 @ControllerAdvice 注解的类中，这样，在每一个 Controller 的接口中，就都能够访问导致这些数据。

使用步骤，首先定义全局数据，如下：

~~~java
@ControllerAdvicepublic class MyGlobalExceptionHandler {    @ModelAttribute(name = "md")    public Map<String,Object> mydata() {        HashMap<String, Object> map = new HashMap<>();        map.put("age", 99);        map.put("gender", "男");        return map;    }}
~~~

使用 @ModelAttribute 注解标记该方法的返回数据是一个全局数据，默认情况下，这个全局数据的 key 就是返回的变量名，value 就是方法返回值，当然开发者可以通过 @ModelAttribute 注解的 name 属性去重新指定 key。

定义完成后，在任何一个Controller 的接口中，都可以获取到这里定义的数据：

~~~java
@RestControllerpublic class HelloController {    @GetMapping("/hello")    public String hello(Model model) {        Map<String, Object> map = model.asMap();        System.out.println(map);        int i = 1 / 0;        return "hello controller advice";    }}
~~~

###### 全局数据预处理

考虑我有两个实体类，Book 和 Author，分别定义如下：

~~~java
public class Book {    private String name;    private Long price;    //getter/setter}public class Author {    private String name;    private Integer age;    //getter/setter}
~~~

此时，如果我定义一个数据添加接口，如下：

~~~java
@PostMapping("/book")public void addBook(Book book, Author author) {    System.out.println(book);    System.out.println(author);}
~~~

这个时候，添加操作就会有问题，因为两个实体类都有一个 name 属性，从前端传递时 ，无法区分。此时，通过 @ControllerAdvice 的全局数据预处理可以解决这个问题

解决步骤如下:

1.给接口中的变量取别名

~~~java
@PostMapping("/book")public void addBook(@ModelAttribute("b") Book book, @ModelAttribute("a") Author author) {    System.out.println(book);    System.out.println(author);}
~~~

2.进行请求数据预处理
在 @ControllerAdvice 标记的类中添加如下代码:

~~~java
@InitBinder("b")public void b(WebDataBinder binder) {    binder.setFieldDefaultPrefix("b.");}@InitBinder("a")public void a(WebDataBinder binder) {    binder.setFieldDefaultPrefix("a.");}
~~~

@InitBinder("b") 注解表示该方法用来处理和Book和相关的参数,在方法中,给参数添加一个 b 前缀,即请求参数要有b前缀.

3.发送请求

请求发送时,通过给不同对象的参数添加不同的前缀,可以实现参数的区分.

![img](https://www.javaboy.org/images/boot/5-1.png)

### 3.6  SpringCloud

https://www.springcloud.cc/spring-cloud-config.html

#### 3.6.1 组件介绍

​    Spring Cloud由众多子项目组成，如Spring Cloud Config、Spring Cloud Netflix、Spring Cloud Consul 等，提供了搭建分布式系统及微服务常用的工具，如配置管理、服务发现、断路器、智能路由、微代理、控制总线、一次性token、全局锁、选主、分布式会话和集群状态等，满足了构建微服务所需的所有解决方案。

##### 3.6.1.1 服务发现——Netflix Eureka

  一个RESTful服务，用来定位运行在AWS地区（Region）中的中间层服务。由两个组件组成：Eureka服务器和Eureka客户端。Eureka服务器用作服务注册服务器。Eureka客户端是一个java客户端，用来简化与服务器的交互、作为轮询负载均衡器，并提供服务的故障切换支持。Netflix在其生产环境中使用的是另外的客户端，它提供基于流量、资源利用率以及出错状态的加权负载均衡。

##### 3.6.1.2 客服端负载均衡——Netflix Ribbon

Ribbon客户端组件提供一系列完善的配置选项，比如连接超时、重试、重试算法等。Ribbon内置可插拔、可定制的负载均衡组件。下面是用到的一些负载均衡策略：

- 简单轮询负载均衡
- 加权响应时间负载均衡
- 区域感知轮询负载均衡
- 随机负载均衡

Ribbon中还包括以下功能：

- 易于与服务发现组件（比如Netflix的Eureka）集成
- 使用Archaius完成运行时配置
- 使用JMX暴露运维指标，使用Servo发布
- 多种可插拔的序列化选择
- 异步和批处理操作（即将推出）
- 自动SLA框架（即将推出）
- 系统管理/指标控制台（即将推出）

##### 3.6.1.3 断路器——Netflix Hystrix

​    断路器可以防止一个应用程序多次试图执行一个操作，即很可能失败，允许它继续而不等待故障恢复或者浪费 CPU 周期，而它确定该故障是持久的。断路器模式也使应用程序能够检测故障是否已经解决。如果问题似乎已经得到纠正，应用程序可以尝试调用操作。



   断路器增加了稳定性和灵活性，以一个系统，提供稳定性，而系统从故障中恢复，并尽量减少此故障的对性能的影响。它可以帮助快速地拒绝对一个操作，即很可能失败，而不是等待操作超时（或者不返回）的请求，以保持系统的响应时间。如果断路器提高每次改变状态的时间的事件，该信息可以被用来监测由断路器保护系统的部件的健康状况，或以提醒管理员当断路器跳闸，以在打开状态。

![img](https://upload-images.jianshu.io/upload_images/13418826-e3a53f6ab0e51889.png?imageMogr2/auto-orient/strip|imageView2/2/format/webp)

##### 3.6.1.4 服务网关——Netflix Zuul	

类似nginx，反向代理的功能，不过netflix自己增加了一些配合其他组件的特性。

##### 3.6.1.5 分布式配置——Spring Cloud Config

![img](https://upload-images.jianshu.io/upload_images/13418826-842214bc1df8f310.png?imageMogr2/auto-orient/strip|imageView2/2/w/498/format/webp)

这个还是静态的，得配合Spring Cloud Bus实现动态的配置更新

##### 3.6.1.6 微服务网关getway

  Spring cloud gateway是spring官方基于Spring 5.0、Spring Boot2.0和Project Reactor等技术开发的网关，Spring Cloud Gateway旨在为微服务架构提供简单、有效和统一的API路由管理方式，Spring Cloud Gateway作为Spring Cloud生态系统中的网关，目标是替代Netflix Zuul，其不仅提供统一的路由方式，并且还基于Filer链的方式提供了网关基本的功能，例如：安全、监控/埋点、限流等。

  推荐文章：https://blog.csdn.net/squirrelanimal0922/article/details/90517946

#### 3.6.2 实战应用

### 3.7 Sentinel 

#### 是什么

随着微服务的流行，服务和服务之间的稳定性变得越来越重要。Sentinel 是面向分布式服务架构的流量控制组件，主要以流量为切入点，从限流、流量整形、熔断降级、系统负载保护、热点防护等多个维度来帮助开发者保障微服务的稳定性。



#### 如何工作

Sentinel 的主要工作机制如下：

- 对主流框架提供适配或者显示的 API，来定义需要保护的资源，并提供设施对资源进行实时统计和调用链路分析。
- 根据预设的规则，结合对资源的实时统计信息，对流量进行控制。同时，Sentinel 提供开放的接口，方便您定义及改变规则。
- Sentinel 提供实时的监控系统，方便您快速了解目前系统的状态



#### 相比Hystrix



#### 相同

Sentinel 和 Hystrix 的原则是一致的: 当检测到调用链路中某个资源出现不稳定的表现，例如请求响应时间长或异常比例升高的时候，则对这个资源的调用进行限制，让请求快速失败，避免影响到其它的资源而导致级联故障。



#### 不同点

在限制的手段上，Sentinel 和 Hystrix 采取了完全不一样的方法。

Hystrix 通过 [线程池隔离](https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FNetflix%2FHystrix%2Fwiki%2FHow-it-Works%23benefits-of-thread-pools) 的方式，来对依赖（在 Sentinel 的概念中对应 *资源*）进行了隔离。这样做的好处是资源和资源之间做到了最彻底的隔离。缺点是除了增加了线程切换的成本（过多的线程池导致线程数目过多），还需要预先给各个资源做线程池大小的分配。

Sentinel 对这个问题采取了两种手段:

- 通过并发线程数进行限制

和资源池隔离的方法不同，Sentinel 通过限制资源并发线程的数量，来减少不稳定资源对其它资源的影响。这样不但没有线程切换的损耗，也不需要您预先分配线程池的大小。当某个资源出现不稳定的情况下，例如响应时间变长，对资源的直接影响就是会造成线程数的逐步堆积。当线程数在特定资源上堆积到一定的数量之后，对该资源的新请求就会被拒绝。堆积的线程完成任务后才开始继续接收请求。

- 通过响应时间对资源进行降级

除了对并发线程数进行控制以外，Sentinel 还可以通过响应时间来快速降级不稳定的资源。当依赖的资源出现响应时间过长后，所有对该资源的访问都会被直接拒绝，直到过了指定的时间窗口之后才重新恢复。



#### Sentinel 控制台

Sentinel 提供一个轻量级的开源控制台，它提供机器发现以及健康情况管理、监控（单机和集群），规则管理和推送的功能。另外，鉴权在生产环境中也必不可少

文档地址：[https://github.com/alibaba/Sentinel/wiki/%E6%8E%A7%E5%88%B6%E5%8F%B0](https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Falibaba%2FSentinel%2Fwiki%2F%E6%8E%A7%E5%88%B6%E5%8F%B0)



#### 如何使用

这里介绍了怎么使用到我们项目中的文档，相当详细，阿里的开源做的很好

[https://github.com/alibaba/Sentinel/wiki/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8](https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Falibaba%2FSentinel%2Fwiki%2F%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8)



##### windos下安装sentinel 

###### 下载：

下载地址：https://github.com/alibaba/Sentinel/releases

下载会很慢，下面给出下载地址

链接：https://pan.baidu.com/s/1nQ9VlxYItAhuAYYXSp22gQ 
提取码：ql72



在本地用下面命令启动  java -jar (sentinel-dashboard-jar包)



浏览器访问 http://localhost:8858/

用户名和密码都是 sentinel

### 3.8  nacos 

##### windows下安装nacos

1、下载
下载地址：https://github.com/alibaba/nacos/releases/tag/1.1.0

选择这个zip下载。

下载完毕后我们可以看看目录结构：



这里的bin目录里面有windows启动文件startup.cmd，我们双击就能启动了，和大多数windows进程类似。

启动后会有一个cmd窗口去打印命令并启动。



这里我们启动成功了，启动失败后窗口会一闪而过。

2、访问
访问地址：http://localhost:8848/nacos/index.html

用户名密码：nacos/nacos



##### linux下安装nacos

- 下载地址[.tar.gz] https://github.com/alibaba/nacos/releases

- ~~~
  tar -zxvf nacos-server-1.1.4.tar.gz mv nacos /usr/local
  ~~~

- 单机模式启动 

- ~~~
  cd /usr/local/nacos/binsh startup.sh -m standalone
  ~~~

- 启动

- ~~~
  bash startup.sh -m standalone
  ~~~

- 启动时报错

- 错误一

- ~~~
  /usr/java/jdk1.8.0_181/bin/java  -Xms512m -Xmx512m -Xmn256m -Dnacos.standalone=true -Djava.ext.dirs=/usr/java/jdk1.8.0_181/jre/lib/ext:/usr/java/jdk1.8.0_181/lib/ext:/usr/local/nacos/plugins/cmdb:/usr/local/nacos/plugins/mysql -Xloggc:/usr/local/nacos/logs/nacos_gc.log -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=100M -Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=8000 -Dnacos.home=/usr/local/nacos -Dloader.path=/usr/local/nacos/plugins/health -jar /usr/local/nacos/target/nacos-server.jar  --spring.config.location=classpath:/,classpath:/config/,file:./,file:./config/,file:/usr/local/nacos/conf/ --logging.config=/usr/local/nacos/conf/nacos-logback.xml --server.max-http-header-size=524288nacos is starting with standalonenacos is starting，you can check the /usr/local/nacos/logs/start.out
  ~~~

  查看/usr/local/nacos/logs/start.out,看文件中提示具体什么错误

  如报下面错误：

  ~~~java
  java.io.FileNotFoundException: /usr/local/nacos/conf/cluster.conf (没有那个文件或目录)	at java.io.FileInputStream.open0(Native Method)	at java.io.FileInputStream.open(FileInputStream.java:195)	at java.io.FileInputStream.<init>(FileInputStream.java:138)	at com.alibaba.nacos.core.utils.SystemUtils.readClusterConf(SystemUtils.java:124)	at com.alibaba.nacos.core.listener.StartingSpringApplicationRunListener.logClusterConf(StartingSpringApplicationRunListener.java:141)	at com.alibaba.nacos.core.listener.StartingSpringApplicationRunListener.contextPrepared(StartingSpringApplicationRunListener.java:91)	at org.springframework.boot.SpringApplicationRunListeners.contextPrepared(SpringApplicationRunListeners.java:60)	at org.springframework.boot.SpringApplication.prepareContext(SpringApplication.java:374)	at org.springframework.boot.SpringApplication.run(SpringApplication.java:314)	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1260)	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1248)	at com.alibaba.nacos.Nacos.main(Nacos.java:33)	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)	at java.lang.reflect.Method.invoke(Method.java:498)	at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner.java:48)	at org.springframework.boot.loader.Launcher.launch(Launcher.java:87)	at org.springframework.boot.loader.Launcher.launch(Launcher.java:50)	at org.springframework.boot.loader.PropertiesLauncher.main(PropertiesLauncher.java:593)
  ~~~

  解决方案

  - 由于启动的默认由cluster改成了standalone单机启动模式，但是启动仍然是集群模式启动，并且抛出上述找不到cluster.conf文件

  - ~~~
    bash startup.sh -m standalone
    ~~~

  - 错误二

  - ~~~
    systemctl start nacos.service
    ~~~

  - 报如下错误

    ~~~
    nacos.service   Loaded: loaded (/usr/lib/systemd/system/nacos.service; bad; vendor preset: disabled)   Active: failed (Result: exit-code) since 一 2019-10-28 22:31:25 CST; 19s ago  Process: 2847 ExecStart=/usr/local/nacos/bin/startup.sh -m standalone (code=exited, status=1/FAILURE)10月 28 22:31:25 localhost.localdomainP1 startup.sh[2847]: which: no javac in (/usr/...10月 28 22:31:25 localhost.localdomainP1 startup.sh[2847]: readlink: 缺少操作数10月 28 22:31:25 localhost.localdomainP1 startup.sh[2847]: Try 'readlink --help' for...10月 28 22:31:25 localhost.localdomainP1 systemd[1]: nacos.service: control process...110月 28 22:31:25 localhost.localdomainP1 startup.sh[2847]: dirname: 缺少操作数10月 28 22:31:25 localhost.localdomainP1 startup.sh[2847]: Try 'dirname --help' for ...10月 28 22:31:25 localhost.localdomainP1 systemd[1]: Failed to start nacos.service.10月 28 22:31:25 localhost.localdomainP1 startup.sh[2847]: ERROR: Please set the JAV...10月 28 22:31:25 localhost.localdomainP1 systemd[1]: Unit nacos.service entered fai....10月 28 22:31:25 localhost.localdomainP1 systemd[1]: nacos.service failed.
    ~~~

    #### 解决方案

    需要更改相应启动文件的JDK配置
    将如下三行注释掉，并将第一行的配置修改为JDK的位置。

    如何找到JDK位置

    ~~~
    whereis java
    ~~~

    找到JDK的位置为: /usr/java/jdk1.8.0_181

    ~~~
    vim startup.sh
    ~~~

    原文

    ~~~
    [ ! -e "$JAVA_HOME/bin/java" ] && JAVA_HOME=$HOME/jdk/java[ ! -e "$JAVA_HOME/bin/java" ] && JAVA_HOME=/usr/java[ ! -e "$JAVA_HOME/bin/java" ] && JAVA_HOME=/opt/taobao/java[ ! -e "$JAVA_HOME/bin/java" ] && unset JAVA_HOME
    ~~~

    修改后

    ~~~
    [ ! -e "$JAVA_HOME/bin/java" ] && JAVA_HOME=/usr/java/jdk1.8.0_181#[ ! -e "$JAVA_HOME/bin/java" ] && JAVA_HOME=/usr/java#[ ! -e "$JAVA_HOME/bin/java" ] && JAVA_HOME=/opt/taobao/java#[ ! -e "$JAVA_HOME/bin/java" ] && unset JAVA_HOME
    ~~~

    

访问web地址

~~~
curl http://127.0.0.1:8848/nacos/index.html
~~~

http://127.0.0.1:8848/nacos/index.html
登录的用户名和密码默认的都是nacos



###### 注意防火墙的端口8848

集群

本例的安装目录为/usr/local/nacos

参考链接： https://www.cnblogs.com/lhlucky/p/nacoscluster.html

###### 1.配置 cluster.conf文件

- 在文件里添加相关服务器IP，三台机器都做相同的配置

- ~~~
  cd /usr/local/nacos/confcp cluster.conf.example cluster.confvim cluster.conf
  ~~~

- cluster.conf文件内容为：

- ~~~
  #it is ip#example#10.10.109.214#11.16.128.34#11.16.128.36192.168.47.128:8848192.168.47.129:8848192.168.47.130:8848
  ~~~

- ###### 2.创建数据库

- 脚本位置 /usr/local/nacos/conf/nacos-mysql.sql

- 将脚本里的SQL语句直接导入既可

- ###### 3.配置application.properties

- ~~~
  cd /usr/local/nacos/confvim application.properties
  ~~~

- 增加内容为:

- ~~~
  spring.datasource.platform=mysqldb.num=1db.url.0=jdbc:mysql://192.168.47.128:5186/nacos_config?serverTimezone=GMT%2B8&characterEncoding=utf8&connectTimeout=1000&socketTimeout=3000&autoReconnect=truedb.user=cicidb.password=123123
  ~~~

- ###### 4.分别启动三台服务器

  ~~~
  cd /usr/local/nacos/binsh startup.sh
  ~~~

  

- 观察日志,看是否有异常打印【cat或者tailf命令】

  /usr/local/nacos/logs/nacos.log
  /usr/local/nacos/logs/naming-raft.log
  /usr/local/nacos/logs/start.out
  启动成功后访问，观察集群

  http://192.168.47.128:8848/nacos/index.html

  http://192.168.47.129:8848/nacos/index.html

  http://192.168.47.130:8848/nacos/index.html

- ###### 5.遇到的问题一

###### 5.1 mysql8问题

直接下载的稳定版本nacos编译后的文件，不支持mysql8及其以上版本，本例中使用的为1.1.4版本

-参考链接
https://www.cnblogs.com/gyli20170901/p/11245270.html

###### 解决方案

下载nacos的源码并更改mysql驱动的版本

###### 5.1.1 下载地址

https://github.com/alibaba/nacos

###### 5.1.2 修改

修改最外层pom.xml 中 mysql驱动版本，我这边使用的是8.0.16

<dependency>
    <groupId>mysql</groupId>
    <artifactId>mysql-connector-java</artifactId>
    <version>8.0.16</version>
</dependency>

###### 5.1.3 修改naming这个项目 com.alibaba.nacos.naming.healthcheck 包下的 MysqlHealthCheckProcessor 类的第24行导包为

import com.mysql.cj.jdbc.MysqlDataSource;


###### 5.1.4修改console项目下的配置文件

-由于mysql8及其以上版本需要带时区，所以还需要修改 console这项目 resources/META-INF下 nacos-default.properties这个文件中的db.url



~~~
db.url.0=jdbc:mysql://11.162.196.161:3306/diamond_devtest?serverTimezone=GMT%2B8&characterEncoding=utf8&connectTimeout=1000&socketTimeout=3000&autoReconnect=truedb.url.1=jdbc:mysql://11.163.152.91:3306/diamond_devtest?serverTimezone=GMT%2B8&characterEncoding=utf8&connectTimeout=1000&socketTimeout=3000&autoReconnect=true
~~~



###### 5.1.5 打包

cmd命令窗口进入项目根目录执行

mvn -Prelease-nacos clean install -U


###### 5.1.6 打包完成后，再次安装nacos，步骤按照上面安装的说明

包的地址[根目录\distribution\target]

###### 5.1.7 再次修改application.properties配置文件

~~~
cd /usr/local/nacos/confvim application.properties
~~~



修改为

~~~
spring.datasource.platform=mysqldb.num=1db.url.0=jdbc:mysql://192.168.47.128:5186/nacos_config?serverTimezone=GMT%2B8&characterEncoding=utf8&connectTimeout=1000&socketTimeout=3000&autoReconnect=truedb.user=cicidb.password=123123
~~~





###### 5.2 unable to find local peer: 192.168.47.128:8848

~~~java
java.lang.IllegalStateException: unable to find local peer: 172.16.26.250:8848, all peers: [120.79.167.88:8848, 119.23.104.130:8848, 47.101.47.127:8848]	at com.alibaba.nacos.naming.consistency.persistent.raft.RaftPeerSet.local(RaftPeerSet.java:224)	at com.alibaba.nacos.naming.monitor.PerformanceLoggerThread.collectMetrics(PerformanceLoggerThread.java:100)	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)	at java.lang.reflect.Method.invoke(Method.java:498)	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:93)	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)	at java.util.concurrent.FutureTask.run(FutureTask.java:266)	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)	at java.lang.Thread.run(Thread.java:748)2019-10-18 14:06:45,000 ERROR Unexpected error occurred in scheduled task.
~~~






因为我部署的三台服务器是虚拟机上的，属于内网，都是在一个网段的。

解决方案

编辑启动文件 /usr/local/nacos/bin/startup.sh

~~~
vim /usr/local/nacos/bin/startup.sh
~~~



依次修改三台服务器的启动文件

###### 单机模式对应的启动参数

~~~
if [[ "${MODE}" == "standalone" ]]; then    JAVA_OPT="${JAVA_OPT} -Xms512m -Xmx512m -Xmn256m"    JAVA_OPT="${JAVA_OPT} -Dnacos.standalone=true"else
~~~



###### 集群模式对应的启动参数

    JAVA_OPT="${JAVA_OPT} -server -Xms2g -Xmx2g -Xmn1g -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m"JAVA_OPT="${JAVA_OPT} -XX:-OmitStackTraceInFastThrow -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=${BASE_DIR}/logs/java_heapdump.hprof"JAVA_OPT="${JAVA_OPT} -XX:-UseLargePages"# *新增以下参数设置本机ip地址*JAVA_OPT="${JAVA_OPT} -Dnacos.server.ip=192.168.47.128"

~~~
fiif [[ "${FUNCTION_MODE}" == "config" ]]; then    JAVA_OPT="${JAVA_OPT} -Dnacos.functionMode=config"elif [[ "${FUNCTION_MODE}" == "naming" ]]; then    JAVA_OPT="${JAVA_OPT} -Dnacos.functionMode=naming"fi
~~~



修改之后再次启动即可

#关闭服务

~~~
cd /usr/local/nacos/bin./shutdown.sh
~~~



#启动服务

~~~
sh startup.sh
~~~



## 四：业务类

### 4.1  金融业务

### 4.2  社交业务

### 4.3  医疗业务

### 4.4  政务业务

### 4.5  电商业务

## 五：中间件

### 5.1 ActiveMQ

#### 5.1.1 概述

​    ActiveMQ是Apache所提供的一个开源的消息系统，完全采用Java来实现，因此，它能很好地支持J2EE提出的JMS（Java Message Service,即Java消息服务）规范。JMS是一组Java应用程序接口，它提供消息的创建、发送、读取等一系列服务。JMS提供了一组公共应用程序接口和响应的语法，类似于Java数据库的统一访问接口JDBC,它是一种与厂商无关的API，使得Java程序能够与不同厂商的消息组件很好地进行通信。

#### 5.1.2  JMS简介

JMS支持两种消息发送和接收模型。

- 一种称为P2P(Ponit to Point)模型，即采用点对点的方式发送消息。P2P模型是基于队列的，消息生产者发送消息到队列，消息消费者从队列中接收消息，队列的存在使得消息的异步传输称为可能，P2P模型在点对点的情况下进行消息传递时采用。

- ![img](https://upload-images.jianshu.io/upload_images/3110861-d5903d5c31002368.png)

- 另一种称为Pub/Sub(Publish/Subscribe，即发布-订阅)模型，发布-订阅模型定义了如何向一个内容节点发布和订阅消息，这个内容节点称为topic(主题)。主题可以认为是消息传递的中介，消息发布这将消息发布到某个主题，而消息订阅者则从主题订阅消息。主题使得消息的订阅者与消息的发布者互相保持独立，不需要进行接触即可保证消息的传递，发布-订阅模型在消息的一对多广播时采用。

- ![img](https://upload-images.jianshu.io/upload_images/3110861-78a5559c4f70ee40.png)

  #### 5.1.3 JMS术语

  - Provider/MessageProvider：生产者
  - Consumer/MessageConsumer：消费者
  - PTP：Point To Point，点对点通信消息模型
  - Pub/Sub：Publish/Subscribe，发布订阅消息模型
  - Queue：队列，目标类型之一，和PTP结合
  - Topic：主题，目标类型之一，和Pub/Sub结合
  - ConnectionFactory：连接工厂，JMS用它创建连接
  - Connnection：JMS Client到JMS Provider的连接
  - Destination：消息目的地，由Session创建
  - Session：会话，由Connection创建，实质上就是发送、接受消息的一个线程，因此生产者、消费者都是Session创建的

#### 5.1.4  Window下安装ActiveMQ

​    1、下载地址：http://activemq.apache.org/download-archives.html ，本文用的是windows版的5.15.3版本，下载下来是压缩包。[apache-activemq-5.15.3-bin.zip](http://archive.apache.org/dist/activemq/5.15.3/apache-activemq-5.15.3-bin.zip) 

​    2、将压缩包解压一个到目录下，CMD进入到解压目录下的bin目录下，执行 activemq.bat start 启动。  如果能成功访问 http://localhost:8161/admin（用户名和密码默认为admin），则启动成功。

#### 5.1.5   ActiveMq集成项目

```xml
<!--ActiveMq-->        <dependency>            <groupId>org.springframework.boot</groupId>            <artifactId>spring-boot-starter-activemq</artifactId>            <version>1.5.0.RELEASE</version>        </dependency>        <!--消息队列连接池-->        <dependency>            <groupId>org.apache.activemq</groupId>            <artifactId>activemq-pool</artifactId>            <version>5.15.0</version>        </dependency>
```

   topic模式有普通订阅和持久化订阅

普通订阅：在消费者启动之前发送过来的消息，消费者启动之后不会去消费；

持久化订阅： 在消费者启动之前发送过来的消息，消费者启动之后会去消费

### 5.2 RebbitMQ

特点

- 开源、性能优秀，稳定性保障
- 提供可靠性消息投递模式、返回模式
- 与Spring AMQP完美整合，API丰富
- 集群模式丰富，表达式配置，HA模式，镜像队列模型
- 保证数据不丢失的前提做到高可靠性、可用性



MQ典型应用场景：

- 异步处理。把消息放入消息中间件中，等到需要的时候再去处理。
- 流量削峰。例如秒杀活动，在短时间内访问量急剧增加，使用消息队列，当消息队列满了就拒绝响应，跳转到错误页面，这样就可以使得系统不会因为超负载而崩溃。
- 日志处理
- 应用解耦。假设某个服务A需要给许多个服务（B、C、D）发送消息，当某个服务（例如B）不需要发送消息了，服务A需要改代码再次部署；当新加入一个服务（服务E）需要服务A的消息的时候，也需要改代码重新部署；另外服务A也要考虑其他服务挂掉，没有收到消息怎么办？要不要重新发送呢？是不是很麻烦，使用MQ发布订阅模式，服务A只生产消息发送到MQ，B、C、D从MQ中读取消息，需要A的消息就订阅，不需要了就取消订阅，服务A不再操心其他的事情，使用这种方式可以降低服务或者系统之间的耦合。



提到RabbitMQ，就不得不提AMQP协议。AMQP协议是具有现代特征的二进制协议。是一个提供统一消息服务的应用层标准高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计。

先了解一下AMQP协议中间的几个重要概念：

- Server：接收客户端的连接，实现AMQP实体服务。
- Connection：连接，应用程序与Server的网络连接，TCP连接。
- Channel：信道，消息读写等操作在信道中进行。客户端可以建立多个信道，每个信道代表一个会话任务。
- Message：消息，应用程序和服务器之间传送的数据，消息可以非常简单，也可以很复杂。有Properties和Body组成。Properties为外包装，可以对消息进行修饰，比如消息的优先级、延迟等高级特性；Body就是消息体内容。
- Virtual Host：虚拟主机，用于逻辑隔离。一个虚拟主机里面可以有若干个Exchange和Queue，同一个虚拟主机里面不能有相同名称的Exchange或Queue。
- Exchange：交换器，接收消息，按照路由规则将消息路由到一个或者多个队列。如果路由不到，或者返回给生产者，或者直接丢弃。RabbitMQ常用的交换器常用类型有direct、topic、fanout、headers四种，后面详细介绍。
- Binding：绑定，交换器和消息队列之间的虚拟连接，绑定中可以包含一个或者多个RoutingKey。
- RoutingKey：路由键，生产者将消息发送给交换器的时候，会发送一个RoutingKey，用来指定路由规则，这样交换器就知道把消息发送到哪个队列。路由键通常为一个“.”分割的字符串，例如“com.rabbitmq”。
- Queue：消息队列，用来保存消息，供消费者消费。

![img](https://img2018.cnblogs.com/blog/1538609/201907/1538609-20190720105435977-1170222541.png)

- 我选择3.8.0-beta.4-management进行安装，带有management是含有管理界面的。
- 拉取镜像和启动：`docker run -d --hostname my-rabbit -p 5672:5672 -p 15672:15672 rabbitmq:3.8.0-beta.4-management`
- 查看镜像：

```
[root@localhost ~]# docker imagesREPOSITORY              TAG                       IMAGE ID            CREATED             SIZEdocker.io/rabbitmq      3.8.0-beta.4-management   d0f93d2b83f7        3 days ago          180 MB
```

- 打开浏览器访问localhost:15672，如果你和我一样装在虚拟机上面的话，需要打开虚拟机ip:15672
- ![img](https://img2018.cnblogs.com/blog/1538609/201907/1538609-20190720105925148-289286470.png)
- 进行填写账号密码：默认账号密码都是guest.
- ![img](https://img2018.cnblogs.com/blog/1538609/201907/1538609-20190720105939506-1976176866.png)

到此，RabbitMQ已经安装并运行起来了。

在这个界面里面我们可以做些什么？
可以手动创建虚拟host，创建用户，分配权限，创建交换机，创建队列等等，还有查看队列消息，消费效率，推送效率等等。

以上这些管理界面的操作在这篇暂时不做扩展描述，我想着重介绍后面实例里会使用到的。

首先先介绍一个简单的一个消息推送到接收的流程，提供一个简单的图：



### ![img](https://img-blog.csdnimg.cn/20190903141227300.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1Mzg3OTQw,size_16,color_FFFFFF,t_70)





https://blog.csdn.net/qq_35387940/article/details/100514134

rabbit+springboot集成 https://blog.csdn.net/qq_35387940/article/details/100514134

### 5.3 Dubbo

特性

- 面向接口代理的高性能RPC调用

  提供高性能的基于代理的远程调用能力，服务以接口为粒度，为开发者屏蔽远程调用底层细节。

- 智能负载均衡

  内置多种负载均衡策略，智能感知下游节点健康状况，显著减少调用延迟，提高系统吞吐量。

- 服务自动注册与发现

  支持多种注册中心服务，服务实例上下线实时感知。

- 高度可扩展能力

  遵循微内核+插件的设计原则，所有核心能力如Protocol、Transport、Serialization被设计为扩展点，平等对待内置实现和第三方实现。

- 运行期流量调度

  内置条件、脚本等路由策略，通过配置不同的路由规则，轻松实现灰度发布，同机房优先等功能。

- 可视化的服务治理与运维

  提供丰富服务治理、运维工具：随时查询服务元数据、服务健康状态及调用统计，实时下发路由策略、调整配置参数。

#### 5.3.1 SpringBoot集成Dubbo/ZooKeeper

  Dubbo 不单单只是高性能的 RPC 调用框架，更是 SOA 服务治理的一种方案。

**核心**：

1. 远程通信，向本地调用一样调用远程方法。

2. 集群容错

3. 服务自动发现和注册，可平滑添加或者删除服务提供者。

我们常常使用 Springboot 暴露 HTTP 服务，并走 JSON 模式。但慢慢量大了，一种 SOA 的治理方案。这样可以暴露出 Dubbo 服务接口，提供给 Dubbo 消费者进行 RPC 调用。下面我们详解下如何集成 Dubbo。

   ZooKeeper 是一个分布式的，开放源码的分布式应用程序协调服务。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。

#### 5.3.2 Dubbo下载与配置

（1）dubbo-admin-2.5.x.war官网下载： 

**dubbo源码提供了两个下载地址，一个是dubbo官网，一个是GitHub上，我们推荐从GitHub上下载。**

原因：

dubbo官网提供的源码版本，都是2.6版本之后的源码，没有2.6版本之前的源码，而2.6之后的版本，主要是提供给springboot使用的，如果我们没有使用使用springboot整合dubbo，那么不建议使用2.6之后的版本，一般使用2.5.3版本的比较多，此版本比较稳定。

还有一个问题，2.6之后的版本，并没有提供dubbo-admin（管理控制台），dubbo-monitor-simple（简易监控中心），dubbo-registry-simple（简易注册中心）等war包



**将它解压，放入到tomcat的webapps目录下，结构如图：**

**（3）由于我的tomcat在用，所以我弄了一个新的tomcat，值得注意的是：tomcat默认端口号8080已经在旧tomcat用了，所以这里需要更改一下新toncat配置，修改一下端口号即可。打开 tomcat目录的conf下的 server.xml 文件。**



**注意顺序：先启动zk，再启动tomcat，再浏览器访问。浏览器输入密码：默认root，root。**



**（1）先启动zk，用管理员方式打开cmd窗口，进入到zk的bin目录然后命令：zkServer.cmd 。也可以直接双击zkServer,不过可能闪退，网上很多解决方法。**



启动tomcat后

**打开浏览器，地址栏输入：http://localhost:8100/dubbo-admin/ (这是我的)，dubbo默认root。**



**（4）**修改Dubbo-admin登录用户名和密码。

进入dubbo-admin的WEB-INF 下的dubbo.properties

dubbo.admin.root.password=root

的意思是用户名为root 密码为root

dubbo.admin.guest.password=guest

的意思是用户名为guest密码为guest

![image-20210907095316704](C:\Users\lei41\AppData\Roaming\Typora\typora-user-images\image-20210907095316704.png)

### 5.4 Zookeeper

zookeeper是一个注册中心

#### linux安装zookeeper及使用

##### 一、安装条件

想要安装zookeeper，必须先在linux中安装好jdk。安装步骤见：

https://www.cnblogs.com/expiator/p/9987351.html

##### 二、下载并解压zookeeper压缩包

\1. 先进入/usr/local/目录，也可以是其他的目录：

```
[root@localhost /]# cd /usr/local
```

\2. zookeeper安装包可以在官网下载。

也可以在后面这个地址下载 http://mirror.bit.edu.cn/apache/zookeeper/zookeeper-3.4.13/zookeeper-3.4.13.tar.gz

如果链接打不开，就先打开 [http://mirror.bit.edu.cn/apache/zookeeper ](http://mirror.bit.edu.cn/apache/zookeeper/)， 再选择版本。

在此目录下载zookeeper安装包：

```
[root@localhost local]# wget http://mirror.bit.edu.cn/apache/zookeeper/zookeeper-3.4.13/zookeeper-3.4.13.tar.gz 
```

\3. 解压：

```
[root@localhost local]# tar -zxvf zookeeper-3.4.13.tar.gz
```

##### 三、编辑配置文件

1.进入conf目录：

```
[root@localhost local]# cd zookeeper-3.4.13/conf
```

\2. 将zoo_sample.cfg这个文件复制为zoo.cfg (必须是这个文件名)

```
[root@localhost conf]# cp  zoo_sample.cfg  zoo.cfg
```

\3. 进入zoo.cfg文件进行编辑

```
[root@localhost conf]# vim zoo.cfg
```

\4. 按 i 进入编辑模式，修改以下内容：

```
dataDir=/tmp/zookeeper/datadataLogDir=/tmp/zookeeper/log
```

注意：如果想配置集群的话，请在clientPort下面添加服务器的ip。如

server.1=192.168.180.132:2888:3888
server.2=192.168.180.133:2888:3888

server.3=192.168.180.134:2888:3888
如果电脑内存比较小，zookeeper还可以设置成伪集群。也就是全部服务器采用同一个ip，但是使用不同的端口。

\5. 在tmp目录创建目录。

```
[root@localhost conf]# mkdir /tmp/zookeeper[root@localhost conf]# mkdir /tmp/zookeeper/data[root@localhost conf]# mkdir /tmp/zookeeper/log
```

 6.如果是配置集群，还需要在前面配置过的dataDir路径下新增myid文件

```
[root@localhost conf]# cd /tmp/zookeeper/data[root@localhost data]# touch myid[root@localhost data]# vim myid
```


在data目录下创建文件，文件名为“myid”, 编辑该“myid”文件，并在对应的IP的机器上输入对应的编号。
如在192.168.180.132上，“myid”文件内容就是1。在192.168.180.133上，内容就是2。



##### 四、配置环境变量

1.上面的操作都完事之后，我们需要配置一下环境变量，配置环境变量的命令如下：

```
[root@localhost zookeeper-3.4.13]# export ZOOKEEPER_INSTALL=/usr/local/zookeeper-3.4.13/[root@localhost zookeeper-3.4.13]# export PATH=$PATH:$ZOOKEEPER_INSTALL/bin
```

 

##### 五、启动zookeeper

1.进入bin目录，并启动zookeep。如果不是在bin目录下执行，启动zookeeper时会报错： bash: ./zkServer.sh: No such file or directory

注意： ./zkServer.sh start前面的 . 不可忽略。

```
[root@localhost local]# cd /usr/local/zookeeper-3.4.13/bin[root@localhost bin]# ./zkServer.sh start
```

2.启动成功效果如下：

```
ZooKeeper JMX enabled by defaultUsing config: /usr/local/zookeeper-3.4.13/bin/../conf/zoo.cfgStarting zookeeper ... STARTED
```

3.zookeeper的服务端启动后，还需要启动zookeeper的客户端：

```
[root@localhost bin]# ./zkCli.sh
```

如果是连接多个不同的主机节点，可以使用如下命令：

```
./zkCli.sh -server 192.168.180.132:2888
```

启动成功效果如下：

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

```
Connecting to localhost:2181..............................Welcome to ZooKeeper!2018-10-25 21:04:54,407 [myid:] - INFO  [main-SendThread(localhost:2181):ClientCnxn$SendThread@1029] - Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)JLine support is enabled2018-10-25 21:04:54,471 [myid:] - INFO  [main-SendThread(localhost:2181):ClientCnxn$SendThread@879] - Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session[zk: localhost:2181(CONNECTING) 0] 2018-10-25 21:04:54,501 [myid:] - INFO  [main-SendThread(localhost:2181):ClientCnxn$SendThread@1303] - Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x10000712e6f0000, negotiated timeout = 30000WATCHER::WatchedEvent state:SyncConnected type:None path:null
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

 

4.查看状态：



```
[root@localhost bin]# ./zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: /usr/local/zookeeper-3.4.13/bin/../conf/zoo.cfgMode: standalone
```

##### 遇到问题怎么解决？

zookeeper的出错日志会记录在 zookeeper.out。

当前处于哪个目录，执行完zkServer.sh start命令， zookeeper.out就会写在哪个目录。

vim zookeeper.out 可以查看报错信息。然后再搜索解决。

##### 六、zookeeper使用

通过 ./zkCli.sh 进入客户端后，就可以使用命令来操作zookeeper了。

1.创建节点

使用create命令，可以创建一个zookeeper节点。

create [-s]  [-e] path data acl

其中-s表示顺序节点，-e表示临时节点。默认情况下，创建的是持久节点。

path是节点路径，data是节点数据，acl是用来进行权限控制的。

如下：

创建一个叫做/zk-test的节点，内容是"123"

```
[zk: localhost:2181(CONNECTED) 0] create /zk-test 123Created /zk-test
```

创建/zk-test的子节点book，内容是"233"

```
[zk: localhost:2181(CONNECTED) 7] create  /zk-test/book  233Created /zk-test/book
```

 

2.查看节点内容

使用get命令，可以获取zookeeper指定节点的内容和属性信息。

如下：

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

```
[zk: localhost:2181(CONNECTED) 1] get /zk-test123cZxid = 0x3actime = Sun Nov 11 21:50:44 CST 2018mZxid = 0x3amtime = Sun Nov 11 21:50:44 CST 2018pZxid = 0x3acversion = 0dataVersion = 0aclVersion = 0ephemeralOwner = 0x0dataLength = 3numChildren = 0
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

3.查看子节点

使用ls命令可以查看指定节点下的所有子节点

以下查看根目录下的所有子节点：

```
[zk: localhost:2181(CONNECTED) 2] ls /[zk-test, zookeeper]
```

查看zk-test节点的子节点：

```
[zk: localhost:2181(CONNECTED) 3] ls /zk-test[book]
```

 

4.更新节点内容

使用set命令，更新节点内容。格式为：

set  path data 

其中的data就是要更新的新内容。

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

```
[zk: localhost:2181(CONNECTED) 4] set /zk-test 456cZxid = 0x3actime = Sun Nov 11 21:50:44 CST 2018mZxid = 0x3bmtime = Sun Nov 11 22:05:20 CST 2018pZxid = 0x3acversion = 0dataVersion = 1aclVersion = 0ephemeralOwner = 0x0dataLength = 3numChildren = 0
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

在输出的信息中，可以发现，dataVersion的值由原来的0 变成了 1，这是因为刚才的更新操作导致该节点的数据版本也发生变更。

6.删除节点

使用delete命令来删除节点，如下：

```
[zk: localhost:2181(CONNECTED) 11] delete /zk-testNode not empty: /zk-test
```

可以发现，一个节点存在子节点时，无法删除该节点。

删除子节点/zk-test/book，如下：

```
[zk: localhost:2181(CONNECTED) 12] delete /zk-test/bookWATCHER::WatchedEvent state:SyncConnected type:NodeDeleted path:/zk-test/book
```

zookeeper中的watcher会监控节点，当子节点发生变化时会发出通知。此时提示子节点 /zk-test/book删除成功。

继续尝试删除节点 /zk-test，

```
[zk: localhost:2181(CONNECTED) 13] ls /zk-test[][zk: localhost:2181(CONNECTED) 14] delete /zk-test[zk: localhost:2181(CONNECTED) 15] ls /[]
```

删除成功。

##### windows 安装 zookeeper

先准备安装包，这里我推荐在Apache官网下载（地址：https://zookeeper.apache.org/releases.html）。

解压复制 将conf目录下的zoo_sample.cfg文件，复制一份，重命名为zoo.cfg



修改zoo.cfg配置文件，将dataDir=/tmp/zookeeper修改成zookeeper安装目录所在的data文件夹（需要在安装目录下面新建一个空的data文件夹和log文件夹），再添加一条添加数据日志的配置，如下图



~~~
dataDir=dataLogDir=
~~~

参数说明：

tickTime：这个时间是作为 Zookeeper 服务器之间或客户端与服务器之间维持心跳的时间间隔，也就是每个 tickTime 时间就会发送一个心跳。
initLimit：这个配置项是用来配置 Zookeeper 接受客户端（这里所说的客户端不是用户连接 Zookeeper 服务器的客户端，而是 Zookeeper 服务器集群中连接到 Leader 的 Follower 服务器）初始化连接时最长能忍受多少个心跳时间间隔数。当已经超过 10 个心跳的时间（也就是 tickTime）长度后 Zookeeper 服务器还没有收到客户端的返回信息，那么表明这个客户端连接失败。总的时间长度就是 5*2000=10 秒
syncLimit：这个配置项标识 Leader 与 Follower 之间发送消息，请求和应答时间长度，最长不能超过多少个 tickTime 的时间长度，总的时间长度就是 2*2000=4 秒
dataDir：顾名思义就是 Zookeeper 保存数据的目录，默认情况下，Zookeeper 将写数据的日志文件也保存在这个目录里。
clientPort：这个端口就是客户端连接 Zookeeper 服务器的端口，Zookeeper 会监听这个端口，接受客户端的访问请求。

双击zkCli.cmd

### 5.5 Redis

#### 5.5.1 概述

​    REmote DIctionary Server(Redis) 是一个由Salvatore Sanfilippo写的key-value存储系统。

Redis是一个开源的使用ANSI C语言编写、遵守BSD协议、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。

它通常被称为数据结构服务器，因为值（value）可以是 字符串(String), 哈希(Hash), 列表(list), 集合(sets) 和 有序集合(sorted sets)等类型。

#### 5.5.2 数据结构

- String: 字符串
- Hash: 散列
- List: 列表
- Set: 集合
- Sorted Set: 有序集合

#### 5.5.3 SpringBoot集成Redis

##### 5.5.3.1 yml配置

```yaml
spring:#Redis  redis:    host: 127.0.0.1    port: 6379    password:    #最大连接数    pool:        #连接池最大连接数（使用负值表示没有限制）        max-active: 8        #连接池最大阻塞等待时间（使用负值表示没有限制）        max-wait: -1        #连接池中的最大空闲连接        max-idle: 8        #连接池中的最小空闲连接        min-idle: 0    #连接超时时间（毫秒）    timeout: 30000
```

##### 5.5.3.2  RedisConfig

```java
@Configuration@EnableCaching@RefreshScopepublic class RedisConfig extends CachingConfigurerSupport {    @Value("${spring.redis.host}")    private String host;    @Value("${spring.redis.port}")    private int port;    @Value("${spring.redis.timeout}")    private int timeout;    @Value("${spring.redis.password}")    private String password;    @Value("${spring.redis.pool.max-active}")    private int maxActive;    @Value("${spring.redis.pool.max-wait}")    private int maxWait;    @Value("${spring.redis.pool.max-idle}")    private int maxIdle;    @Value("${spring.redis.pool.min-idle}")    private int minIdle;    @RefreshScope    @Bean    public KeyGenerator wiselyKeyGenerator(){        return new KeyGenerator() {            @Override            public Object generate(Object target, Method method, Object... params) {                StringBuilder sb = new StringBuilder();                sb.append(target.getClass().getName());                sb.append(method.getName());                for (Object obj : params) {                    sb.append(obj.toString());                }                return sb.toString();            }        };    }    @RefreshScope    @Bean    public JedisConnectionFactory redisConnectionFactory() {        JedisConnectionFactory factory = new JedisConnectionFactory();        factory.setHostName(host);        factory.setPort(port);        factory.setTimeout(timeout); //设置连接超时时间        factory.setPassword(password);        factory.getPoolConfig().setMaxIdle(maxIdle);        factory.getPoolConfig().setMinIdle(minIdle);        factory.getPoolConfig().setMaxTotal(maxActive);        factory.getPoolConfig().setMaxWaitMillis(maxWait);        return factory;    }    @RefreshScope    @Bean    public CacheManager cacheManager(RedisTemplate redisTemplate) {//        RedisCacheManager cacheManager = new RedisCacheManager(redisTemplate);//        // Number of seconds before expiration. Defaults to unlimited (0)//        cacheManager.setDefaultExpiration(10); //设置key-value超时时间        return null;    }    @RefreshScope    @Bean    public RedisTemplate<String, String> redisTemplate(RedisConnectionFactory factory) {        StringRedisTemplate template = new StringRedisTemplate(factory);        setSerializer(template); //设置序列化工具，这样ReportBean不需要实现Serializable接口        template.afterPropertiesSet();        return template;    }    @RefreshScope    private void setSerializer(StringRedisTemplate template) {        Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class);        ObjectMapper om = new ObjectMapper();        om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY);        om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL);        jackson2JsonRedisSerializer.setObjectMapper(om);        template.setValueSerializer(jackson2JsonRedisSerializer);    }
```

##### 5.5.3.3 RedisUtils

```java
@Servicepublic class RedisUtils {    @Autowired    private RedisTemplate redisTemplate;    /**     * 写入缓存     * @param key     * @param value     * @return     */    public boolean set(final String key, Object value) {        boolean result = false;        try {            ValueOperations<Serializable, Object> operations = redisTemplate.opsForValue();            operations.set(key, value);            result = true;        } catch (Exception e) {            e.printStackTrace();        }        return result;    }    /**     * 写入缓存设置时效时间     * @param key     * @param value     * @return     */    public boolean set(final String key, Object value, Long expireTime , TimeUnit timeUnit) {        boolean result = false;        try {            ValueOperations<Serializable, Object> operations = redisTemplate.opsForValue();            operations.set(key, value);            redisTemplate.expire(key, expireTime, timeUnit);            result = true;        } catch (Exception e) {            e.printStackTrace();        }        return result;    }    /**     * 批量删除对应的value     * @param keys     */    public void remove(final String... keys) {        for (String key : keys) {            remove(key);        }    }    /**     * 批量删除key     * @param pattern     */    public void removePattern(final String pattern) {        Set<Serializable> keys = redisTemplate.keys(pattern);        if (keys.size() > 0){            redisTemplate.delete(keys);        }    }    /**     * 删除对应的value     * @param key     */    public void remove(final String key) {        if (exists(key)) {            redisTemplate.delete(key);        }    }    /**     * 判断缓存中是否有对应的value     * @param key     * @return     */    public boolean exists(final String key) {        return redisTemplate.hasKey(key);    }    /**     * 读取缓存     * @param key     * @return     */    public Object get(final String key) {        Object result = null;        ValueOperations<Serializable, Object> operations = redisTemplate.opsForValue();        result = operations.get(key);        return result;    }    /**     * 哈希 添加     * @param key     * @param hashKey     * @param value     */    public void hmSet(String key, Object hashKey, Object value){        HashOperations<String, Object, Object> hash = redisTemplate.opsForHash();        hash.put(key,hashKey,value);    }    /**     * 哈希获取数据     * @param key     * @param hashKey     * @return     */    public Object hmGet(String key, Object hashKey){        HashOperations<String, Object, Object>  hash = redisTemplate.opsForHash();        return hash.get(key,hashKey);    }    /**     * 列表添加     * @param k     * @param v     */    public void lPush(String k,Object v){        ListOperations<String, Object> list = redisTemplate.opsForList();        list.rightPush(k,v);    }    /**     * 列表获取     * @param k     * @param l     * @param l1     * @return     */    public List<Object> lRange(String k, long l, long l1){        ListOperations<String, Object> list = redisTemplate.opsForList();        return list.range(k,l,l1);    }    /**     * 集合添加     * @param key     * @param value     */    public void add(String key,Object value){        SetOperations<String, Object> set = redisTemplate.opsForSet();        set.add(key,value);    }    /**     * 集合获取     * @param key     * @return     */    public Set<Object> setMembers(String key){        SetOperations<String, Object> set = redisTemplate.opsForSet();        return set.members(key);    }    /**     * 有序集合添加     * @param key     * @param value     * @param scoure     */    public void zAdd(String key,Object value,double scoure){        ZSetOperations<String, Object> zset = redisTemplate.opsForZSet();        zset.add(key,value,scoure);    }    /**     * 有序集合获取     * @param key     * @param scoure     * @param scoure1     * @return     */    public Set<Object> rangeByScore(String key,double scoure,double scoure1){        ZSetOperations<String, Object> zset = redisTemplate.opsForZSet();        return zset.rangeByScore(key, scoure, scoure1);    }
```

##### Linux部署Redis

~~~shell
#安装C语言环境(已经安装可跳过)yum install gcc-c++#下载压缩包wget http://download.redis.io/releases/redis-4.0.1.tar.gz#解压tar -zxvf redis-4.0.1.tar.gz#进入解压目录并编译Rediscd redis-4.0.1#进行编译make#安装Redismake install PREFIX=/usr/local/redis
~~~

PREFIX后面的/usr/local/redis是安装路径，我们启动redis的文件都在这里，也可以自定义。出现如下提示则安装成功：

~~~shell
make[1]: Entering directory `/root/redis-3.0.6/src'​Hint: It's a good idea to run 'make test' ;)​    INSTALL install    INSTALL install    INSTALL install    INSTALL install    INSTALL installmake[1]: Leaving directory `/root/redis-3.0.6/src​
~~~

###### 拷贝配置文件并运行

接下把我们的配置文件redis.conf手动拷贝到安装路径,，以便开启后台运行与远程访问。

```
#拷贝redis.conf文件cp -r redis.conf /usr/local/redis/bin/
```

![img](https://img-blog.csdn.net/20181006143827767?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1OTkyOTAw/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

~~~
#开启服务端./redis-server redis.conf
~~~

~~~
cd /usr/redis/#链接此redis./redis-cli  或者  ./redis-cli -h 127.0.0.1 -p 6379 
~~~

-h：指定主机IP-p：指定主机端口默认主机IP是127.0.0.1 默认端口 6379不填则使用默认值

##### 设置后台进行和远程连接

###### **接下里我们在配置文件redis.conf中进行相关的配置**

```
#打开配置文件vim redis.conf 
```

在vim编辑模式下，输入行数+gg可以快捷跳行。例如跳到第138行，输入：138gg

##### 设置后台启动

###### **将第138行的daemonize no修改为daemonize yes即可**

![img](https://img-blog.csdn.net/20181006165018960?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1OTkyOTAw/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

##### 开启远程访问

###### **将第70行的bind注释，第90行将protected-mode改为no**



重启redis

~~~
#首先查询到redis的pid后，kill掉,然后重启[root@localhost bin]# ps -ef|grep redisroot      20940      1  0 12:12 ?        00:00:18 ./redis-server *:6379 [root@localhost bin]# kill 20940[root@localhost bin]# ./redis-server redis.conf ​
~~~

![img](https://img-blog.csdn.net/20181006170328200?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1OTkyOTAw/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

```
#远程连接./redis-cli -h 你服务器的ip -p 6379 -a 你的密码
```

![img](https://img-blog.csdn.net/20181006171840614?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1OTkyOTAw/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)	

### 5.6 MongoDb

#### 5.6.1 概述

~~~
    MongoDB是一个基于分布式文件存储 [1]  的数据库。由C++语言编写。旨在为WEB应用提供可扩展的高性能数据存储解决方案。    MongoDB是一个介于关系数据库和非关系数据库之间的产品，是非关系数据库当中功能最丰富，最像关系数据库的。它支持的数据结构非常松散，是类似json的bson格式，因此可以存储比较复杂的数据类型。Mongo最大的特点是它支持的查询语言非常强大，其语法有点类似于面向对象的查询语言，几乎可以实现类似关系数据库单表查询的绝大部分功能，而且还支持对数据建立索引。
~~~

#### 5.6.2 windows集成

#### 5.6.3 Linux集成

~~~shell
环境搭建：   1 下载Linux包    wget http://fastdl.mongodb.org/linux/mongodb-linux-x86_64-3.2.12.tgz      2  解压   tar -zxvf mongodb-linux-x86_64-3.2.12.tgz /usr/local/mongo      3  配置系统文件profile        sudo vi /etc/profile    插入下列内容：      export MONGODB_HOME=/usr/local/mongodb      export PATH=$PATH:$MONGODB_HOME/bin        source /etc/profile       4 创建用于存放数据和日志文件的文件夹，并修改其权限增加读写权限   cd /usr/local/mongodb   sudo mkdir -p data/db   sudo chmod -R 777 data/db   sudo mkdir logs   cd logs   sudo touch mongodb.log      5 进入到bin目录，增加一个配置文件   cd /usr/local/mongodb/bin     sudo vi mongodb.conf
~~~

##### MongoDB启动配置

~~~shell
dbpath = /usr/local/mongodb/data/db #数据文件存放目录  logpath = /usr/local/mongodb/logs/mongodb.log #日志文件存放目录  port = 28017  #默认端口27017  fork = true  #以守护程序的方式启用，即在后台运行  nohttpinterface = true 
~~~

##### 启动配置

~~~shell
启动mongod数据库服务，以配置文件的方式启动cd /usr/local/mongodb/bin./mongod -f mongodb.conf [wj@bogon bin]$ sudo ./mongod -f mongodb.conf --logappendabout to fork child process, waiting until server is ready for connections.forked process: 6385all output going to: /usr/local/mongodb/logs/mongodb.logchild process started successfully, parent exiting
~~~

##### 连接数据库

~~~
./mongo在浏览器中诊断访问http://XXXX:27017You are trying to access MongoDB on the native driver port. For http diagnostic access, add 1000 to the port number
~~~



### 5.7 Mysql

https://www.runoob.com/mysql/mysql-tutorial.html

#### 5.7.1 概述

​     MySQL 是一个关系型数据库管理系统，由瑞典 MySQL AB 公司开发，目前属于 Oracle 公司。MySQL 是一种关联数据库管理系统，关联数据库将数据保存在不同的表中，而不是将所有数据放在一个大仓库内，这样就增加了速度并提高了灵活性。

- MySQL 是开源的，目前隶属于 Oracle 旗下产品。
- MySQL 支持大型的数据库。可以处理拥有上千万条记录的大型数据库。
- MySQL 使用标准的 SQL 数据语言形式。
- MySQL 可以运行于多个系统上，并且支持多种语言。这些编程语言包括 C、C++、Python、Java、Perl、PHP、Eiffel、Ruby 和 Tcl 等。
- MySQL 对PHP有很好的支持，PHP 是目前最流行的 Web 开发语言。
- MySQL 支持大型数据库，支持 5000 万条记录的数据仓库，32 位系统表文件最大可支持 4GB，64 位系统支持最大的表文件为8TB。
- MySQL 是可以定制的，采用了 GPL 协议，你可以修改源码来开发自己的 MySQL 系统。

安装

https://www.cnblogs.com/fnlingnzb-learner/p/5830622.html

mysql 官方下载地址

https://dev.mysql.com/downloads/mysql/

my.ini

```ini
[client]# 设置mysql客户端默认字符集default-character-set=utf8 [mysqld]# 设置3306端口port = 3306# 设置mysql的安装目录basedir=C:\\web\\mysql-8.0.11# 设置 mysql数据库的数据的存放目录，MySQL 8+ 不需要以下配置，系统自己生成即可，否则有可能报错# datadir=C:\\web\\sqldata# 允许最大连接数max_connections=20# 服务端使用的字符集默认为8比特编码的latin1字符集character-set-server=utf8# 创建新表时将使用的默认存储引擎default-storage-engine=INNODB
```



### Memcached 

##### Memcached 安装

https://www.runoob.com/memcached/memcached-install.html



### 5.8 Oracle

### 5.9 Solr

### 5.10 FreeMaker

### 5.11 Netty

### 5.12 Nginx

### 5.13 Tomcat

### 5.14 Apache

### 5.15 FastDFS

### 5.16 Jenkins

#### 一、介绍Jenkins

##### 1、Jenkins概念

　　Jenkins是一个功能强大的应用程序，允许**持续集成和持续交付项目**，无论用的是什么平台。这是一个免费的源代码，可以处理任何类型的构建或持续集成。集成Jenkins可以用于一些测试和部署技术。Jenkins是一种软件允许持续集成。

##### 2、Jenkins目的

① 持续、自动地构建/测试软件项目。

② 监控软件开放流程，快速问题定位及处理，提示开放效率。

##### 3、特性

① 开源的java语言开发持续集成工具，支持CI，CD。

② 易于安装部署配置：可通过yum安装,或下载war包以及通过docker容器等快速实现安装部署，可方便web界面配置管理。

③ 消息通知及测试报告：集成RSS/E-mail通过RSS发布构建结果或当构建完成时通过e-mail通知，生成JUnit/TestNG测试报告。

④ 分布式构建：支持Jenkins能够让多台计算机一起构建/测试。

⑤ 文件识别:Jenkins能够跟踪哪次构建生成哪些jar，哪次构建使用哪个版本的jar等。

⑥ 丰富的插件支持:支持扩展插件，你可以开发适合自己团队使用的工具，如git，svn，maven，docker等。

##### 4、产品发布流程

产品设计成型 -> 开发人员开发代码 -> 测试人员测试功能 -> 运维人员发布上线

持续集成 （Continuous integration，简称CI）

持续交付（Continuous delivery）

持续部署（continuous deployment）

 

#### 二、安装Jenkins

##### 1、安装JDK

  Jenkins是Java编写的，所以需要先安装JDK，这里采用yum安装，如果对版本有需求，可以直接在Oracle官网下载JDK；也可自己编译安装。

[root@jenkins ~]# yum install -y java-1.8.0

 

##### 2、安装Jekins

[root@jenkins ~]# cd /etc/yum.repos.d/

[root@jenkins yum.repos.d]# wget http://pkg.jenkins.io/redhat/jenkins.repo

[root@jenkins ~]# rpm --import http://pkg.jenkins.io/redhat/jenkins.io.key

[root@jenkins ~]# yum install -y jenkins

 

##### 3、修改配置文件

（1）查询yum下载Jenkins安装的文件

[root@jenkins ~]# rpm -ql jenkins

```
/etc/init.d/jenkins/etc/logrotate.d/jenkins/etc/sysconfig/jenkins/usr/lib/jenkins/usr/lib/jenkins/jenkins.war/usr/sbin/rcjenkins/var/cache/jenkins/var/lib/jenkins/var/log/jenkins
```

 

（2）创建Jenkins主目录

[root@jenkins ~]# mkdir /data/jenkins -p

[root@jenkins ~]# chown -R jenkins.jenkins /data/jenkins/

 

（3）修改配置文件

[root@jenkins ~]# vim /etc/sysconfig/jenkins

```
JENKINS_HOME="/mnt/cellar/jenkins"JENKINS_USER="jenkins"JENKINS_JAVA_OPTIONS="-Djava.awt.headless=true -Xms256m -Xmx512m -XX:MaxNewSize=256m -XX:Maxize=256m"JENKINS_PORT="8000" 
```

（4）开启Jenkins服务

[root@jenkins bin]# systemctl start jenkins

 

（5）网页打开配置

打开192.168.130.110:8000/

**① 为了安全考虑，首先需要解锁Jenkins，请在/var/lib/jenkins/secrets/initialAdminPassword中查看文件。**

![img](https://img2018.cnblogs.com/blog/1216496/201809/1216496-20180929154422645-196405166.png)

在Jenkins服务器上查询管理员密码

[root@centos7-1 ~]# cat /data/jenkins/secrets/initialAdminPassword

250d0360e2a149dbb7402f96a26945e2

 

**② 选择需要安装的插件**

选择默认推荐即可，会安装通用的社区插件，剩下的可以在使用的时候再进行安装。

![img](https://img2018.cnblogs.com/blog/1216496/201809/1216496-20180929154455631-121998829.png)

开始安装，由于网络原因，有一些插件会安装失败。

![img](https://img2018.cnblogs.com/blog/1216496/201809/1216496-20180929154509960-593928049.png)

 

**③ 设置Admin用户和密码**

![img](https://img2018.cnblogs.com/blog/1216496/201809/1216496-20180929154521356-1783143237.png)

 

**④ 安装完成**

![img](https://img2018.cnblogs.com/blog/1216496/201809/1216496-20180929154533743-185875991.png)

 

**⑤ 登录Jenkins**

![img](https://img2018.cnblogs.com/blog/1216496/201809/1216496-20180929154546439-1243749439.png)

 

#### 三、安装完后，简单的配置

##### 1、系统配置

① 系统消息：Welcome to Jenkins~

② 全局属性--->环境变量，可根据自己的项目添加；如：gitlab：

![img](https://img2018.cnblogs.com/blog/1216496/201812/1216496-20181225161055783-1178107.png)

 

③ 扩展邮件通知（用于之后项目构建后发送邮件）

![img](https://img2018.cnblogs.com/blog/1216496/201812/1216496-20181225161119613-946281686.png)

 

④ 邮件配置

　　管理监控配置--->系统管理员邮件地址：along@163.com，要和下面的用户名一致；

　　邮件通知，配置如下：可以点击测试，是否配置成功

![img](https://img2018.cnblogs.com/blog/1216496/201812/1216496-20181225161136561-477202932.png)

 

##### 2、全局工具配置

如果你持续集成需要用的哪些工具，就需要在这里添加配置；后边持续集成中，将会详细讲解；

这里只举例：添加JDK工具

点击新增---> 取消自动安装 ---->然后查询Jenkins服务器上JDK的路径，填写JAVA_HOME --->  保存即可

![img](https://img2018.cnblogs.com/blog/1216496/201809/1216496-20180929154647848-771853598.png)

 

##### 3、插件管理

这里有可更新、可选未安装插件、已安装插件；可以通过过滤快速查找

![img](https://img2018.cnblogs.com/blog/1216496/201809/1216496-20180929155328709-302472729.png)

 

#### 四、开始一个简单的项目

##### 1、新建任务

输入一个项目名称，构建一个自由风格的软件项目

![img](https://img2018.cnblogs.com/blog/1216496/201812/1216496-20181225100855566-682627741.png) 

 

##### 2、配置项目

（1）General

描述：test  自己随意添加；

显示名称：along 是Jenkins看到的项目名称；

其他更多的用法，后续再讲；

![img](https://img2018.cnblogs.com/blog/1216496/201809/1216496-20180929161011857-231187012.png)

（2）源码管理（就是拉取代码的地方，可以选择git或SVN）

① 选择git，输入gitlab项目地址

![img](https://img2018.cnblogs.com/blog/1216496/201812/1216496-20181225101954642-1408979051.png)

 

② 点击Add添加凭据

选择SSH Username with pricate key，秘钥认证，输入私钥即可；

注：Jenkins服务器需在gitlab项目上有key

![img](https://img2018.cnblogs.com/blog/1216496/201809/1216496-20180929155449880-1498963020.png)

因为只是简单的示范，所以就只有这些简单的配置； 

 

##### 3、构建项目

（1）点击项目damo，立即构建

![img](https://img2018.cnblogs.com/blog/1216496/201809/1216496-20180929155508543-1988910911.png)

（2）可以点击#1，查询详细的控制台输出信息；

![img](https://img2018.cnblogs.com/blog/1216496/201809/1216496-20180929155516248-1862719168.png)

 

（3）在Jenkins服务器上认证

在这个目录下能找到自己拉取git的项目；证明项目成功完成

[root@jenkins ~]# ls /data/jenkins/workspace/  

damo  damo@tmp

 

### 5.17 Doker

### 5.18 Mycat

### 5.19 Swagger

#### 1：简介

​    Swagger是一款接口文档生成中间件技术 便于维护现有开发的接口

#### 2：SpringBoot上集成

pom.xml加入依赖

~~~xml
<dependency>    <groupId>io.springfox</groupId>    <artifactId>springfox-swagger2</artifactId>    <version>2.9.2</version></dependency><dependency>    <groupId>io.springfox</groupId>    <artifactId>springfox-swagger-ui</artifactId>    <version>2.9.2</version></dependency><dependency>    <groupId>org.springframework.boot</groupId>    <artifactId>spring-boot-starter-web</artifactId></dependency>
~~~

配置 swaggerConfig 文件

~~~java
@Configuration@EnableSwagger2public class SwaggerConfig {    @Bean    public Docket createRestApi() {        return new Docket(DocumentationType.SWAGGER_2)                .pathMapping("/")                .select()                .apis(RequestHandlerSelectors.basePackage("com.nvn.controller"))                .paths(PathSelectors.any())                .build().apiInfo(new ApiInfoBuilder()                        .title("SpringBoot整合Swagger")                        .description("SpringBoot整合Swagger，详细信息......")                        .version("9.0")                        .contact(new Contact("啊啊啊啊","blog.csdn.net","aaa@gmail.com"))                        .license("The Apache License")                        .licenseUrl("http://www.baidu.com")                        .build());    }}
~~~

​     这里提供一个配置类，首先通过@EnableSwagger2注解启用Swagger2，然后配置一个Docket Bean，这个Bean中，配置映射路径和要扫描的接口的位置，在apiInfo中，主要配置一下Swagger2文档网站的信息，例如网站的title，网站的描述，联系人的信息，使用的协议等等。

如此，Swagger2就算配置成功了，非常方便。

此时启动项目，输入http://localhost:8080/swagger-ui.html，能够看到如下页面，说明已经配置成功了：

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190324120135562.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly93YW5nc29uZy5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70)

这里边涉及到多个API，我来向小伙伴们分别说明：

~~~java
@RestController@Api(tags = "用户管理相关接口")@RequestMapping("/user")public class UserController {    @PostMapping("/")    @ApiOperation("添加用户的接口")    @ApiImplicitParams({            @ApiImplicitParam(name = "username", value = "用户名", defaultValue = "李四"),            @ApiImplicitParam(name = "address", value = "用户地址", defaultValue = "深圳", required = true)    }    )    public RespBean addUser(String username, @RequestParam(required = true) String address) {        return new RespBean();    }    @GetMapping("/")    @ApiOperation("根据id查询用户的接口")    @ApiImplicitParam(name = "id", value = "用户id", defaultValue = "99", required = true)    public User getUserById(@PathVariable Integer id) {        User user = new User();        user.setId(id);        return user;    }    @PutMapping("/{id}")    @ApiOperation("根据id更新用户的接口")    public User updateUserById(@RequestBody User user) {        return user;    }}
~~~



~~~java
@ApiModelpublic class User {    @ApiModelProperty(value = "用户id")    private Integer id;    @ApiModelProperty(value = "用户名")    private String username;    @ApiModelProperty(value = "用户地址")    private String address;    //getter/setter}
~~~



1. @Api注解可以用来标记当前Controller的功能。
2. @ApiOperation注解用来标记一个方法的作用。
3. @ApiImplicitParam注解用来描述一个参数，可以配置参数的中文含义，也可以给参数设置默认值，这样在接口测试的时候可以避免手动输入。
4. 如果有多个参数，则需要使用多个@ApiImplicitParam注解来描述，多个@ApiImplicitParam注解需要放在一个@ApiImplicitParams注解中。
5. 需要注意的是，@ApiImplicitParam注解中虽然可以指定参数是必填的，但是却不能代替@RequestParam(required = true)，前者的必填只是在Swagger2框架内必填，抛弃了Swagger2，这个限制就没用了，所以假如开发者需要指定一个参数必填，@RequestParam(required = true)注解还是不能省略。
6. 如果参数是一个对象（例如上文的更新接口），对于参数的描述也可以放在实体类中。



如果项目中有加入security权限控制 记得在权限配置中开发访问权限

~~~java
@Overridepublic void configure(WebSecurity web) throws Exception {    web.ignoring()            .antMatchers("/swagger-ui.html")            .antMatchers("/v2/**")            .antMatchers("/swagger-resources/**");}
~~~



### 5.20 Taskcontroll

### 5.21 Docker

#### 5.21.1 docker 简介

 Docker是基于Go语言实现的云开源项目

*Docker的主要目标是“Build,Ship and Run Any App,Anywhere”，也就是通过对应用组件的封装、分发、部署、运行等生命周期的管理，使用户的App（可以使一个WEB应用或数据库应用等等）及其运行环境能够做到“一次封装，到处运行”



##### 一. Docker的三大核心概念：镜像、容器、仓库。

镜像：类似虚拟机的镜像、用俗话说就是安装文件。

容器：类似一个轻量级的沙箱，容器是从镜像创建应用运行实例，

可以将其启动、开始、停止、删除、而这些容器都是相互隔离、互不可见的。

仓库：类似代码仓库，是Docker集中存放镜像文件的场所。

![img](https://img-blog.csdn.net/20180921092727583?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2RlYnVnYnVnYmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

#### 5.21.2 docker 安装

#####  5.21.2.1 Linux下

// 安装lsb  -bash: lsb_release: 未找到命令

~~~
https://blog.csdn.net/xufengzhu/article/details/73330741
~~~



此处在Centos7进行安装，可以使用以下命令查看CentOS版本

```
lsb_release -a
```

![img](https://img2018.cnblogs.com/blog/761230/201909/761230-20190920092034990-377974794.png)

在 CentOS 7安装docker要求系统为64位、系统内核版本为 3.10 以上，可以使用以下命令查看

~~~
uname -r
~~~

![img](https://img2018.cnblogs.com/blog/761230/201909/761230-20190920092306272-1825494524.png)

用Yum源安装

**查看是否已安装docker列表**

```
yum list installed | grep docker
```

![img](https://img2018.cnblogs.com/blog/761230/201909/761230-20190924101015120-484595522.png)

 **安装docker**

```
yum -y install docker
```

-y表示不询问安装，直到安装成功，安装完后再次查看安装列表

![img](https://img2018.cnblogs.com/blog/761230/201909/761230-20190924101635249-774913670.png)

**启动docker**

```
systemctl start docker
```

CentOS7下载docker后启动会出现的错误：Job for docker.service failed because the control process exited with error code. See "systemctl status docker.service" and "journalctl -xe" for details
说明docker就没有启动成功

 

解决方法：

vim /etc/sysconfig/docker-storage

添加配置文件中：

```
DOCKER_STORAGE_OPTIONS="--selinux-enabled --log-driver=journald --signature-verification=false"vim /etc/docker/daemon.json写入指定参数：{ "storage-driver": "devicemapper" }重启docker服务
```

systemctl restart docker

没有出现错误信息，说明问题已经解决

**查看docker服务状态**

```
systemctl status docker
```

![img](https://img2018.cnblogs.com/blog/761230/201909/761230-20190924101735498-1013963263.png)

以上说明docker安装成功



离线安装模式

 **安装包官方地址**：https://download.docker.com/linux/static/stable/x86_64/

可以先下载到本地，然后通过ftp工具上传到服务器上，或者在服务器上使用命令下载

```
wget https://download.docker.com/linux/static/stable/x86_64/docker-18.06.3-ce.tgz
```

**解压**

```
tar -zxvf docker-18.06.3-ce.tgz
```

 **将解压出来的docker文件复制到 /usr/bin/ 目录下**

```
cp docker/* /usr/bin/
```

**在/etc/systemd/system/目录下新增docker.service文件**，内容如下，这样可以将docker注册为service服务

~~~xml
[Unit]Description=Docker Application Container EngineDocumentation=https://docs.docker.comAfter=network-online.target firewalld.serviceWants=network-online.target  [Service]Type=notify# the default is not to use systemd for cgroups because the delegate issues still# exists and systemd currently does not support the cgroup feature set required# for containers run by dockerExecStart=/usr/bin/dockerd --selinux-enabled=false <font color='red'>--insecure-registry=127.0.0.1</font></font>ExecReload=/bin/kill -s HUP $MAINPID# Having non-zero Limit*s causes performance problems due to accounting overhead# in the kernel. We recommend using cgroups to do container-local accounting.LimitNOFILE=infinityLimitNPROC=infinityLimitCORE=infinitys# Uncomment TasksMax if your systemd version supports it.# Only systemd 226 and above support this version.#TasksMax=infinityTimeoutStartSec=0# set delegate yes so that systemd does not reset the cgroups of docker containersDelegate=yes# kill only the docker process, not all processes in the cgroupKillMode=process# restart the docker process if it exits prematurelyRestart=on-failureStartLimitBurst=3StartLimitInterval=60s  [Install]WantedBy=multi-user.target
~~~

此处的--insecure-registry=127.0.0.1（此处改成你私服ip）设置是针对有搭建了自己私服Harbor时允许docker进行不安全的访问，否则访问将会被拒绝。

**启动docker**

给docker.service文件添加执行权限

```
chmod +x /etc/systemd/system/docker.service 
```

重新加载配置文件（每次有修改docker.service文件时都要重新加载下）

```
systemctl daemon-reload                
```

启动

```
systemctl start docker
```

设置开机启动

```
systemctl enable docker.service
```

查看docker服务状态

```
systemctl status docker
```

![img](https://img2018.cnblogs.com/blog/761230/201909/761230-20190924100503875-876834976.png)

上图表示docker已安装成功

#### 5.21.3 docker 核心

~~~
docker排坑问题 ： Error response from daemon: manifest for *:latest not found我们可以登录docker hub：https://hub.docker.com/u/library，搜索自己想要下载的镜像名:
~~~

##### 5.21.3.1 Docker 安装mysql 

###### 1.docker使用非root权限运行docker

```
sudo usermod -aG docker your-user
```

###### 2.第一步，拉取MySQL镜像

```
docker pull mysql:5.5
```

查看镜像

```
docker images
```

###### 3.创建并启动一个MySQL容器

```
docker run --name yi-mysql -e MYSQL_ROOT_PASSWORD=123456 -p 3306:3306 -d mysql:5.5
```

- –name：给新创建的容器命名，此处命名为`pwc-mysql`
- -e：配置信息，此处配置`mysql`的`root用户`的登陆密码
- -p：端口映射，此处映射`主机3306端口`到`容器pwc-mysql的3306端口`
- -d：成功启动容器后输出容器的完整ID，例如上图 `73f8811f669ee...`

###### **查看容器运行状态：**

```
docker ps
```

###### 4.测试MySQL

可以用navicat或者其他工具连接测试

###### 5.创建多个mysql服务

```
 docker run --name dbdb -e MYSQL_ROOT_PASSWORD=123456 -p 4306:3306 -d mysql:5.5
```

###### 6.查看所有容器

```
docker ps -a
```

###### 7.启动和关闭容器

启动：

```
docker start yi-mysql   //通过指定容器名字docker start 847r758488f  //通过指定容器ID
```

关闭：

```
docker stop yi-mysql   //通过指定容器名字docker stop 847r758488f //通过指定容器ID
```

###### 8.进行容器的命令行模式

docker exec -it 055201b67e06 bash

即可进行MySQL各种命令

```
mysql -uroot -p -h localhost
```

退出容器 Ctrl+D或者exit



##### 5.21.3.2 Docker 安装tomcat

###### 搜索tomcat

```
docker search tomcat
```

###### 下载tomcat

```
docker pull tomcat:8.5
```

其中8.5是tomcat的版本

###### 查看下载的tomcat

```
docker images
```

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190621130313299.png)

###### 启动容器

```
docker run --name tomcat8001 -p 8001:8080 -v /soft/tomcat/8001/conf:/usr/local/tomcat/conf -v /soft/tomcat/8001/logs:/usr/local/tomcat/logs -v /soft/tomcat/8001/webapps:/usr/local/tomcat/webapps -d tomcat:8.5
```

–name 为启动的tomcat容器重新起一个名字
-p 8001:8080 将宿主机的8001端口映射到容器的8080端口
-v /soft/tomcat/8001/conf:/usr/local/tomcat/conf 将容器的目录映射到宿主机的目录中
-d 表示后台启动容器
查看是否启动成功

```
docker ps
```

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190621130547714.png)
如果看到tomcat的启动信息，说明启动成功，否则，启动失败。

###### 停止容器

```
docker stop tomcat8001   /   docker stop "CONTAINER ID"
```

###### 重新启动容器

```
docker start tomcat8001  // docker start "CONTAINER ID"
```

###### 启动失败的解决方法

1.启动失败查看所有被启动过的容器，包括关闭的容器

```
docker ps -a
```

如果出现如下图所示：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190621131016498.png)
解决方法为：
首先先启动一容器：

```
docker run --name tomcat -p 8001:8080 -d tomcat:8.5
```

之后拷贝tomcat容器的conf、logs、webapps目录到宿主机

```
docker cp tomcat:/usr/local/tomcat/conf /soft/tomcat/8001docker cp tomcat:/usr/local/tomcat/logs /soft/tomcat/8001docker cp tomcat:/usr/local/tomcat/webapps /soft/tomcat/8001
```

然后停止刚开启的tomcat容器，并删除

```
docker rm tomcat
```

最后重新启动一个tomcat容器

```
docker run --name tomcat8001 -p 8001:8080 -v /soft/tomcat/8001/conf:/usr/local/tomcat/conf -v /soft/tomcat/8
```



##### 5.21.3.3 Docker 安装nginx

~~~
###########################################运行容器#安装Nginx#搜索、下载镜像docker search nginxdocker pull nginxdocker images nginx#运行容器mynginxdocker run -p 80:80 --name mynginx -d nginx#查看端口netstat -antp|grep 80#访问测试curl 127.0.0.1#外部浏览器访问ip正常，部署成功#进入Nginx容器docker exec -it mynginx /bin/sh#退出容器 exitCtrl+d #快捷键#列出容器docker ps -a#删除容器docker rm mynginx##########################################运行Nginx部署网站###########################################接下来思考问题：#Nginx配置、查看日志、部署网站#需要把外部的目录或文件映射到docker容器#创建目录Ngdir=/www/docker/nginxmkdir -p $Ngdir/{www,log,conf/conf.d}#创建配置(采用默认配置去注释)echo '#man configuser nginx;worker_processes 1;error_log /var/log/nginx/error.log warn;pid /var/run/nginx.pid;events {worker_connections 1024;}http {include /etc/nginx/mime.types;default_type application/octet-stream;log_format main '$remote_addr - $remote_user [$time_local] "$request" ''$status $body_bytes_sent "$http_referer" ''"$http_user_agent" "$http_x_forwarded_for"';access_log /var/log/nginx/access.log main;sendfile on;keepalive_timeout 65;include /etc/nginx/conf.d/*.conf;}'>$Ngdir/conf/nginx.conf#echo '#nginxserver {listen 80;server_name localhost;location / {root /usr/share/nginx/html;index index.html index.htm;}error_page 500 502 503 504 404 /50x.html;location = /50x.html {root /usr/share/nginx/html;}}'>$Ngdir/conf/conf.d/default.conf#htmlecho 'Welcome to nginx!'>$Ngdir/www/index.htmlecho 'error_page 500 502 503 504 404'>$Ngdir/www/50x.html#使用nginx镜像，创建容器mynginxdocker run -p 80:80 --name mynginx \-v $Ngdir/conf/nginx.conf:/etc/nginx/nginx.conf:ro \-v $Ngdir/conf/conf.d:/etc/nginx/conf.d:ro \-v $Ngdir/www:/usr/share/nginx/html:rw \-v $Ngdir/log:/var/log/nginx:rw \-d nginx#测试html内容curl 127.0.0.1curl 127.0.0.1/123#查看error.logcat $Ngdir/log/error.log#测试成功 ^_^# 参数说明：# -p 80:80：本地80端口:映射docker容器80端口# -v $Ngdir/log:/var/log/nginx 主机log目录挂载到容器log/nginx
~~~



##### 5.21.3.4 Docker 安装 Sql Server

　　然后根据这个上docker拉取镜像

```
 docker pull mcr.microsoft.com/mssql/server:2017-latest
```

　　查看镜像并允许此镜像

```
docker imagessudo docker run -e "ACCEPT_EULA=Y" -e "SA_PASSWORD=MyPassWord123"  -p 1433:1433 --name sql1  -d mcr.microsoft.com/mssql/server:2017-latest
```

 

　　然后查看是否允许成功

```
Docker ps -a
```

 

　　出现下图这样既允许成功，显示UP(如果失败的话通过docker logs 容器名进行查看错误日志)

 ![img](https://img2018.cnblogs.com/blog/1470432/201907/1470432-20190730175207460-1936354168.png)

 https://www.cnblogs.com/Fengyinyong/p/13916376.html

　　然后这里我们就配置了SQL Server，接下来我们实际进入容器内操作。

```
sudo docker exec -it sql1 "bash"/opt/mssql-tools/bin/sqlcmd -S localhost -U SA -P "MyPassWord123"
```

　　然后现在就可以进行日常的数据库操作了，输入命令后执行Go结束

 ![img](https://img2018.cnblogs.com/blog/1470432/201907/1470432-20190730175223314-731769061.png)

 

　　　　创建库

```
CREATE DATABASE TestDB
```

 

　　　　使用库、创建表

```
USE TestDBCREATE TABLE Inventory (id INT, LastName NVARCHAR(50), FirstName NVARCHAR(50))
```

 

　　　　查询表

```
Select * from  Inventory
```

 

　　　　查询用户创建的表

```
select name from sysobjects where type = 'U'
```

 

 ~~~
###### 　　**系统表sysobjects保存的都是数据库对象,其中type表示各种对象的类型，具体包括:**###### 　　**U = 用户表**###### 　　**S = 系统表**###### 　　**C = CHECK 约束**###### 　　**D = 默认值或 DEFAULT 约束**###### 　　**F = FOREIGN KEY 约束**###### 　　**L = 日志**###### 　　**FN = 标量函数**###### 　　**IF = 内嵌表函数**###### 　　**P = 存储过程**###### 　　**PK = PRIMARY KEY 约束（类型是 K）**###### 　　**RF = 复制筛选存储过程**###### 　　**TF = 表函数**###### 　　**TR = 触发器**###### 　　**UQ = UNIQUE 约束（类型是 K）**###### 　　**V = 视图**###### 　　**X = 扩展存储过程及相关的对象信息。**
 ~~~



###### **其他配置**

　　一、更改sa的登录密码

```
sudo docker exec -it sql1 /opt/mssql-tools/bin/sqlcmd  -S localhost -U SA -P "MyPassWord123"  -Q 'ALTER LOGIN SA WITH PASSWORD="MyPassWord456"'
```

 

　　二、保留数据

- - 将主机目录装载为数据卷

```
docker run -e 'ACCEPT_EULA=Y' -e 'MSSQL_SA_PASSWORD=MyPassWord456' -p 1433:1433 -v  /var/opt/mssql -d mcr.microsoft.com/mssql/server:2017-latest
```

 

- -  使用数据卷容器

```
docker run -e 'ACCEPT_EULA=Y' -e 'MSSQL_SA_PASSWORD=MyPassWord456' -p 1433:1433 -v sqlvolume:/var/opt/mssql -d mcr.microsoft.com/mssql/server:2017-latest
```

 

　　三、删除或退出容器

 　　　删除容器：docker rm 容器名

　　　 删除镜像：docker rmi 镜像名

　　　 退出容器;Ctrl+D



##### 5.21.3.5 Docker 安装jenkins

###### **查看docker的jenkins镜像版本**

```
#查看jenkins版本命令docker search jenkins
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

```
[root@localhost docker]# docker search jenkinsNAME                                   DESCRIPTION                                     STARS               OFFICIAL            AUTOMATEDjenkins                                Official Jenkins Docker image                   4153                [OK]                jenkins/jenkins                        The leading open source automation server       1326                                    jenkinsci/jenkins                      Jenkins Continuous Integration and Delivery …   355                                     jenkinsci/blueocean                    https://jenkins.io/projects/blueocean           339                                     jenkinsci/jnlp-slave                   A Jenkins slave using JNLP to establish conn…   101                                     [OK]
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

 

[回到顶部](https://www.cnblogs.com/nhdlb/p/12576273.html#_labelTop)

###### **远程拉取镜像**

```
#拉取镜像命令(不标注表示最新的)docker pull jenkins
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

```
[root@localhost docker]# docker pull jenkinsUsing default tag: latestlatest: Pulling from library/jenkins55cbf04beb70: Pull complete 1607093a898c: Pull complete 9a8ea045c926: Pull complete d4eee24d4dac: Pull complete c58988e753d7: Pull complete 794a04897db9: Pull complete 70fcfa476f73: Pull complete
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

 

[回到顶部](https://www.cnblogs.com/nhdlb/p/12576273.html#_labelTop)

###### **创建挂载目录**

**挂载目录用于映射jenkins的jenkins_home下的配置文件等信息。**

```
#本文的挂载目录是home下mkdir /home/jenkins
```

**重点：此目录需要设置权限，否则启动容器报错权限错误**

```
#修改权限（1000:1000 是UID和GID）chown -R 1000:1000 /home/jenkins/
```

 

[回到顶部](https://www.cnblogs.com/nhdlb/p/12576273.html#_labelTop)

###### **启动容器**

```
#运用镜像启动容器命令docker run -d -p 8000:8080 -p 50000:50000 -v /home/jenkins:/var/jenkins_home --name jenkins --restart always --privileged=true  -u root jenkins
```

**-p : 映射端口，宿主机端口：容器端口**

**-v : 挂载，宿主机目录：容器目录**

**--name : 自定义容器名**

**-u : 权限用户名**

**--privileged : 使用该参数，container内的root拥有真正的root权限，否则，container（容器）内的root只是外部的一个普通用户权限，privileged启动的容器可以看到很多host上的设备，并且可以执行mount，甚至允许你在docker容器内启动docker容器。**

**未设置privileged参数**

**![img](https://img2020.cnblogs.com/blog/1582099/202003/1582099-20200326180014286-902354315.png)**

###### **设置privileged参数**

**![img](https://img2020.cnblogs.com/blog/1582099/202003/1582099-20200326180114524-2140536814.png)**

 **-p 50000:50000 : 如果您在其他机器上设置了一个或多个基于JNLP的Jenkins代理程序，而这些代理程序又与 jenkinsci/blueocean 容器交互（充当“主”Jenkins服务器，或者简称为“Jenkins主”）， 则这是必需的。默认情况下，基于JNLP的Jenkins代理通过TCP端口50000与Jenkins主站进行通信。**

 

[回到顶部](https://www.cnblogs.com/nhdlb/p/12576273.html#_labelTop)

###### **修改default.json、hudson.model.UpdateCenter.xml配置文件**

**启动容器后，进入刚才设置的挂载目录 /home/jenkins 内，可以看到已经有映射的配置文件了。**

**![img](https://img2020.cnblogs.com/blog/1582099/202003/1582099-20200326180722031-1849480941.png)**

**首先修改****hudson.model.UpdateCenter.xml配置文件**

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

```
默认路径http://updates.jenkins-ci.org/update-center.json改成路径http://mirror.xmission.com/jenkins/updates/update-center.json
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

**完成后修改 /updates/default.json 配置文件**

```
默认路径"connectionCheckUrl":"http://www.google.com/" 改为路径"connectionCheckUrl":"http://www.baidu.com/"
```

 

[回到顶部](https://www.cnblogs.com/nhdlb/p/12576273.html#_labelTop)

###### **重启jenkins容器**

```
#重启jenkins容器docker restart jenkins
```

 

[回到顶部](https://www.cnblogs.com/nhdlb/p/12576273.html#_labelTop)

###### **测试**

**![img](https://img2020.cnblogs.com/blog/1582099/202003/1582099-20200326181347255-700999645.png)**

**成功！**



##### [docker上部署nginx容器80端口自动转443端口]

拉去nginx镜像

\# docker pull nginx

运行nginx容器config用于拷贝nginx配置文件

\# docker run --name nginxconfig -d docker.io/nginx

\# docker cp nginxconfig:/etc/nginx/ /root/

删除

\# docker stop nginxconfig

\# docker rm nginxconfig

创建服务nginx容器

\# docker run --name nginx -p 80:80 -p 443:443 -v /root/nginx/:/etc/nginx/ -d docker.io/nginx

- 映射端口443，用于https请求
- 映射端口80，用于http请求

nginx配置文件如下（不做任何修改）

~~~xml
[root@iZm5eclei4hhnwn6mo9va6Z ~]# lsmysql  nginx   redis[root@iZm5eclei4hhnwn6mo9va6Z ~]#[root@iZm5eclei4hhnwn6mo9va6Z ~]# cd nginx[root@iZm5eclei4hhnwn6mo9va6Z nginx]#[root@iZm5eclei4hhnwn6mo9va6Z nginx]# lscerts  conf.d  fastcgi_params  koi-utf  koi-win  mime.types  modules  nginx.conf  scgi_params  uwsgi_params  win-utf[root@iZm5eclei4hhnwn6mo9va6Z nginx]#[root@iZm5eclei4hhnwn6mo9va6Z nginx]# cat nginx.confuser  nginx;                                #运行nginx的用户worker_processes  1;                        #启动进程设置成和CPU数量相等error_log  /var/log/nginx/error.log warn;   #全局错误日志pid        /var/run/nginx.pid;              #PID文件的位置#工作模式及连接数上限events {    worker_connections  1024;               #单个后台work进程最大并发数设置为1024}http {    include       /etc/nginx/mime.types;    #设定mime类型    default_type  application/octet-stream;    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '       #设定日志格式                      '$status $body_bytes_sent "$http_referer" '                      '"$http_user_agent" "$http_x_forwarded_for"';    access_log  /var/log/nginx/access.log  main;    sendfile        on;    #tcp_nopush     on;    keepalive_timeout  65;                 #设置连接超时的事件    #gzip  on;                             #开启GZIP压缩    include /etc/nginx/conf.d/*.conf;}[root@iZm5eclei4hhnwn6mo9va6Z nginx]#
~~~

拷贝申请的阿里云ssl证书

~~~
[root@iZm5eclei4hhnwn6mo9va6Z nginx]# cd certs/[root@iZm5eclei4hhnwn6mo9va6Z certs]#[root@iZm5eclei4hhnwn6mo9va6Z certs]# ls2032088_cnbi.jiaxin365.cn.key  2032088_cnbi.jiaxin365.cn.pem[root@iZm5eclei4hhnwn6mo9va6Z certs]#[root@iZm5eclei4hhnwn6mo9va6Z certs]# pwd/root/nginx/certs
~~~

配置http自动跳往https

~~~
[root@iZm5eclei4hhnwn6mo9va6Z nginx]# cd conf.d/[root@iZm5eclei4hhnwn6mo9va6Z conf.d]#[root@iZm5eclei4hhnwn6mo9va6Z conf.d]# pwd/root/nginx/conf.d[root@iZm5eclei4hhnwn6mo9va6Z conf.d]#[root@iZm5eclei4hhnwn6mo9va6Z conf.d]# lsdefault.conf[root@iZm5eclei4hhnwn6mo9va6Z conf.d]#[root@iZm5eclei4hhnwn6mo9va6Z conf.d]# cat default.confserver {        server_name  cnbi.jiaxin365.cn;    #域名        listen 80;                         #侦听80端口        rewrite ^(.*) https://$server_name$1 permanent;       #${server_name}可以换成$host    }                                                         #设置http自动跳转httpsserver {    listen    443 ssl;                     #侦听443端口    server_name  cnbi.jiaxin365.cn;        #域名    #charset koi8-r;    #access_log  /var/log/nginx/host.access.log  main;    # 增加ssl    ssl on;                                #如果强制HTTPs访问，这行要打开    ssl_certificate /etc/nginx/certs/2032088_cnbi.jiaxin365.cn.pem;    ssl_certificate_key /etc/nginx/certs/2032088_cnbi.jiaxin365.cn.key;    ssl_session_cache    shared:SSL:1m;    ssl_session_timeout 5m;    ssl_protocols  SSLv2 SSLv3 TLSv1.2;    # 指定密码为openssl支持的格式    ssl_ciphers  HIGH:!aNULL:!MD5;         # 密码加密方式    ssl_prefer_server_ciphers  on;         # 依赖SSLv3和TLSv1协议的服务器密码将优先于客户端密码    location / {                           # 定义首页索引目录和名称        root   /usr/share/nginx/html;        index  index.html index.htm;    }    #error_page  404              /404.html;    # redirect server error pages to the static page /50x.html    #    error_page   500 502 503 504  /50x.html;    location = /50x.html {                #重定向错误页面到 /50x.html        root   /usr/share/nginx/html;    }    # proxy the PHP scripts to Apache listening on 127.0.0.1:80    #    #location ~ \.php$ {    #    proxy_pass   http://127.0.0.1;    #}    # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000    #    #location ~ \.php$ {    #    root           html;    #    fastcgi_pass   127.0.0.1:9000;    #    fastcgi_index  index.php;    #    fastcgi_param  SCRIPT_FILENAME  /scripts$fastcgi_script_name;    #    include        fastcgi_params;    #}    # deny access to .htaccess files, if Apache's document root    # concurs with nginx's one    #    #location ~ /\.ht {    #    deny  all;    #}}
~~~

 重启容器

\# docker restart nginx

查看容器是否启动成功 

\# docker ps -a

打开浏览器测试



##### 5.21.3.6 Docker 安装 showDoc

部署ShowDoc


一.什么是ShowDoc？


每当接手一个他人开发好的模块或者项目，看着那些没有写注释的代码，我们都无比抓狂。文档呢？！文档呢？！ShowDoc就是一个非常适合IT团队的在线文档分享工具，它可以加快团队之间沟通的效率。

 

二.ShowDoc基本配置。（附上[[官网详细安装]][1]）


确保系统已经安装docker

 

1.安装镜像。(建议使用国内镜像)


#国内镜像安装命令

docker pull registry.docker-cn.com/star7th/showdoc

#国外官方镜像安装命令

docker pull star7th/showdoc


2.新建存放showdoc数据的目录

#新建两个目录

mkdir /showdoc_data

mkdir /showdoc_data/html


3.给showdoc_data目录权限


chmod 777 -R /showdoc_data


 4.启动showdoc容器。


docker run -d --name showdoc -p 4999:80 -v /showdoc_data/html:/var/www/html/ registry.docker-cn.com/star7th/showdoc


 5.转移数据。


#这一部留意命令行界面有没有权限禁止的错误提示。

#如果有则检查权限，或者安全限制（比如说可能selinux会禁止docker进程写文件。

docker exec showdoc \cp -fr /showdoc_data/html/ /var/www/


6.根据以上命令操作的话，以后showdoc的数据都会存放在 /showdoc_data/html 目录下。

 7.接下来，你可以打开 http://ip:4999/来访问showdoc。默认账户密码是showdoc/123456。



**二、下载 showdoc**

showdoc 的 GitHub 项目地址为：https://github.com/star7th/showdoc，下载地址为 https://github.com/star7th/showdoc.git 或者 git://github.com/star7th/showdoc.git

```
[root@masternode opt]# mkdir git_repository[root@masternode opt]# chmod 777 git_repository[root@masternode opt]# cd git_repository[root@masternode git_repository]# git clone git://github.com/star7th/showdoc.git
```

git 默认是在当前目录下下载项目代码。

**三、创建镜像**

下载后，生成 showdoc 目录，进入目录，可以看到 Dockerfile 文件，使用 docker build -t showdoc ./ 命令根据 Dockerfile 来创建镜像，-t，--tag，镜像的名字及标签，通常 name:tag 或者 name 格式；可以在一次构建中为一个镜像设置多个标签。./ 表示当前 Dockerfile 所在目录。

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

```
[root@masternode git_repository]# cd showdoc[root@masternode showdoc]# ls -ltrtotal 36-rw-r--r--  1 root root 1743 Jul  6 21:00 LICENSE.txt-rw-r--r--  1 root root  257 Jul  6 21:00 Dockerfile-rw-r--r--  1 root root 4221 Jul  6 21:00 README.mddrwxr-xr-x 14 root root  214 Jul  6 21:00 Publicdrwxr-xr-x  2 root root   28 Jul  6 21:00 Sqlite-rw-r--r--  1 root root  564 Jul  6 21:00 composer.json-rw-r--r--  1 root root   30 Jul  6 21:00 robots.txtdrwxr-xr-x  2 root root  142 Jul  6 21:00 install-rw-r--r--  1 root root 1023 Jul  6 21:00 index.php-rw-r--r--  1 root root 4286 Jul  6 21:00 favicon.icodrwxr-xr-x  4 root root   29 Jul  6 21:00 documentationdrwxr-xr-x  3 root root   38 Jul  6 21:00 webdrwxr-xr-x  4 root root   75 Jul  6 21:00 serverdrwxr-xr-x  7 root root  250 Jul  6 21:00 web_src[root@masternode showdoc]# pwd/opt/git_repository/showdoc[root@masternode showdoc]# docker imagesREPOSITORY          TAG                 IMAGE ID            CREATED             SIZEnginx               latest              f68d6e55e065        4 days ago          109MBhello-world         latest              fce289e99eb9        6 months ago        1.84kB[root@masternode showdoc]# docker build -t showdoc ./......[root@masternode showdoc]# docker imagesREPOSITORY                TAG                 IMAGE ID            CREATED             SIZEshowdoc                   latest              40d2089cc644        15 seconds ago      384MBnginx                     latest              f68d6e55e065        4 days ago          109MBhello-world               latest              fce289e99eb9        6 months ago        1.84kBricharvey/nginx-php-fpm   1.5.4               0b8e5203860f        12 months ago       300MB
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

此处 docker build 时间比较长，镜像创建好之后，使用 docker images 可以看到。

**四、新建并启动容器**

此处会涉及到端口映射的概念。

```
[root@masternode showdoc]# docker run -d --name showdoc -p 4999:80 showdoc11f2354ab1cb48a264555660e8f363654f7bd23745f165fe03a379f94fabfe77[root@masternode showdoc]# docker psCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                                                                              NAMES11f2354ab1cb        showdoc             "docker-php-entrypoi…"   9 seconds ago       Up 8 seconds        443/tcp, 9000/tcp, 0.0.0.0:4999->80                                         /tcp   showdoc
```

此处使用 -d 选项表示后台运行，--name 指定容器名称，-p 进行端口映射，宿主机端口:容器端口，将允许映射容器内应用的服务端口到本地宿主机端口，此处将本地宿主机的 4999 映射到了容器的 80 端口。之后访问宿主机的 4999 端口即可访问容器内 Web 应用提供的界面。



##### 5.21.3.7 Docker 安装 MongoDb

此外，我们还可以用 **docker search mongo** 命令来查看可用版本：

```
$ docker search mongoNAME                              DESCRIPTION                      STARS     OFFICIAL   AUTOMATEDmongo                             MongoDB document databases ...   1989      [OK]       mongo-express                     Web-based MongoDB admin int...   22        [OK]       mvertes/alpine-mongo              light MongoDB container          19                   [OK]mongooseim/mongooseim-docker      MongooseIM server the lates...   9                    [OK]torusware/speedus-mongo           Always updated official Mon...   9                    [OK]jacksoncage/mongo                 Instant MongoDB sharded cluster  6                    [OK]mongoclient/mongoclient           Official docker image for M...   4                    [OK]jadsonlourenco/mongo-rocks        Percona Mongodb with Rocksd...   4                    [OK]asteris/apache-php-mongo          Apache2.4 + PHP + Mongo + m...   2                    [OK]19hz/mongo-container              Mongodb replicaset for coreos    1                    [OK]nitra/mongo                       Mongo3 centos7                   1                    [OK]ackee/mongo                       MongoDB with fixed Bluemix p...  1                    [OK]kobotoolbox/mongo                 https://github.com/kobotoolb...  1                    [OK]valtlfelipe/mongo                 Docker Image based on the la...  1                    [OK]
```

###### 2、取最新版的 MongoDB 镜像

这里我们拉取官方的最新版本的镜像：

```
$ docker pull mongo:latest
```

[![img](https://www.runoob.com/wp-content/uploads/2016/06/docker-mongo3.png)](https://www.runoob.com/wp-content/uploads/2016/06/docker-mongo3.png)

###### 3、查看本地镜像

使用以下命令来查看是否已安装了 mongo：

```
$ docker images
```

[![img](https://www.runoob.com/wp-content/uploads/2016/06/docker-mongo4.png)](https://www.runoob.com/wp-content/uploads/2016/06/docker-mongo4.png)

在上图中可以看到我们已经安装了最新版本（latest）的 mongo 镜像。

###### 4、运行容器

安装完成后，我们可以使用以下命令来运行 mongo 容器：

```
$ docker run -itd --name mongo -p 27017:27017 mongo --auth
```

参数说明：

- **-p 27017:27017** ：映射容器服务的 27017 端口到宿主机的 27017 端口。外部可以直接通过 宿主机 ip:27017 访问到 mongo 的服务。
- **--auth**：需要密码才能访问容器服务。

[![img](https://www.runoob.com/wp-content/uploads/2016/06/docker-mongo5.png)](https://www.runoob.com/wp-content/uploads/2016/06/docker-mongo5.png)

###### 5、安装成功

最后我们可以通过 **docker ps** 命令查看容器的运行信息：

[![img](https://www.runoob.com/wp-content/uploads/2016/06/docker-mongo6.png)](https://www.runoob.com/wp-content/uploads/2016/06/docker-mongo6.png)

接着使用以下命令添加用户和设置密码，并且尝试连接。

```
$ docker exec -it mongo mongo admin# 创建一个名为 admin，密码为 123456 的用户。>  db.createUser({ user:'admin',pwd:'123456',roles:[ { role:'userAdminAnyDatabase', db: 'admin'},"readWriteAnyDatabase"]});# 尝试使用上面创建的用户信息进行连接。> db.auth('admin', '123456')mongodb role类型数据库用户角色（Database User Roles）：read：授予User只读数据的权限readWrite：授予User读写数据的权限数据库管理角色（Database Administration Roles）：dbAdmin：在当前dB中执行管理操作dbOwner：在当前DB中执行任意操作userAdmin：在当前DB中管理User备份和还原角色（Backup and Restoration Roles）：backuprestore跨库角色（All-Database Roles）：readAnyDatabase：授予在所有数据库上读取数据的权限readWriteAnyDatabase：授予在所有数据库上读写数据的权限userAdminAnyDatabase：授予在所有数据库上管理User的权限dbAdminAnyDatabase：授予管理所有数据库的权限集群管理角色（Cluster Administration Roles）：clusterAdmin：授予管理集群的最高权限clusterManager：授予管理和监控集群的权限，A user with this role can access the config and local databases, which are used in sharding and replication, respectively.clusterMonitor：授予监控集群的权限，对监控工具具有readonly的权限hostManager：管理Server
```

[![img](https://www.runoob.com/wp-content/uploads/2016/06/docker-mongo7.png)](https://www.runoob.com/wp-content/uploads/2016/06/docker-mongo7.png)



##### 5.21.3.8 Docker 安装 个人博客

二、部署wordpress

~~~shell
docker pull wordpress  --拉取镜像docker images --查看镜像我这里80端口被使用了，只能映射别的端口docker run --name blog -p 8081:80 -itd 镜像iddocker ps --查看镜像
~~~




在浏览器输入ip:8081  出现如下界面



选择相应语音，在数据库中创建相应数据库，输入相应数据直至安装完成



安装成功后再次输入ip：8081




博客就这样搭建好啦，是不是很简单呢！

注：博客后台ip:8081/wp-admin/

##### 5.21.3.9 Docker 安装 nocos

###### 方式一

```
仅部署nacos-server,不使用prometheus/grafana等监控组件
```

###### 1.拉取镜像



```undefined
docker pull nacos/nacos-server
```

###### 2.挂载目录



```bash
mkdir -p /home/nacos/logs/                      #新建logs目录mkdir -p /home/nacos/init.d/          vim /home/nacos/init.d/custom.properties        #修改配置文件添加如下参数:
```



```cpp
server.contextPath=/nacosserver.servlet.contextPath=/nacosserver.port=8848spring.datasource.platform=mysqldb.num=1db.url.0=jdbc:mysql://xx.xx.xx.x:3306/nacos_devtest_prod?characterEncoding=utf8&connectTimeout=1000&socketTimeout=3000&autoReconnect=truedb.user=userdb.password=passnacos.cmdb.dumpTaskInterval=3600nacos.cmdb.eventTaskInterval=10nacos.cmdb.labelTaskInterval=300nacos.cmdb.loadDataAtStart=falsemanagement.metrics.export.elastic.enabled=falsemanagement.metrics.export.influx.enabled=falseserver.tomcat.accesslog.enabled=trueserver.tomcat.accesslog.pattern=%h %l %u %t "%r" %s %b %D %{User-Agent}inacos.security.ignore.urls=/,/**/*.css,/**/*.js,/**/*.html,/**/*.map,/**/*.svg,/**/*.png,/**/*.ico,/console-fe/public/**,/v1/auth/login,/v1/console/health/**,/v1/cs/**,/v1/ns/**,/v1/cmdb/**,/actuator/**,/v1/console/server/**nacos.naming.distro.taskDispatchThreadCount=1nacos.naming.distro.taskDispatchPeriod=200nacos.naming.distro.batchSyncKeyCount=1000nacos.naming.distro.initDataRatio=0.9nacos.naming.distro.syncRetryDelay=5000nacos.naming.data.warmup=truenacos.naming.expireInstance=true:wq 保存退出
```

###### 3.启动容器



```jsx
docker  run \--name nacos -d \-p 8848:8848 \--privileged=true \--restart=always \-e JVM_XMS=256m \-e JVM_XMX=256m \-e MODE=standalone \-e PREFER_HOST_MODE=hostname \-v /home/nacos/logs:/home/nacos/logs \-v /home/nacos/init.d/custom.properties:/home/nacos/init.d/custom.properties \nacos/nacos-server
```

###### 方式二

```
通过docker-compose部署,包含prometheus/grafana等监控组件
```

###### 1.拉取仓库



```php
git clone --depth 1 https://github.com/nacos-group/nacos-docker.git
```

###### 2.运行docker-compose



```bash
cd nacos-dockerdocker-compose -f example/standalone-derby.yaml up -d 
```



###### 方式三

拉镜像，版本查看：https://github.com/nacos-group/nacos-docker

```
docker pull nacos/nacos-server:1.1.4  //稳定版，无权限docker pull nacos/nacos-server:1.3.1  //稳定版，有权限
```

创建数据目录

```
mkdir -p /home/dockerdata/nacos/logsmkdir -p /home/dockerdata/nacos1.3.1/logs 
```

 

运行镜像 默认账号密码：nacos/nacos

~~~shell
\#1.1.4docker run -d \-e PREFER_HOST_MODE=ip \-e MODE=standalone \-e SPRING_DATASOURCE_PLATFORM=mysql \-e MYSQL_MASTER_SERVICE_HOST=172.168.1.33 \-e MYSQL_MASTER_SERVICE_PORT=3306 \-e MYSQL_MASTER_SERVICE_USER=root \-e MYSQL_MASTER_SERVICE_PASSWORD=root \-e MYSQL_MASTER_SERVICE_DB_NAME=nacos \-e MYSQL_SLAVE_SERVICE_HOST=172.168.1.33 \-e MYSQL_SLAVE_SERVICE_PORT=3306 \-v /home/dockerdata/nacos/logs:/home/nacos/logs \-p 8848:8848 \--name nacos \--restart=always \nacos/nacos-server:1.1.4  \#1.3.1docker run -d \-e PREFER_HOST_MODE=ip \-e MODE=standalone \-e SPRING_DATASOURCE_PLATFORM=mysql \-e MYSQL_SERVICE_HOST=172.168.1.33 \-e MYSQL_SERVICE_PORT=3306 \-e MYSQL_SERVICE_USER=root \-e MYSQL_SERVICE_PASSWORD=root \-e MYSQL_SERVICE_DB_NAME=nacos \-e TIME_ZONE='Asia/Shanghai' \-v /home/dockerdata/nacos1.3.1/logs:/home/nacos/logs \-p 8848:8848 \--name nacos1.3.1 \--restart=always \nacos/nacos-server:1.3.1
~~~





[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

nacos初始化sql,需要先创建nacos数据库后，然后执行下面的sql

https://github.com/alibaba/nacos/blob/master/config/src/main/resources/META-INF/nacos-db.sql

![img](https://images.cnblogs.com/OutliningIndicators/ContractedBlock.gif) View Code

 

1.1.4 升级1.3.1需要执行的脚本

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

```
ALTER TABLE `roles` ADD UNIQUE `uk_username_role` (`username`, `role`);CREATE TABLE permissions (    role varchar(50) NOT NULL,    resource varchar(512) NOT NULL,    action varchar(8) NOT NULL,    constraint uk_role_permission UNIQUE (role,resource,action)) ROW_FORMAT=DYNAMIC;
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

 如果启动1.3.1报错，比如mysql时区异常，把conf配置文件弄到主机上

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

```
docker cp nacos1.3.1:/home/nacos/conf /home/dockerdata/nacos1.3.1 #修改mysql的配置后docker stop nacos1.3.1docker rm nacos1.3.1
```

~~~shell
docker run -d \-e PREFER_HOST_MODE=ip \-e MODE=standalone \-e SPRING_DATASOURCE_PLATFORM=mysql \-e MYSQL_SERVICE_HOST=172.168.1.33 \-e MYSQL_SERVICE_PORT=3306 \-e MYSQL_SERVICE_USER=root \-e MYSQL_SERVICE_PASSWORD=root \-e MYSQL_SERVICE_DB_NAME=nacos \-e TIME_ZONE='Asia/Shanghai' \-v /home/dockerdata/nacos1.3.1/logs:/home/nacos/logs \-v /home/dockerdata/nacos1.3.1/conf:/home/nacos/conf \-p 8848:8848 \--name nacos1.3.1 \--restart=always \nacos/nacos-server:1.3.1
~~~



##### 5.21.3.10 Docker 安装 Elasticsearch

如果没有安装docker请参考我的另一篇使用docker安装redis   yum安装一行命令即可搞定

 使用 Docker 中国官方镜像加速

```
[root@VM_0_4_centos ~]# docker pull registry.docker-cn.com/library/elasticsearch
```

 查看镜像：命令 docker images

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

```
docker imagesREPOSITORY                                     TAG                 IMAGE ID            CREATED             SIZEregistry.docker-cn.com/library/elasticsearch   latest              73e6fdf8bd4f        5 days ago          486 MBregistry.docker-cn.com/library/redis           latest              4e8db158f18d        2 weeks ago         83.4 MB
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

运行

注意：5.0*默认*分配jvm空间大小为*2g* 5.0之前好像是1g

如果你的服务器内存够大请随意，我的只有2g内存 第一次装没设置大小，结果嘛，大不了重装系统而已

-e ES_JAVA_OPTS="-Xms256m -Xmx256m" //设置初始内存 和最大内存

```
docker run -e ES_JAVA_OPTS="-Xms256m -Xmx256m" -d -p 9200:9200 -p 9300:9300 --name myes  73e6fdf8bd4f[注：这是要运行的镜像id]
```

docker ps 查看 可以看到myes以运行

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

```
docker psCONTAINER ID        IMAGE                                  COMMAND                  CREATED             STATUS              PORTS                                            NAMESfa6da79ebd61        73e6fdf8bd4f                           "/docker-entrypoin..."   3 minutes ago       Up 3 minutes        0.0.0.0:9200->9200/tcp, 0.0.0.0:9300->9300/tcp   myes7512230290be        registry.docker-cn.com/library/redis   "docker-entrypoint..."   26 hours ago        Up 26 hours         0.0.0.0:6379->6379/tcp                           myredis
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

 

测试：

浏览器输入：http://140.1x3.x.xx:9200/ 你的服务器ip 端口号

浏览器返回如下信息，证明安装成功

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

```
{  "name" : "kdJt_qz",  "cluster_name" : "elasticsearch",  "cluster_uuid" : "24MHPea3QCGX10L_yyxe4A",  "version" : {    "number" : "5.6.10",    "build_hash" : "b727a60",    "build_date" : "2018-06-06T15:48:34.860Z",    "build_snapshot" : false,    "lucene_version" : "6.6.1"  },  "tagline" : "You Know, for Search"}
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)



##### 5.21.3.10 Docker 安装 Jmeter

前置条件 配置好了JDK1.8

1: 下载tar安装包  

wget https://mirrors.tuna.tsinghua.edu.cn/apache/jmeter/binaries/apache-jmeter-5.4.tgz



2：编写Dockerfile镜像文件

vi Dockerfile

~~~shell
FROM java:8ENV http_proxy ""ENV https_proxy ""RUN mkdir /jmeterdockerRUN mkdir -p /jmeterdocker/testRUN mkdir -p /jmeterdocker/test/input/jmxRUN mkdir -p /jmeterdocker/test/input/testdataRUN mkdir -p /jmeterdocker/test/report/htmlRUN mkdir -p /jmeterdocker/test/report/jtlRUN mkdir -p /jmeterdocker/test/report/outputdataRUN cd /jmeterdockerENV JMETER_VERSION=5.4ENV JMETER_HOME=/jmeterdocker/apache-jmeter-${JMETER_VERSION}ENV JMETER_PATH=${JMETER_HOME}/bin:${PATH}ENV PATH=${JMETER_HOME}/bin:${PATH}COPY apache-jmeter-${JMETER_VERSION}.tgz /jmeterdockerRUN cd /jmeterdocker \&& tar xvf apache-jmeter-5.4.tgz \&& rm apache-jmeter-5.4.tgz
~~~



3：执行命令生成镜像

docker build -t jmeter_test:v1 .

4：启动容器



~~~shell
docker run --name="my-jmeter" --net="host"  -v /tmp/jmeterspace/test/input/jmx:/jmeterdocker/test/input/jmx  -v /tmp/jmeterspace/test/input/testdata:/jmeterdocker/test/input/testdata  -v /tmp/jmeterspace/test/report/html:/jmeterdocker/test/report/html  -v /tmp/jmeterspace/test/report/jtl:/jmeterdocker/test/report/jtl  -v /tmp/jmeterspace/test/report/outputputdata:/jmeterdocker/test/report/outputdata   -it -d 【image id】
~~~









#### 拓展  Docker-compose

~~~shell
解决docker-compose 命令不存在、未找到命令错误1.安装扩展源sudo yum -y install epel-release2.安装python-pip模块sudo yum install python-pip3.查看docker-compose版本docker-compose version\# 提示未找到命令4.通过以命令进行安装cd /usr/local/bin/wget https://github.com/docker/compose/releases/download/1.14.0-rc2/docker-compose-Linux-x86_64rename docker-compose-Linux-x86_64 docker-compose docker-compose-Linux-x86_64chmod +x /usr/local/bin/docker-compose5.再通过docker-compose version命令进行查看
~~~






#### 拓展：DockerFile

**Dockerfile概述**

> Dockerfile是docker中镜像文件的的描述文件，说的直白点就是镜像文件到底是由什么东西一步步构成的。
> 例如：你在淘宝上买了一个衣架，但是卖家并没有给你发一个完整的衣架，而是一些组件和一张图纸，你按照这个图纸一步一步将衣架组装起来，就成了你所需要的样子。那么Dockerfile 就是这张图纸，镜像文件就是你需要的这个衣架，Dockerfile 不建议随便命名，就用 Dockerfile。
> 因此，Dockerfile其内部包含了一条条的指令，每一条指令构建一层，因此每一条指令的内容，就是描述该层应当如何构建。

**Docker 执行 Dockerfile 的大致流程：**

> （1）docker从基础镜像运行一个容器；
> （2）执行一条指令并对容器作出修改；
> （3）执行类似dockercommit的操作提交一个新的镜像层
> （4）docker再基于刚提交的镜像运行一个新容器；
> （5）执行dockerfile中的下一条指令直到所有指令都执行完成。

**回顾Dockerfile**

> 说到Dockerfile，就离不开Dockerfile的核心组件，尤其是镜像。镜像是运行容器的基础环境，也就是说镜像是docker容器创建的关键，而创建镜像的三种方式之一的Dockerfile是最为灵活的。

**什么是Dockerfile？**
Dockerfile可以看做是被Docker程序所解释翻译的脚本，由一组命令集合而成，每一条命令都对应一条操作命令，有其翻译为Linux下的具体命令。用户可以通过自定义内容来快速构建镜像。
​ 其实说简单点，你可以认为Dockerfile是“专门用于构建镜像的shell脚本”。
​ 还记得Dockerfile的严格格式吗？我们先来看一下这个表格。
![img](https://s4.51cto.com/images/blog/202007/29/329c162ed62fb6551505e2840581fdad.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_90,type_ZmFuZ3poZW5naGVpdGk=)

###### 1.构建httpd服务镜像

```handlebars
[root@localhost ~]# cd /opt/[root@localhost opt]# mkdir apache ##创建目录[root@localhost opt]# cd apache/[root@localhost sshd]# vim Dockerfile  ##编写dockerfile文件#基于的基础镜像FROM centos#维护镜像的用户信息MAINTAINER zjz#镜像操作指令安装Apache软件RUN yum -y updateRUN yum -y install httpd#开启 80端口EXPOSE 80#复制网站首页文件ADD index.html /var/www/html/index.html#将执行脚本复制到镜像中ADD run.sh /run.shRUN chmod 755 /run.sh#启动容器是执行脚本CMD ["/run.sh"]其中注意：run 命令可以有多条CMD只能有一条，若有多条则只会执行最后一条编写启动httpd服务的shell脚本vim run.sh#!/bin/bashrm -rf /run/httpd/*exec /usr/sbin/apachectl -D FOREGROUND编写测试页面vim index.htmlthis is docker httpd web使用tree命令查看目录的文件结构没有tree这个命令，用yum -y install tree 装一哈[root@localhost apache]# tree ././├── Dockerfile├── index.html└── run.sh0 directories, 3 files1.2.3.4.5.6.7.8.9.10.11.12.13.14.15.16.17.18.19.20.21.22.23.24.25.26.27.28.29.30.31.32.33.34.35.36.37.38.39.40.41.42.43.44.45.46.
```

构建和使用镜像（创建运行容器）

```handlebars
[root@localhost apache]# docker build -t httpd:new .1.
```

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200728102634676.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDkwNzgxMw==,size_16,color_FFFFFF,t_70)

```handlebars
[root@localhost apache]# docker images1.
```

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200728102803213.png)

```handlebars
#基于构建的镜像创建并运行容器，给容器取名为test[root@localhost apache]# docker run --name test -d -P httpd:new  1.2.
```

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200728102913188.png)

```handlebars
[root@localhost apache]# docker ps -a1.
```

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200728103018381.png)
这样我们进入容器中检查一下这个页面文件是否存在

```handlebars
[root@localhost apache]# docker exec -it test /bin/bash[root@0467d8d2d590 /]# cat /var/www/html/index.html this is docker httpd web1.2.3.
```

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200728103316453.png)
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200728144850125.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDkwNzgxMw==,size_16,color_FFFFFF,t_70)

###### 2、构建sshd镜像

```handlebars
[root@localhost ~]# cd /opt/[root@localhost opt]# mkdir sshd  ##创建目录[root@localhost opt]# cd sshd/[root@localhost sshd]# vim Dockerfile  ##编写dockerfile文件#sshd服务的镜像构建——基于Dockerfile#首先先下载基础镜像centos，创建对应的工作目录#开始编写nginx的Dockerfile#第一步：基础镜像FROM centos:7#第二步：维护者信息MAINTAINER zjz#第三步：指令集RUN yum -y updateRUN yum -y install openssh* net-tools lsof telnet passwd RUN echo '123123' | passwd --stdin root#不以PAM认证登录而是以密钥对登录（非对称密钥），即禁用ssh的PAM认证RUN sed -i 's/UsePAM yes/UsePAM no/g' /etc/ssh/sshd_configRUN ssh-keygen -t rsa -f /etc/ssh/ssh_host_rsa_key#禁用ssh中PAM会话模块RUN sed -i '/^session\s\+required\s\+pam_loginuid.so/s/^/#/' /etc/pam.d/sshd#创建ssh工作目录和权限设置RUN mkdir -p /root/.ssh && chown root:root /root && chmod 700 /root/.ssh#开放22端口EXPOSE 22#第四步：启动容器时执行指令CMD ["/usr/sbin/sshd","-D"]构建镜像和运行容器[root@localhost sshd]# docker run -d -P sshd:new 6005aaad0e99897e11672e081101a43aee169c06acba08a48b1353317d9504eb[root@localhost sshd]# docker ps -aCONTAINER ID        IMAGE               COMMAND               CREATED             STATUS              PORTS                   NAMES6005aaad0e99        sshd:new            "/usr/sbin/sshd -D"   7 seconds ago       Up 6 seconds        0.0.0.0:32768->22/tcp   pensive_poincare测试[root@localhost sshd]# ssh 192.168.10.52 -p 32768The authenticity of host '[192.168.10.52]:32768 ([192.168.10.52]:32768)' can't be established.RSA key fingerprint is c5:95:5d:0a:ce:b3:d8:cc:43:f7:b6:32:89:12:28:21.Are you sure you want to continue connecting (yes/no)? yesWarning: Permanently added '[192.168.10.52]:32768' (RSA) to the list of known hosts.root@192.168.10.52's password: Permission denied, please try again.root@192.168.10.52's password: [root@6005aaad0e99 ~]# exitlogoutConnection to 192.168.10.52 closed.此时我们登录该容器（ssh或者docker exec命令）查看sshd服务的状态（但是systemctl无法使用）[root@6005aaad0e99 ~]# systemctl status sshdFailed to get D-Bus connection: Operation not permitted一则我们可以使用下面的命令使用该命令，二则我们可以基于上面构建的镜像作为基础镜像构建systemctl的镜像来测试验证。[root@localhost sshd]# docker run --privileged -itd -P sshd:new  /usr/sbin/init bf552af2fb6b7d512bc44c32262a5dcce092e26bb7bec8e73c866a5c5a755d83[root@localhost sshd]#  docker ps -aCONTAINER ID        IMAGE               COMMAND               CREATED             STATUS              PORTS                   NAMESbf552af2fb6b        sshd:new            "/usr/sbin/init"      6 seconds ago       Up 6 seconds        0.0.0.0:32770->22/tcp   adoring_bosebb24b2efd442        systemctl:new       "/usr/sbin/init"      13 minutes ago      Up 13 minutes       22/tcp                  sleepy_curie0467d8d2d590        httpd:new           "/run.sh"             27 minutes ago      Up 27 minutes       0.0.0.0:32769->80/tcp   test6005aaad0e99        sshd:new            "/usr/sbin/sshd -D"   About an hour ago   Up About an hour    0.0.0.0:32768->22/tcp   pensive_poincare[root@localhost sshd]# ssh 192.168.10.52 -p 32770The authenticity of host '[192.168.10.52]:32770 ([192.168.10.52]:32770)' can't be established.ECDSA key fingerprint is e7:5b:57:32:ea:12:db:90:c5:da:d5:3d:95:ff:48:ab.Are you sure you want to continue connecting (yes/no)? yesWarning: Permanently added '[192.168.10.52]:32770' (ECDSA) to the list of known hosts.root@192.168.10.52's password: [root@bf552af2fb6b ~]#  systemctl status sshd● sshd.service - OpenSSH server daemon   Loaded: loaded (/usr/lib/systemd/system/sshd.service; enabled; vendor preset: enabled)   Active: active (running) since Tue 2020-07-28 02:55:53 UTC; 48s ago     Docs: man:sshd(8)           man:sshd_config(5) Main PID: 75 (sshd)   CGroup: /docker/bf552af2fb6b7d512bc44c32262a5dcce092e26bb7bec8e73c866a5c5a755d83/system.slice/sshd.service           ├─ 75 /usr/sbin/sshd -D           ├─ 85 sshd: root@pts/1           ├─ 89 -bash           └─102 systemctl status sshd           ‣ 75 /usr/sbin/sshd -DJul 28 02:55:53 bf552af2fb6b systemd[1]: Starting OpenSSH server daemon...Jul 28 02:55:53 bf552af2fb6b sshd[75]: Server listening on 0.0.0.0 port 22.Jul 28 02:55:53 bf552af2fb6b sshd[75]: WARNING: 'UsePAM no' is not supported in Red Hat Enterprise Linux and ...lems.Jul 28 02:55:53 bf552af2fb6b sshd[75]: Server listening on :: port 22.Jul 28 02:55:53 bf552af2fb6b systemd[1]: Started OpenSSH server daemon.Jul 28 02:56:23 bf552af2fb6b sshd[85]: WARNING: 'UsePAM no' is not supported in Red Hat Enterprise Linux and ...lems.Jul 28 02:56:27 bf552af2fb6b sshd[85]: Failed password for root from 192.168.10.52 port 35474 ssh2Jul 28 02:56:29 bf552af2fb6b sshd[85]: Failed password for root from 192.168.10.52 port 35474 ssh2Jul 28 02:56:31 bf552af2fb6b sshd[85]: Accepted password for root from 192.168.10.52 port 35474 ssh2Hint: Some lines were ellipsized, use -l to show in full.1.2.3.4.5.6.7.8.9.10.11.12.13.14.15.16.17.18.19.20.21.22.23.24.25.26.27.28.29.30.31.32.33.34.35.36.37.38.39.40.41.42.43.44.45.46.47.48.49.50.51.52.53.54.55.56.57.58.59.60.61.62.63.64.65.66.67.68.69.70.71.72.73.74.75.76.77.78.79.80.81.82.83.84.85.86.87.88.89.90.91.
```

###### 3、构建systemctl镜像

```handlebars
[root@localhost ~]# cd /opt/[root@localhost opt]# mkdir systemctl  ##创建目录[root@localhost opt]# cd systemctl/[root@localhost sshd]# vim Dockerfile  ##编写dockerfile文件FROM sshd:newMAINTAINER zjzENV container docker#下面的命令是放在一个镜像层中执行的，可以减少镜像层#括号中的指令含义是遍历进入的目录文件，删除除了systemd-tmpfiles-setup.service的所有文件,之后删除一些其他文件RUN (cd /lib/systemd/system/sysinit.target.wants/; for i in *; do [ $i == systemd-tmpfiles-setup.service ] || rm -f $i; done); \rm -f /lib/systemd/system/multi-user.target.wants/*; \rm -f /etc/systemd/system/*.wants/*; \rm -f /lib/systemd/system/local-fs.target.wants/*; \rm -f /lib/systemd/system/sockets.target.wants/*udev*; \rm -f /lib/systemd/system/sockets.target.wants/*initctl*; \rm -f /lib/systemd/system/basic.target.wants/*; \rm -f /lib/systemd/system/anaconda.target.wants/*;VOLUME [ "/sys/fs/cgroup" ]CMD ["/usr/sbin/init"]1.2.3.4.5.6.7.8.9.10.11.12.13.14.15.16.17.18.19.
```

构建运行及测试

```handlebars
[root@localhost systemctl]# docker build -t systemctl:new . ##创建镜像[root@localhost systemctl]# docker run --privileged -it -v /sys/fs/cgroup/:/sys/fs/cgroup:ro systemctl:new /usr/sbin/init ##privateged container 内的root拥有真正的root权限，否则，container内的root只是外部的一个普通用户权限。systemd 219 running in system mode. (+PAM +AUDIT +SELINUX +IMA -APPARMOR +SMACK +SYSVINIT +UTMP +LIBCRYPTSETUP +GCRYPT +GNUTLS +ACL +XZ +LZ4 -SECCOMP +BLKID +ELFUTILS +KMOD +IDN)Detected virtualization docker.Detected architecture x86-64.Welcome to CentOS Linux 7 (Core)!Set hostname to <bb24b2efd442>.[  OK  ] Created slice Root Slice.[  OK  ] Listening on Journal Socket.[  OK  ] Created slice System Slice.[  OK  ] Reached target Slices.[  OK  ] Reached target Paths.[  OK  ] Listening on Delayed Shutdown Socket.[  OK  ] Reached target Local File Systems.         Starting Create Volatile Files and Directories...[  OK  ] Reached target Swap.         Starting Journal Service...[  OK  ] Started Create Volatile Files and Directories.[ INFO ] Update UTMP about System Boot/Shutdown is not active.[DEPEND] Dependency failed for Update UTMP about System Runlevel Changes.Job systemd-update-utmp-runlevel.service/start failed with result 'dependency'.[  OK  ] Started Journal Service.[  OK  ] Reached target System Initialization.[  OK  ] Listening on D-Bus System Message Bus Socket.[  OK  ] Reached target Sockets.[  OK  ] Reached target Basic System.[  OK  ] Reached target Multi-User System.[  OK  ] Started Daily Cleanup of Temporary Directories.[  OK  ] Reached target Timers.1.2.3.4.5.6.7.8.9.10.11.12.13.14.15.16.17.18.19.20.21.22.23.24.25.26.27.28.29.30.31.
```

重新开启一个终端进行测试

```handlebars
[root@localhost ~]# cd /opt/[root@localhost opt]# cd systemctl/[root@localhost systemctl]# docker ps -a[root@localhost systemctl]# docker psCONTAINER ID        IMAGE               COMMAND               CREATED             STATUS              PORTS                   NAMESbb24b2efd442        systemctl:new       "/usr/sbin/init"      9 minutes ago       Up 9 minutes        22/tcp                  sleepy_curie0467d8d2d590        httpd:new           "/run.sh"             23 minutes ago      Up 23 minutes       0.0.0.0:32769->80/tcp   test6005aaad0e99        sshd:new            "/usr/sbin/sshd -D"   44 minutes ago      Up 44 minutes       0.0.0.0:32768->22/tcp   pensive_poincare[root@localhost systemctl]# docker exec -it sleepy_curie /bin/bash[root@bb24b2efd442 /]# systemctl status sshd● sshd.service - OpenSSH server daemon   Loaded: loaded (/usr/lib/systemd/system/sshd.service; disabled; vendor preset: enabled)   Active: inactive (dead)     Docs: man:sshd(8)           man:sshd_config(5)[root@bb24b2efd442 /]# ssh 192.168.10.52 -p 22The authenticity of host '192.168.10.52 (192.168.10.52)' can't be established.ECDSA key fingerprint is SHA256:X3dOS5bVumqe/7loOyPanoa7rXqlTF79C5mavP1EQW0.ECDSA key fingerprint is MD5:00:8f:be:85:3b:97:c9:05:bb:fb:fe:17:14:49:19:9f.Are you sure you want to continue connecting (yes/no)? yesWarning: Permanently added '192.168.10.52' (ECDSA) to the list of known hosts.root@192.168.10.52's password: Last failed login: Tue Jul 28 10:46:42 CST 2020 from 172.17.0.4 on ssh:nottyThere were 2 failed login attempts since the last successful login.Last login: Tue Jul 28 10:43:54 2020 from 192.168.10.1[root@localhost ~]# exitlogoutConnection to 192.168.10.52 closed.[root@bb24b2efd442 /]# exitexit1.2.3.4.5.6.7.8.9.10.11.12.13.14.15.16.17.18.19.20.21.22.23.24.25.26.27.28.29.30.31.
```

###### 4.构建Nginx镜像

```handlebars
[root@localhost ~]# cd /opt/[root@localhost opt]# mkdir nginx   ##创建Nginx目录[root@localhost opt]# cd nginx/[root@localhost nginx]# vim DockerfileFROM centos:7MAINTAINER The is nginx <zjz>RUN yum install -y proc-devel gcc gcc-c++ zlib zlib-devel make openssl-devel wgetADD nginx-1.14.0.tar.gz /usr/localWORKDIR /usr/local/nginx-1.14.0/RUN ./configure --prefix=/usr/local/nginx && make && make installEXPOSE 80EXPOSE 443RUN echo "daemon off;">>/usr/local/nginx/conf/nginx.confWORKDIR /root/nginxADD run.sh /run.shRUN chmod 755 /run.shCMD ["/run.sh"][root@localhost nginx]# vim run.sh#!/bin/bash/usr/local/nginx/sbin/nginx   ##开启Nginx服务[root@localhost nginx]# rz    ##在xshell里上传nginx安装包[root@localhost nginx]# lsnginx-1.14.0.tar.gz[root@localhost nginx]# docker build -t nginx:new .   ##创建镜像[root@localhost nginx]# docker run -d -P nginx:new    ##创建容器ba75ff06051430938bbb014450cd16f7b2b7a2fe023969a6a0ec76051d6872c5[root@localhost nginx]# docker ps -a   ##查看容器CONTAINER ID        IMAGE               COMMAND               CREATED             STATUS              PORTS                                           NAMESba75ff060514        nginx:new           "/run.sh"             14 seconds ago      Up 14 seconds       0.0.0.0:32772->80/tcp, 0.0.0.0:32771->443/tcp   pedantic_archimedes1.2.3.4.5.6.7.8.9.10.11.12.13.14.15.16.17.18.19.20.21.22.23.24.25.26.27.28.29.30.31.32.33.
```

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200728135652379.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDkwNzgxMw==,size_16,color_FFFFFF,t_70)

###### 5.构建Tomcat镜像

```handlebars
[root@localhost opt]# mkdir tomcat[root@localhost opt]# cd tomcat/[root@localhost tomcat]# rz[root@localhost tomcat]# lsjdk-8u211-linux-x64.tar.gz[root@localhost tomcat]# rz[root@localhost tomcat]# lsapache-tomcat-8.5.35.tar.gz  jdk-8u211-linux-x64.tar.gz[root@localhost tomcat]# vim DockerfileFROM centos:7MAINTAINER this is tomcatADD jdk-8u211-linux-x64.tar.gz /usr/localWORKDIR /usr/localRUN mv jdk1.8.0_211  /usr/local/javaENV JAVA_HOME /usr/local/java     ##设置环境变量ENV JAVA_BIN /usr/local/java/binENV JRE_HOME /usr/local/java/jreENV PATH $PATH:/usr/local/java/bin:/usr/local/java/jre/binENV CLASSPATH /usr/local/java/jre/bin:/usr/local/java/lib:/usr/local/java/jre/lib/charsets.jarADD apache-tomcat-8.5.35.tar.gz  /usr/localWORKDIR /usr/localRUN mv apache-tomcat-8.5.35  /usr/local/tomcat8EXPOSE 8080ENTRYPOINT ["/usr/local/tomcat8/bin/catalina.sh","run"][root@localhost tomcat]# docker build -t tomcat:centos .  ##创建镜像[root@localhost tomcat]# docker run --name tomcat01 -p 1234:8080 -it  tomcat:centos /bin/bash##创建容器[root@localhost tomcat]# docker psCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                                           NAMES3f81e707d8b6        tomcat:centos       "/usr/local/tomcat8/…"   3 minutes ago       Up 3 minutes        0.0.0.0:1234->8080/tcp                          tomcat011.2.3.4.5.6.7.8.9.10.11.12.13.14.15.16.17.18.19.20.21.22.23.24.25.26.27.28.29.30.31.32.33.
```

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200728143626649.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDkwNzgxMw==,size_16,color_FFFFFF,t_70)

###### 6.构建MySQL镜像

```handlebars
[root@localhost mysql5.7]# cat Dockerfile#基于基础镜像FROM centos:7#维护该镜像的用户信息MAINTAINER zjz#指令集#下载相关工具RUN yum -y install \ncurses \ncurses-devel \bison \cmake \make \gcc \gcc-c++#创建mysql用户RUN useradd -s /sbin/nologin mysql#复制软件包到指定目录（将会自动解压）ADD mysql-boost-5.7.20.tar.gz /usr/local/src#指定工作目录WORKDIR /usr/local/src/mysql-5.7.20/#cmake配置及编译安装RUN cmake \-DCMAKE_INSTALL_PREFIX=/usr/local/mysql \-DMYSQL_UNIX_ADDR=/usr/local/mysql/mysql.sock \-DSYSCONFDIR=/etc \-DSYSTEMD_PID_DIR=/usr/local/mysql \-DDEFAULT_CHARSET=utf8 \-DDEFAULT_COLLATION=utf8_general_ci \-DWITH_INNOBASE_STORAGE_ENGINE=1 \-DWITH_ARCHIVE_STORAGE_ENGINE=1 \-DWITH_BLACKHOLE_STORAGE_ENGINE=1 \-DWITH_PERFSCHEMA_STORAGE_ENGINE=1 \-DMYSQL_DATADIR=/usr/local/mysql/data \-DWITH_BOOST=boost \-DWITH_SYSTEMD=1 && make && make install#更改mysql目录属主属组RUN chown -R mysql:mysql /usr/local/mysql/#删除默认安装的my.cnf文件RUN rm -rf /etc/my.cnf#复制一份my.cnf到etc目录下ADD my.cnf /etc#更改该文件权限RUN chown mysql:mysql /etc/my.cnf#设置环境变量，命令目录及库文件目录ENV PATH=/usr/local/mysql/bin:/usr/local/mysql/lib:$PATH#指定工作目录WORKDIR /usr/local/mysql/#初始化设置RUN bin/mysqld \--initialize-insecure \--user=mysql \--basedir=/usr/local/mysql \--datadir=/usr/local/mysql/data#优化启动方式RUN cp /usr/local/mysql/usr/lib/systemd/system/mysqld.service /usr/lib/systemd/system/EXPOSE 3306#直接设置运行启动脚本RUN echo -e "#!/bin/sh \nsystemctl enable mysqld" > /run.shRUN chmod 755 /run.shRUN sh /run.sh#启动容器时执行CMD ["init"]1.2.3.4.5.6.7.8.9.10.11.12.13.14.15.16.17.18.19.20.21.22.23.24.25.26.27.28.29.30.31.32.33.34.35.36.37.38.39.40.41.42.43.44.45.46.47.48.49.50.51.52.53.54.55.56.57.58.59.60.61.62.63.64.
```

my.cnf文件

```handlebars
[client]port = 3306default-character-set=utf8socket = /usr/local/mysql/mysql.sock[mysql]port = 3306default-character-set=utf8socket = /usr/local/mysql/mysql.sock[mysqld]user = mysqlbasedir = /usr/local/mysqldatadir = /usr/local/mysql/dataport = 3306character_set_server=utf8pid-file = /usr/local/mysql/mysqld.pidsocket = /usr/local/mysql/mysql.sockserver-id = 1sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES,NO_AUTO_CREATE_USER,NO_AUTO_VALUE_ON_ZERO,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,PIPES_AS_CONCAT,ANSI_QUOTES1.2.3.4.5.6.7.8.9.10.11.12.13.14.15.16.17.18.19.20.21.
```

构建及运行

```handlebars
[root@localhost mysql5.7]# docker build -t mysql:latest ....//友情提示MySQL5.7时间比较长[root@localhost mysql5.7]# docker run --name mysql_new -d -P --privileged mysql:latest e9c9f93766d149a3387aed4cb5e04425269a884fccf06256b087d00e4c262222[root@localhost mysql5.7]# docker ps -aCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                                           NAMESe9c9f93766d1        mysql:latest        "init"                   6 seconds ago       Up 5 seconds        0.0.0.0:32774->3306/tcp  1.2.3.4.5.6.7.
```

进入MySQL服务的容器中进行提权操作

```handlebars
[root@localhost mysql5.7]# docker exec -it mysql_new /bin/bash[root@e9c9f93766d1 mysql]# mysqlWelcome to the MySQL monitor.  Commands end with ; or \g.Your MySQL connection id is 3Server version: 5.7.20 Source distributionCopyright (c) 2000, 2017, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.mysql> grant all privileges on *.* to 'root'@'%' identified by '123456';Query OK, 0 rows affected, 1 warning (0.00 sec)mysql>  flush privileges;Query OK, 0 rows affected (0.01 sec)mysql> exitBye[root@e9c9f93766d1 mysql]# exitexit1.2.3.4.5.6.7.8.9.10.11.12.13.14.15.16.17.18.19.20.21.22.23.24.
```

宿主机系统安装mariadb服务来测试

登录后复制

```handlebars
[root@localhost mysql5.7]# yum install mariadb -y[root@localhost mysql5.7]# mysql -h 20.0.0.149 -P 32774 -uroot -p123456Welcome to the MariaDB monitor.  Commands end with ; or \g.Your MySQL connection id is 4Server version: 5.7.20 Source distributionCopyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.MySQL [(none)]> show databases;+--------------------+| Database           |+--------------------+| information_schema || mysql              || performance_schema || sys                |+--------------------+4 rows in set (0.01 sec)#创建一个数据库，退出后再次然后进入容器查看MySQL [(none)]> create database mydb;Query OK, 1 row affected (0.00 sec)MySQL [(none)]> exitBye[root@localhost mysql5.7]# docker exec -it mysql_new /bin/bash[root@e9c9f93766d1 mysql]# mysqlWelcome to the MySQL monitor.  Commands end with ; or \g.Your MySQL connection id is 5Server version: 5.7.20 Source distributionCopyright (c) 2000, 2017, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.mysql> show databases;+--------------------+| Database           |+--------------------+| information_schema || mydb               || mysql              || performance_schema || sys                |+--------------------+5 rows in set (0.00 sec)mysql> exitBye[root@e9c9f93766d1 mysql]# exitexit[root@localhost mysql5.7]# 1.2.3.4.5.6.7.8.9.10.11.12.13.14.15.16.17.18.19.20.21.22.23.24.25.26.27.28.29.30.31.32.33.34.35.36.37.38.39.40.41.42.43.44.45.46.47.48.49.50.51.52.53.54.55.56.57.58.
```

工程中一般不会将MySQL服务放在容器中运行，而是会单独使用服务器部署提供服务（搭建高可用集群架构）



5.21.3.10 docker 部署Jar

在服务器的/home目录下创建目录存放jar包及Dockerfile文件

将jar上传到该目录下

执行vim Dockerfile 命令创建Dockerfile文件，内容如下：

~~~makefile
FROM java:8MAINTAINER testADD operation-manager-0.0.1-SNAPSHOT.jar operation.jarEXPOSE 8080ENTRYPOINT ["java","-jar","operation.jar"]
~~~



其中：
from java:8 拉取一个jdk为1.8的docker image
maintainer 作者是test
operation-manager-0.0.1-SNAPSHOT.ja 就是你上传的jar包，替换为jar包的名称
operation.jar 是你将该jar包重新命名为什么名称，在容器中运行
expose 该容器暴露的端口是多少，就是jar在容器中以多少端口运行
entrypoint 容器启动之后执行的命令，java -jar operation.jar 即启动jar

创建好Dockerfile文件之后，执行命令 docker build -t operation . 构建镜像：
注意最后的 . 表示 Dockerfile 文件在当前目录下
operation 指定构建之后镜像名称
镜像构建成功之后，就可以运行容器了
一般是用 docker run -d --name operation -p 8080:8080 operation 命令启动，
但是为了后续的项目更新方便，这里推荐使用下面这条命令：

~~~shell
docker run -d --name operation -p 8083:8080 -v /home/fxy/docker/service1/operation-manager-0.0.1-SNAPSHOT.jar:/operation.jar operation:latest
~~~



其中：
-p 映射端口8761 本机的端口 映射的容器的端口
-v 挂载目录/home/fxy/docker/service1/operation-manager-0.0.1-SNAPSHOT.jar:本地目录 /operation.jar容器目录，在创建前容器是没有software目录的，docker 容器会自己创建
–privileged=true 关闭安全权限，否则你容器操作文件夹没有权限
operation:latest 使用的镜像名称及版本

然后docker ps 看看你的容器有没有在运行即可，运行成功会出现以下内容：

docker logs --tail 300 -f operation查看启动日志（最后300行）

项目有更新时，只需将/home/fxy/docker/service1/下的jar替换掉，然后执行

docker stop operation
docker start operation

即可更新完毕，可以通过docker ps查看是否启动成功，或者调用接口验证



### 5.22 WebSoket

  WebSocket协议是基于TCP的一种新的网络协议。它实现了浏览器与服务器全双工(full-duplex)通信——允许服务器主动发送信息给客户端。

#### WebSocket和Socket的区别

#### 　　1.WebSocket:

1. 1. websocket通讯的建立阶段是依赖于http协议的。最初的握手阶段是http协议，握手完成后就切换到websocket协议，并完全与http协议脱离了。
   2. 建立通讯时，也是由客户端主动发起连接请求，服务端被动监听。
   3. 通讯一旦建立连接后，通讯就是“全双工”模式了。也就是说服务端和客户端都能在任何时间自由得发送数据，非常适合服务端要主动推送实时数据的业务场景。
   4. 交互模式不再是“请求-应答”模式，完全由开发者自行设计通讯协议。
   5. 通信的数据是基于“帧(frame)”的，可以传输文本数据，也可以直接传输二进制数据，效率高。当然，开发者也就要考虑封包、拆包、编号等技术细节。

#### 　　2.Socket:

1. 1. 服务端监听通讯，被动提供服务；客户端主动向服务端发起连接请求，建立起通讯。
   2. 每一次交互都是：客户端主动发起请求（request），服务端被动应答（response）。
   3. 服务端不能主动向客户端推送数据。
   4. 通信的数据是基于文本格式的。二进制数据（比如图片等）要利用base64等手段转换为文本后才能传输。

### 5.23 GitLab搭建

### 5.24 Memcache 搭建

Memcache缓存是个好软件，这里讲下在Linux下安装的方法：

服务器端主要是安装memcache服务器端，目前的最新版本是 memcached-1.3.0 。
下载：http://www.danga.com/memcached/dist/memcached-1.2.2.tar.gz
另外，Memcache用到了libevent这个库用于Socket的处理，所以还需要安装libevent，libevent的最新版本是libevent-1.3。（如果你的系统已经安装了libevent，可以不用安装）
官网：http://www.monkey.org/~provos/libevent/
下载：http://www.monkey.org/~provos/libevent-1.3.tar.gz

用wget指令直接下载这两个东西.下载回源文件后。
1.先安装libevent。这个东西在配置时需要指定一个安装路径，即./configure –prefix=/usr；然后make；然后make install；
2.再安装memcached，只是需要在配置时需要指定libevent的安装路径即./configure –with-libevent=/usr；然后make；然后make install；
这样就完成了Linux下Memcache服务器端的安装。详细的方法如下：

> 1.分别把memcached和libevent下载回来，放到 /tmp 目录下：
> \# cd /tmp
> \# wget http://www.danga.com/memcached/dist/memcached-1.2.0.tar.gz
> \# wget http://www.monkey.org/~provos/libevent-1.2.tar.gz
>
> 2.先安装libevent：
> \# tar zxvf libevent-1.2.tar.gz
> \# cd libevent-1.2
> \# ./configure –prefix=/usr
> \# make
> \# make install
>
> 3.测试libevent是否安装成功：
> \# ls -al /usr/lib | grep libevent
> lrwxrwxrwx 1 root root 21 11?? 12 17:38 libevent-1.2.so.1 -> libevent-1.2.so.1.0.3
> -rwxr-xr-x 1 root root 263546 11?? 12 17:38 libevent-1.2.so.1.0.3
> -rw-r–r– 1 root root 454156 11?? 12 17:38 libevent.a
> -rwxr-xr-x 1 root root 811 11?? 12 17:38 libevent.la
> lrwxrwxrwx 1 root root 21 11?? 12 17:38 libevent.so -> libevent-1.2.so.1.0.3
> 还不错，都安装上了。
>
> 4.安装memcached，同时需要安装中指定libevent的安装位置：
> \# cd /tmp
> \# tar zxvf memcached-1.2.0.tar.gz
> \# cd memcached-1.2.0
> \# ./configure –with-libevent=/usr
> \# make
> \# make install
> 如果中间出现报错，请仔细检查错误信息，按照错误信息来配置或者增加相应的库或者路径。
> 安装完成后会把memcached放到 /usr/local/bin/memcached ，
>
> 5.测试是否成功安装memcached：
> \# ls -al /usr/local/bin/mem*
> -rwxr-xr-x 1 root root 137986 11?? 12 17:39 /usr/local/bin/memcached
> -rwxr-xr-x 1 root root 140179 11?? 12 17:39 /usr/local/bin/memcached-debug

**安装Memcache的PHP扩展**
1.在http://pecl.php.net/package/memcache 选择相应想要下载的memcache版本。
2.安装PHP的memcache扩展

> tar vxzf memcache-2.2.1.tgz
> cd memcache-2.2.1
> /usr/local/php/bin/phpize
> ./configure –enable-memcache –with-php-config=/usr/local/php/bin/php-config –with-zlib-dir
> make
> make install

3.上述安装完后会有类似这样的提示：

> Installing shared extensions: /usr/local/php/lib/php/extensions/no-debug-non-zts-2007xxxx/

4.把php.ini中的extension_dir = “./”修改为

> extension_dir = “/usr/local/php/lib/php/extensions/no-debug-non-zts-2007xxxx/”

5.添加一行来载入memcache扩展：extension=memcache.so**memcached的基本设置** ：

1.启动Memcache的服务器端：
\# /usr/local/bin/memcached -d -m 10 -u root -l 192.168.0.200 -p 12000 -c 256 -P /tmp/memcached.pid

> -d选项是启动一个守护进程，
> -m是分配给Memcache使用的内存数量，单位是MB，我这里是10MB，
> -u是运行Memcache的用户，我这里是root，
> -l是监听的服务器IP地址，如果有多个地址的话，我这里指定了服务器的IP地址192.168.0.200，
> -p是设置Memcache监听的端口，我这里设置了12000，最好是1024以上的端口，
> -c选项是最大运行的并发连接数，默认是1024，我这里设置了256，按照你服务器的负载量来设定，
> -P是设置保存Memcache的pid文件，我这里是保存在 /tmp/memcached.pid，

2.如果要结束Memcache进程，执行：

> \# kill `cat /tmp/memcached.pid`

也可以启动多个守护进程，不过端口不能重复。

3.重启apache，service httpd restart

**Memcache环境测试** ：
运行下面的php文件，如果有输出This is a test!，就表示环境搭建成功。开始领略Memcache的魅力把！
< ?php
$mem = new Memcache;
$mem->connect(”127.0.0.1″, 11211);
$mem->set(’key’, ‘This is a test!’, 0, 60);
$val = $mem->get(’key’);
echo $val;
?>



### 5.25  Kafka

#### 一、简介

##### 1.1　概述

Kafka是最初由Linkedin公司开发，是一个分布式、分区的、多副本的、多订阅者，基于zookeeper协调的分布式日志系统（也可以当做MQ系统），常见可以用于web/nginx日志、访问日志，消息服务等等，Linkedin于2010年贡献给了Apache基金会并成为顶级开源项目。

主要应用场景是：日志收集系统和消息系统。

Kafka主要设计目标如下：

- 以时间复杂度为O(1)的方式提供消息持久化能力，即使对TB级以上数据也能保证常数时间的访问性能。
- 高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒100K条消息的传输。
- 支持Kafka Server间的消息分区，及分布式消费，同时保证每个partition内的消息顺序传输。
- 同时支持离线数据处理和实时数据处理。
- Scale out:支持在线水平扩展



##### 1.2　消息系统介绍

一个消息系统负责将数据从一个应用传递到另外一个应用，应用只需关注于数据，无需关注数据在两个或多个应用间是如何传递的。分布式消息传递基于可靠的消息队列，在客户端应用和消息系统之间异步传递消息。有两种主要的消息传递模式：**点对点传递模式、发布-订阅模式**。大部分的消息系统选用发布-订阅模式。**Kafka就是一种发布-订阅模式**。



##### 1.3　点对点消息传递模式

在点对点消息系统中，消息持久化到一个队列中。此时，将有一个或多个消费者消费队列中的数据。但是一条消息只能被消费一次。当一个消费者消费了队列中的某条数据之后，该条数据则从消息队列中删除。该模式即使有多个消费者同时消费数据，也能保证数据处理的顺序。这种架构描述示意图如下：

![img](https://images2018.cnblogs.com/blog/1228818/201805/1228818-20180507190326476-771565746.png)

**生产者发送一条消息到queue，只有一个消费者能收到**。



##### 1.4　发布-订阅消息传递模式

在发布-订阅消息系统中，消息被持久化到一个topic中。与点对点消息系统不同的是，消费者可以订阅一个或多个topic，消费者可以消费该topic中所有的数据，同一条数据可以被多个消费者消费，数据被消费后不会立马删除。在发布-订阅消息系统中，消息的生产者称为发布者，消费者称为订阅者。该模式的示例图如下：

![img](https://images2018.cnblogs.com/blog/1228818/201805/1228818-20180507190443404-1266011458.png)

**发布者发送到topic的消息，只有订阅了topic的订阅者才会收到消息**。

[回到顶部](https://www.cnblogs.com/qingyunzong/p/9004509.html#_labelTop)

#### 二、Kafka的优点



##### 2.1　解耦

在项目启动之初来预测将来项目会碰到什么需求，是极其困难的。消息系统在处理过程中间插入了一个隐含的、基于数据的接口层，两边的处理过程都要实现这一接口。这允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。

##### 2.2　冗余（副本）

有些情况下，处理数据的过程会失败。除非数据被持久化，否则将造成丢失。消息队列把数据进行持久化直到它们已经被完全处理，通过这一方式规避了数据丢失风险。许多消息队列所采用的"插入-获取-删除"范式中，在把一个消息从队列中删除之前，需要你的处理系统明确的指出该消息已经被处理完毕，从而确保你的数据被安全的保存直到你使用完毕。

##### 2.3　扩展性

因为消息队列解耦了你的处理过程，所以增大消息入队和处理的频率是很容易的，只要另外增加处理过程即可。不需要改变代码、不需要调节参数。扩展就像调大电力按钮一样简单。

##### 2.4　灵活性&峰值处理能力

在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量并不常见；如果为以能处理这类峰值访问为标准来投入资源随时待命无疑是巨大的浪费。使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃。

##### 2.5　可恢复性

系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理。

##### 2.6　顺序保证

在大多使用场景下，数据处理的顺序都很重要。大部分消息队列本来就是排序的，并且能保证数据会按照特定的顺序来处理。Kafka保证一个Partition内的消息的有序性。

##### 2.7　缓冲

在任何重要的系统中，都会有需要不同的处理时间的元素。例如，加载一张图片比应用过滤器花费更少的时间。消息队列通过一个缓冲层来帮助任务最高效率的执行———写入队列的处理会尽可能的快速。该缓冲有助于控制和优化数据流经过系统的速度。

##### 2.8　异步通信

很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们。

#### 三、常用Message Queue对比

##### 3.1　RabbitMQ

RabbitMQ是使用Erlang编写的一个开源的消息队列，本身支持很多的协议：AMQP，XMPP, SMTP, STOMP，也正因如此，它非常重量级，更适合于企业级的开发。同时实现了Broker构架，这意味着消息在发送给客户端时先在中心队列排队。对路由，负载均衡或者数据持久化都有很好的支持。

##### 3.2　Redis

Redis是一个基于Key-Value对的NoSQL数据库，开发维护很活跃。虽然它是一个Key-Value数据库存储系统，但它本身支持MQ功能，所以完全可以当做一个轻量级的队列服务来使用。对于RabbitMQ和Redis的入队和出队操作，各执行100万次，每10万次记录一次执行时间。测试数据分为128Bytes、512Bytes、1K和10K四个不同大小的数据。实验表明：入队时，当数据比较小时Redis的性能要高于RabbitMQ，而如果数据大小超过了10K，Redis则慢的无法忍受；出队时，无论数据大小，Redis都表现出非常好的性能，而RabbitMQ的出队性能则远低于Redis。

##### 3.3　ZeroMQ

ZeroMQ号称最快的消息队列系统，尤其针对大吞吐量的需求场景。ZeroMQ能够实现RabbitMQ不擅长的高级/复杂的队列，但是开发人员需要自己组合多种技术框架，技术上的复杂度是对这MQ能够应用成功的挑战。ZeroMQ具有一个独特的非中间件的模式，你不需要安装和运行一个消息服务器或中间件，因为你的应用程序将扮演这个服务器角色。你只需要简单的引用ZeroMQ程序库，可以使用NuGet安装，然后你就可以愉快的在应用程序之间发送消息了。但是ZeroMQ仅提供非持久性的队列，也就是说如果宕机，数据将会丢失。其中，Twitter的Storm 0.9.0以前的版本中默认使用ZeroMQ作为数据流的传输（Storm从0.9版本开始同时支持ZeroMQ和Netty作为传输模块）。

##### 3.4　ActiveMQ

ActiveMQ是Apache下的一个子项目。 类似于ZeroMQ，它能够以代理人和点对点的技术实现队列。同时类似于RabbitMQ，它少量代码就可以高效地实现高级应用场景。

##### 3.5　Kafka/Jafka

Kafka是Apache下的一个子项目，是一个高性能跨语言分布式发布/订阅消息队列系统，而Jafka是在Kafka之上孵化而来的，即Kafka的一个升级版。具有以下特性：快速持久化，可以在O(1)的系统开销下进行消息持久化；高吞吐，在一台普通的服务器上既可以达到10W/s的吞吐速率；完全的分布式系统，Broker、Producer、Consumer都原生自动支持分布式，自动实现负载均衡；支持Hadoop数据并行加载，对于像Hadoop的一样的日志数据和离线分析系统，但又要求实时处理的限制，这是一个可行的解决方案。Kafka通过Hadoop的并行加载机制统一了在线和离线的消息处理。Apache Kafka相对于ActiveMQ是一个非常轻量级的消息系统，除了性能非常好之外，还是一个工作良好的分布式系统。

[回到顶部](https://www.cnblogs.com/qingyunzong/p/9004509.html#_labelTop)

#### 四、Kafka中的术语解释

##### 4.1　概述

在深入理解Kafka之前，先介绍一下Kafka中的术语。下图展示了Kafka的相关术语以及之间的关系：

![img](https://images2018.cnblogs.com/blog/1228818/201805/1228818-20180507190731172-1317551019.png)

上图中一个topic配置了3个partition。Partition1有两个offset：0和1。Partition2有4个offset。Partition3有1个offset。副本的id和副本所在的机器的id恰好相同。

如果一个topic的副本数为3，那么Kafka将在集群中为每个partition创建3个相同的副本。集群中的每个broker存储一个或多个partition。多个producer和consumer可同时生产和消费数据。

##### 4.2　broker

Kafka 集群包含一个或多个服务器，服务器节点称为broker。

broker存储topic的数据。如果某topic有N个partition，集群有N个broker，那么每个broker存储该topic的一个partition。

如果某topic有N个partition，集群有(N+M)个broker，那么其中有N个broker存储该topic的一个partition，剩下的M个broker不存储该topic的partition数据。

如果某topic有N个partition，集群中broker数目少于N个，那么一个broker存储该topic的一个或多个partition。在实际生产环境中，尽量避免这种情况的发生，这种情况容易导致Kafka集群数据不均衡。

##### 4.3　Topic

每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。（物理上不同Topic的消息分开存储，逻辑上一个Topic的消息虽然保存于一个或多个broker上但用户只需指定消息的Topic即可生产或消费数据而不必关心数据存于何处）

类似于数据库的表名

##### 4.3　**Partition**

topic中的数据分割为一个或多个partition。每个topic至少有一个partition。每个partition中的数据使用多个segment文件存储。partition中的数据是有序的，不同partition间的数据丢失了数据的顺序。如果topic有多个partition，消费数据时就不能保证数据的顺序。在需要严格保证消息的消费顺序的场景下，需要将partition数目设为1。

##### 4.4　Producer

生产者即数据的发布者，该角色将消息发布到Kafka的topic中。broker接收到生产者发送的消息后，broker将该消息**追加**到当前用于追加数据的segment文件中。生产者发送的消息，存储到一个partition中，生产者也可以指定数据存储的partition。

##### 4.5　Consumer

消费者可以从broker中读取数据。消费者可以消费多个topic中的数据。

##### 4.6　Consumer Group

每个Consumer属于一个特定的Consumer Group（可为每个Consumer指定group name，若不指定group name则属于默认的group）。

##### 4.7　Leader

每个partition有多个副本，其中有且仅有一个作为Leader，Leader是当前负责数据的读写的partition。

##### 4.8　Follower

Follower跟随Leader，所有写请求都通过Leader路由，数据变更会广播给所有Follower，Follower与Leader保持数据同步。如果Leader失效，则从Follower中选举出一个新的Leader。当Follower与Leader挂掉、卡住或者同步太慢，leader会把这个follower从“in sync replicas”（ISR）列表中删除，重新创建一个Follower。

学习：https://www.cnblogs.com/qingyunzong/p/9004509.html

#### 1、介绍：

**kafka是一个分布式的信息流式处理的工具。**

**Kafka的特性:**

高吞吐量、低延迟每个topic可以分多个partition, consumer group 对partition进行consume操作。

可扩展性：kafka集群支持热扩展。

持久性、可靠性：消息被持久化到本地磁盘，并且支持数据备份防止数据丢失

容错性：允许集群中节点失败（若副本数量为n,则允许n-1个节点失败）。

高并发：支持数千个客户端同时读写。

**Kafka流程：**

Kafka中发布订阅的对象是topic。我们可以为每类数据创建一个topic，把向topic发布消息的客户端称作producer，从topic订阅消息的客户端称作consumer。Producers和consumers可以同时从多个topic读写数据。一个kafka集群由一个或多个broker服务器组成，它负责持久化和备份具体的kafka消息。

Producers往Brokers里面的指定Topic中写消息，Consumers从Brokers里面拉去指定Topic的消息，然后进行业务处理。

一个topic实际是由多个partition组成的，遇到瓶颈时，可以通过增加partition的数量来进行横向扩容。单个parition内是保证消息有序。

正常的topic相当于一个MQ的队列，发布者发送message必须指定topic，然后Kafka会根据接收到的message进行load balance，均匀的分布到topic的不同的partition上，一个消费者组要全部消费这个topic上的所有partition，所以一个消费者组如果多个消费者，那么这里面的消费者是不能消费到全部消息的。

订阅topic是以一个消费组来订阅的，一个消费组里面可以有多个消费者。同一个消费组中的两个消费者，不会同时消费一个partition。换句话来说，就是一个partition，只能被消费组里的一个消费者消费，但是可以同时被多个消费组消费。因此，如果消费组内的消费者如果比partition多的话，那么就会有个别消费者一直空闲。

**zookeeper作用：**

**zookeeper是为了解决分布式一致性问题的工具。**

kafka 很多说不需要安装zk的是因为他们都使用了kafka自带的zk，至于kafka为什么使用zk，你首先要知道zk的作用, 作为去中心化的集群模式。需要要消费者知道现在那些生产者（对于消费者而言，kafka就是生产者）是可用的。如果没了zk消费者如何知道呢？如果每次消费者在消费之前都去尝试连接生产者测试下是否连接成功，效率呢？所以kafka需要zk，在kafka的设计中就依赖了zk了。

安装kafka之前需要先安装zookeeper集群，虽然卡夫卡有自带的zk集群，但是建议还是使用单独的zk集群。

具体原因：

kafka使用zookeeper来实现动态的集群扩展，不需要更改客户端（producer和consumer）的配置。broker会在zookeeper注册并保持相关的元数据（topic，partition信息等）更新。而客户端会在zookeeper上注册相关的watcher。一旦zookeeper发生变化，客户端能及时感知并作出相应调整。这样就保证了添加或去除broker时，各broker间仍能自动实现负载均衡。这里的客户端指的是Kafka的消息生产端(Producer)和消息消费端(Consumer)·

Kafka使用zk的分布式协调服务，将生产者，消费者，消息储存（broker，用于存储信息，消息读写等）结合在一起。

同时借助zk，kafka能够将生产者，消费者和broker在内的所有组件在无状态的条件下建立起生产者和消费者的订阅关系，实现生产者的负载均衡。

\1. broker在zk中注册

kafka的每个broker（相当于一个节点，相当于一个机器）在启动时，都会在zk中注册，告诉zk其brokerid，在整个的集群中，[broker.id/brokers/ids，当节点失效时，zk就会删除该节点，就很方便的监控整个集群broker的变化，及时调整负载均衡。](https://link.zhihu.com/?target=http%3A//broker.id/brokers/ids%EF%BC%8C%E5%BD%93%E8%8A%82%E7%82%B9%E5%A4%B1%E6%95%88%E6%97%B6%EF%BC%8Czk%E5%B0%B1%E4%BC%9A%E5%88%A0%E9%99%A4%E8%AF%A5%E8%8A%82%E7%82%B9%EF%BC%8C%E5%B0%B1%E5%BE%88%E6%96%B9%E4%BE%BF%E7%9A%84%E7%9B%91%E6%8E%A7%E6%95%B4%E4%B8%AA%E9%9B%86%E7%BE%A4broker%E7%9A%84%E5%8F%98%E5%8C%96%EF%BC%8C%E5%8F%8A%E6%97%B6%E8%B0%83%E6%95%B4%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E3%80%82)

\2. topic在zk中注册

在kafka中可以定义很多个topic，每个topic又被分为很多个分区。一般情况下，每个分区独立在存在一个broker上，所有的这些topic和broker的对应关系都有zk进行维护

\3. consumer(消费者)在zk中注册

所以，Zookeeper作用：管理broker、consumer。

#### 2、kafka集群搭建

**环境：**

JDK：1.8.0_221

ZK：3.4.14

Kafka：0.11.0.0

Scala：2.11.8

1. **由于ZK、Kakfa运行需要依赖JVM环境，需要先安装JDK**（网上很多，不再描述）

[https://www.oracle.com/java/technologies/javase-downloads.htmlwww.oracle.com](https://link.zhihu.com/?target=https%3A//www.oracle.com/java/technologies/javase-downloads.html)

![img](https://pic3.zhimg.com/80/v2-6dd903b161c87c33f5e803eccea5cfea_720w.png)

**2.ZK安装**

zooKeeper是作为分布式协调服务，是不需要依赖于Hadoop的环境，也可以为其他的分布式环境提供服务。

[Index of /apache/zookeeper/zookeeper-3.4.14mirror.bit.edu.cn](https://link.zhihu.com/?target=https%3A//mirror.bit.edu.cn/apache/zookeeper/zookeeper-3.4.14/)

解压：

```bash
gunzip zookeeper-3.4.14.tar.gztar -zxvf zookeeper-3.4.14.tar
```

配置：

由于是单点模式，所以配置server.1=本地IP,或者不配置server默认localhost

```text
进入conf文件夹mv zoo_sample.cfg zoo.cfg修改zoo.cfg的配置#tickTime: zookeeper中使用的基本时间单位, 毫秒值.#dataDir: 数据目录. 可以是任意目录.#initLimit: 配置leader节点和follower节点启动并且完成数据同步的时间.#syncLimit:leader节点和follower节点心跳检测的最大延迟时间.#clientPort: 监听client连接的端口号.#server.x中的“x”表示ZooKeeper Server进程的标识   例如：clientPort=2181server.1=localhost:2888:3888server.2=localhost:2889:3889server.3=localhost:2890:3890
```

![img](https://pic3.zhimg.com/80/v2-625e46a3edf7ea2fea5953a1e2751792_720w.jpg)

启动：

./zkServer.sh start

![img](https://pic4.zhimg.com/80/v2-60ec593e8b32855cddaa699fb2363473_720w.png)

验证：

./zkServer.sh status

![img](https://pic4.zhimg.com/80/v2-a63b480123c5cc41b8e3fac9598008e3_720w.png)

连接：

./zkCli.sh -server localhost

![img](https://pic2.zhimg.com/80/v2-d54278e3193492c5a3789ed374091dc1_720w.jpg)

**3、Kafka集群搭建**

](https://link.zhihu.com/?target=http%3A//kafka.apache.org/downloads)

![img](https://pic1.zhimg.com/80/v2-e5afeb42f584f79b90feba738166bc48_720w.jpg)

修改配置：

```bash
log.dirs=/Users/gaowei/Package/kafka_2.11-0.11.0.0/logzookeeper.connect=自己的IP(或者localhost):2181listeners=PLAINTEXT://自己的IP(或者localhost):9092advertised.listeners=PLAINTEXT://自己的IP(或者localhost):9092
```

![img](https://pic1.zhimg.com/80/v2-4e6d09263d716571ff3336499720aecc_720w.jpg)

启动

```text
./kafka-server-start.sh ./../config/server.properties &
```

![img](https://pic2.zhimg.com/80/v2-5e3d1d6ba2b86ec5cec0073023975775_720w.jpg)

后台启动

~~~shell
首先进入kafka的bin内然后运行sh kafka-server-start.sh -daemon ../config/server.properties就可以使kafka后台运行了
~~~



测试：

```text
1.创建topic:bin/kafka-topics.sh  --create  --zookeeper localhost:2181  --replication-factor 1  --partitions 1  --topic test2.查看topic列表：bin/kafka-topics.sh  --list  --zookeeper localhost:2181  3.生成消息：bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test 4.消费消息(从头消费)：bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic test  --from-beginning
```

创建topic:

![img](https://pic4.zhimg.com/80/v2-0ca942b28cc666fb959606ac0519aa03_720w.png)

生产者：

![img](https://pic2.zhimg.com/80/v2-99b4c0e510a4fd9298208a33d70c5365_720w.png)

消费者：

![img](https://pic1.zhimg.com/80/v2-352f62c3fe19440e6d76d33e72a71230_720w.jpg)

出现报错原因：

kafka_2.11-0.10.2.1升级了消费者命令，新版本采用bootstrap-server参数，而不是之前的zookeeper参数。其实报错里面已经很清楚了(新版本指的是kafka 0.8.0之后的版本)。

修改消费者命令：

```bash
./kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning
```

![img](https://pic2.zhimg.com/80/v2-118dfcb114dc39d7d65d1ae120a98c95_720w.jpg)



3. #### windows 下配置 kafka 

   https://www.cnblogs.com/shej123/p/10277653.html

### 5.26  Kubernetes（K8S）

[**Kubernetes**](https://www.kubernetes.org.cn/)是一个开源的，用于管理云平台中多个主机上的容器化的应用，Kubernetes的目标是让部署容器化的应用简单并且高效（powerful）,Kubernetes提供了应用部署，规划，更新，维护的一种机制。

Kubernetes一个核心的特点就是能够自主的管理容器来保证云平台中的容器按照用户的期望状态运行着（比如用户想让apache一直运行，用户不需要关心怎么去做，Kubernetes会自动去监控，然后去重启，新建，总之，让apache一直提供服务），管理员可以加载一个微型服务，让规划器来找到合适的位置，同时，Kubernetes也系统提升工具以及人性化方面，让用户能够方便的部署自己的应用（就像canary deployments）。

现在Kubernetes着重于不间断的服务状态（比如web服务器或者缓存服务器）和原生云平台应用（Nosql）,在不久的将来会支持各种生产云平台中的各种服务，例如，分批，工作流，以及传统数据库。

在Kubenetes中，所有的容器均在[**Pod**](https://www.kubernetes.org.cn/tags/pod)中运行,一个Pod可以承载一个或者多个相关的容器，在后边的案例中，同一个Pod中的容器会部署在同一个物理机器上并且能够共享资源。一个Pod也可以包含O个或者多个磁盘卷组（volumes）,这些卷组将会以目录的形式提供给一个容器，或者被所有Pod中的容器共享，对于用户创建的每个Pod,系统会自动选择那个健康并且有足够容量的机器，然后创建类似容器的容器,当容器创建失败的时候，容器会被node agent自动的重启,这个node agent叫kubelet,但是，如果是Pod失败或者机器，它不会自动的转移并且启动，除非用户定义了 replication controller。

用户可以自己创建并管理Pod,Kubernetes将这些操作简化为两个操作：基于相同的Pod配置文件部署多个Pod复制品；创建可替代的Pod当一个Pod挂了或者机器挂了的时候。而Kubernetes API中负责来重新启动，迁移等行为的部分叫做“replication controller”，它根据一个模板生成了一个Pod,然后系统就根据用户的需求创建了许多冗余，这些冗余的Pod组成了一个整个应用，或者服务，或者服务中的一层。一旦一个Pod被创建，系统就会不停的监控Pod的健康情况以及Pod所在主机的健康情况，如果这个Pod因为软件原因挂掉了或者所在的机器挂掉了，replication controller 会自动在一个健康的机器上创建一个一摸一样的Pod,来维持原来的Pod冗余状态不变，一个应用的多个Pod可以共享一个机器。

我们经常需要选中一组Pod，例如，我们要限制一组Pod的某些操作，或者查询某组Pod的状态，作为Kubernetes的基本机制，用户可以给Kubernetes Api中的任何对象贴上一组 key:value的标签，然后，我们就可以通过标签来选择一组相关的Kubernetes Api 对象，然后去执行一些特定的操作，每个资源额外拥有一组（很多） keys 和 values,然后外部的工具可以使用这些keys和vlues值进行对象的检索，这些Map叫做annotations（注释）。

Kubernetes支持一种特殊的网络模型，Kubernetes创建了一个地址空间，并且不动态的分配端口，它可以允许用户选择任何想使用的端口，为了实现这个功能，它为每个Pod分配IP地址。

现代互联网应用一般都会包含多层服务构成，比如web前台空间与用来存储键值对的内存服务器以及对应的存储服务，为了更好的服务于这样的架构，Kubernetes提供了服务的抽象，并提供了固定的IP地址和DNS名称，而这些与一系列Pod进行动态关联，这些都通过之前提到的标签进行关联，所以我们可以关联任何我们想关联的Pod，当一个Pod中的容器访问这个地址的时候，这个请求会被转发到本地代理（kube proxy）,每台机器上均有一个本地代理，然后被转发到相应的后端容器。Kubernetes通过一种轮训机制选择相应的后端容器，这些动态的Pod被替换的时候,Kube proxy时刻追踪着，所以，服务的 IP地址（dns名称），从来不变。

所有Kubernetes中的资源，比如Pod,都通过一个叫URI的东西来区分，这个URI有一个UID,URI的重要组成部分是：对象的类型（比如pod），对象的名字，对象的命名空间，对于特殊的对象类型，在同一个命名空间内，所有的名字都是不同的，在对象只提供名称，不提供命名空间的情况下，这种情况是假定是默认的命名空间。UID是时间和空间上的唯一。

官方网站:https://www.kubernetes.org.cn/



k8s全称kubernetes，这个名字大家应该都不陌生，k8s是为容器服务而生的一个可移植容器的编排管理工具，越来越多的公司正在拥抱k8s，并且当前k8s已经主导了云业务流程，推动了微服务架构等热门技术的普及和落地，正在如火如荼的发展。那么称霸容器领域的k8s究竟是有什么魔力呢？

首先，我们从容器技术谈起，在容器技术之前，大家开发用虚拟机比较多，比如vmware和openstack，我们可以使用虚拟机在我们的操作系统中模拟出多台子电脑（Linux），子电脑之间是相互隔离的，但是虚拟机对于开发和运维人员而言，存在启动慢，占用空间大，不易迁移的缺点。举一个我亲身经历过的场景吧，之前在vmware中开发了一个线下平台，为了保证每次能够顺利使用，我们就把这个虚拟机导出为OVF，然后随身携带，用的时候在服务器中部署，这里就充分体现了虚拟机的缺点。

接着，容器化技术应运而生，它不需要虚拟出整个操作系统，只需要虚拟一个小规模的环境即可，而且启动速度很快，除了运行其中应用以外，基本不消耗额外的系统资源。Docker是应用最为广泛的容器技术，通过打包镜像，启动容器来创建一个服务。但是随着应用越来越复杂，容器的数量也越来越多，由此衍生了管理运维容器的重大问题，而且随着云计算的发展，云端最大的挑战，容器在漂移。在此业务驱动下，k8s问世，提出了一套全新的基于容器技术的分布式架构领先方案，在整个容器技术领域的发展是一个重大突破与创新。

那么，K8S实现了什么？

从架构设计层面，我们关注的可用性，伸缩性都可以结合k8s得到很好的解决，如果你想使用微服务架构，搭配k8s，真的是完美，再从部署运维层面，服务部署，服务监控，应用扩容和故障处理，k8s都提供了很好的解决方案。

具体来说，主要包括以下几点：

1. 服务发现与调度
2. 负载均衡
3. 服务自愈
4. 服务弹性扩容
5. 横向扩容
6. 存储卷挂载

总而言之，k8s可以使我们应用的部署和运维更加方便。

最后，我们看下k8s的架构：

![preview](https://pic2.zhimg.com/v2-499cc023903440be0fee5cf63b689c89_r.jpg)

k8s集群由Master节点和Node（Worker）节点组成。

**Master节点**

Master节点指的是集群控制节点，管理和控制整个集群，基本上k8s的所有控制命令都发给它，它负责具体的执行过程。在Master上主要运行着：

1. Kubernetes Controller Manager（kube-controller-manager）：k8s中所有资源对象的自动化控制中心，维护管理集群的状态，比如故障检测，自动扩展，滚动更新等。
2. Kubernetes Scheduler（kube-scheduler）： 负责资源调度，按照预定的调度策略将Pod调度到相应的机器上。
3. etcd：保存整个集群的状态。

**Node节点**

除了master以外的节点被称为Node或者Worker节点，可以在master中使用命令 `kubectl get nodes`查看集群中的node节点。每个Node都会被Master分配一些工作负载（Docker容器），当某个Node宕机时，该节点上的工作负载就会被Master自动转移到其它节点上。在Node上主要运行着：

1. kubelet：负责Pod对应的容器的创建、启停等任务，同时与Master密切协作，实现集群管理的基本功能
2. kube-proxy：实现service的通信与负载均衡
3. docker（Docker Engine）：Docker引擎，负责本机的容器创建和管理

### 5.27  ElasticSearch

##### windows 下安装elasticsearch

ElasticSearch，简称ES， 是一个基于Lucene的分布式全文搜索服务器，和SQL Server的全文索引（Fulltext Index）有点类似，都是基于分词和分段的全文搜索引擎，具有分词，同义词，词干查询的功能，但是ES天生具有分布式和实时的属性。

 

##### **一，安装Java SE环境**

安装Java JDK和配置JAVA_HOME环境变量：

1，从[Java Se Download](http://www.oracle.com/technetwork/java/javase/downloads/index.html)下载和安装Java SE开发包，当前最新版本是Java SE 10.0.2

2，安装完成之后，需要在服务器上创建**JAVA_HOME**环境变量，设置变量值是：D:\Program Files\Java\jdk-10.0.2

3， 禁用Java JDK的自动更新，避免ElasticSearch收到JRE版本影响。

在控制面板（Control Panel）上点击Java图标，打开Java控制面板，切换到Update 选项卡（tab），取消选择“Check for Updates Automatically”，禁止系统自动进行JDR的自动更新。

切换到Advanced选项卡，设置Application Installation为Never install.

 

##### **二，安装ElasticSearch**

**1，从官方下载中心 [ElasticSearch Download](https://www.elastic.co/downloads/elasticsearch) 下载ElasticSearch安装包，当前最新版本是6.3.1**

2，将zip文件解压到D盘，进入 **D:\elasticsearch-6.3.1\bin** 目录，双击执行 **elasticsearch.bat，该**脚本文件执行 ElasticSearch 启动程序

3，打开浏览器，输入 **http://localhost:9200** ，显式以下画面，说明ES安装成功。

​    

   ![img](https://images2018.cnblogs.com/blog/1420905/201807/1420905-20180718110729431-393253622.png)

##### **三，安装head插件**

为了便于管理ES，可使用head插件，这是最初级的管理工具，在浏览器中显示ES集群，索引等信息，十分简便好用。 

1, 首先要安装Ｎodejs，下载地址：https://nodejs.org/en/

2, 解压  [elasticsearch-head-master](https://codeload.github.com/mobz/elasticsearch-head/zip/master) 到 **D:\elasticsearch-6.3.1****\elasticsearch-head-master**, 

3, 配置 elasticsearch-6.3.1\config\**elasticsearch.yml**

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

```
# 设成0.0.0.0让任何人都可以访问，线上服务不要这样设置。#network.host: 0.0.0.0http.port: 9200# 解决elasticsearch-head 集群健康值: 未连接问题http.cors.enabled: truehttp.cors.allow-origin: "*"
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

4, 在elasticsearch-head-master目录下执行 **npm install -g grunt-cli**

grunt 是基于Node.js的项目构建工具，可以进行打包压缩、测试、执行等等的工作，head插件就是通过grunt启动。

5, 在elasticsearch-head-master目录下执行**npm install** 安装依赖

6, 修改elasticsearch-head-master配置。

修改服务器监听地址:**Gruntfile.js** 

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

```
        connect: {            server: {                options: {                    port: 9100,                    base: '.',                    keepalive: true,                    hostname: '*'                }            }        }
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

7, 启动运行head服务, 执行 **grunt server** 命令。

8, 访问head管理页面，地址:http://localhost:9100/ 

![img](https://images2018.cnblogs.com/blog/1420905/201807/1420905-20180718113012464-410609290.png)

 **四， 配置EalsticSearch为Windows服务**

切换到ElasticSearch的bin目录执行相应命令：

安装   elasticsearch-service.bat **install**

**删除   elasticsearch-service.bat** **remove**

启动   elasticsearch-service.bat ***\*start\****

停止   elasticsearch-service.bat **stop**

###### 

#####  *** Keep learning and growing. ***



#### Elasticsearch+kibana安装windows+ liunx

什么是Kibana?
Kibana 是一个设计出来用于和 Elasticsearch 一起使用的开源的分析与可视化平台，可以用 kibana 搜索、查看、交互存放在Elasticsearch 索引里的数据，使用各种不同的图表、表格、地图等展示高级数据分析与可视化，基于浏览器的接口使你能快速创建和分享实时展现Elasticsearch查询变化的动态仪表盘，让大量数据变得简单，容易理解。

##### Kibana 7.* 安装条件

（适用windows 10 ，64位）

1. 保证安装了JDK
2. 保证安装node
3. 保证安装了Elasticsearch

##### JDK的安装：

点击[JDK官网下载](https://www.oracle.com/technetwork/java/javase/downloads/)

选择对应系统的安装包下载安装

（window10*64位操作系统）下载的版本如下图所示：

![img](https://img2018.cnblogs.com/i-beta/1432988/201912/1432988-20191203111223307-1146501561.png)

下载完毕之后双击安装，安装完毕之后进行环境变量的配置。

右键“我的电脑”---“属性”---“高级系统设置”---“环境变量”，进入环境变量的配置界面：

（2）在系统变量中“新建”环境变量 JAVA_HOME

![img](https://img-blog.csdn.net/2018072514432882?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNDcyNzIzOA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

（3）向PATH(在系统目录中找到PATH并双击)中添加 

![img](https://img2018.cnblogs.com/i-beta/1432988/201912/1432988-20191203112834878-1799079018.png)

（4）检查是否安装成功，同时按下键盘win+R键，打开运行窗口。在窗口中输入“cmd”，按“回车键（Enter）”或点击“确定”，进行测试。

- 输入java见如下显示：

![img](https://img2020.cnblogs.com/i-beta/1432988/202003/1432988-20200326102301039-999608260.png)

 

则代表成功安装。

node的安装：
点击[node官网下载](https://nodejs.org/en/)

![img](https://img2018.cnblogs.com/i-beta/1432988/201912/1432988-20191203140022816-1957030942.png)

下载双击安装

确保安装成功：输入 

node -v

![img](https://img2018.cnblogs.com/i-beta/1432988/201912/1432988-20191203140131283-106987478.png)

##### Elasticsearch的安装：

- 点击[Elasticsearch官网下载](https://www.elastic.co/cn/downloads/elasticsearch) 
- 注意这个版本号！！！
- 值得注意的是，elasticsearch的版本和kibana的版本必须一致，才可以正确运行。

![img](https://img2018.cnblogs.com/i-beta/1432988/201912/1432988-20191203140303871-680797916.png)

- 解压
- 进入bin目录，双击elasticsearch.bat（第一种方式）：等待启动
- 通过cmd的方式进入bin目录，运行elasticsearch.bat install 安装服务（第二种方式）：打开elasticsearch服务
- 配置文件可以自定义可先用默认启动，跳过
- 打开http://localhost:9200/，如果发现显示下图内容，则启动成功。

![img](https://img2018.cnblogs.com/i-beta/1432988/201912/1432988-20191203144136921-1785245649.png)

##### Kibana 的安装：

- 点击

  kibana官网下载

   ![img](https://img2018.cnblogs.com/i-beta/1432988/201912/1432988-20191203144847871-1905674228.png)

   图为下载的版本7.5.0，kibana的版本和elasticsearch的版本和必须一致。

- 修改配置（可以省略）

- 打开下图的路径文件kibana.yml（可以通过记事本方式） 

  ![img](https://img2018.cnblogs.com/i-beta/1432988/201912/1432988-20191203145040523-528876499.png)

- 设置elasticsearch.url为启动的elasticsearch（http://localhost:9200/）（其实按照默认可以不用修改配置文件）  

- ![img](https://img2018.cnblogs.com/i-beta/1432988/201912/1432988-20191203145131967-790174406.png)

- 进入kibana的bin目录，双击kibana.bat（第一种方式）

- 通过cmd的方式进入kibana的bin目录，运行kibana.bat（第二种方式）；

- 访问：http://localhost:5601，出现以下界面即完成安装。

- ![img](https://img2018.cnblogs.com/i-beta/1432988/201912/1432988-20191203145223648-935452405.png)

##### liunx安装

过程基本上一致，只记录下关键点

###### 1.1 选择 liunx包 并解压缩安装

```
https://www.elastic.co/cn/downloads/elasticsearchtar -xzvf elasticsearch-7.5.0-linux-x86_64.tar.gzmv  elasticsearch-7.5.0   elasticsearch
```

###### 1.2 修改jvm配置

```
cd  elasticsearch/configvim  jvm.options  # 修改为内存的一半  机器为32 我就配置了16
```

　　-Xms16g
　　-Xmx16g

###### 1.3 配置集群设置

vim elasticsearch.yml

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

```
cluster.name: es    集群名称，相同名称为一个集群node.name: node_1   节点名称，集群模式下每个节点名称唯一node.master: true     当前节点是否可以被选举为master节点，是：true、否：falsenode.data: true   当前节点是否用于存储数据，是：true、否：false  path.data: /data,/data1    索引数据存放的位置path.logs: /usr/local/elasticsearch/logs  日志文件存放的位置network.host: 0.0.0.0   监听地址，用于访问该eshttp.port: 9190  es对外提供的http端口，默认 9200discovery.seed_hosts: ["x.x.x.x", "x.x.x.x","x.x.x.x"]   写入候选主节点的设备地址，在开启服务后可以被选为主节点cluster.initial_master_nodes: ["x.x.x.x", "x.x.x.x", "x.x.x.x"] 初始化一个新的集群时需要此配置来选举master 或者写入节点名字http.cors.enabled: true   是否支持跨域，是：true，在使用head插件时需要此配置http.cors.allow-origin: "*"  "*" 表示支持所有域名indices.fielddata.cache.size: 16g
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

###### 1.4 创建用户 不能用root启动es

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

```
useradd  elasticsearch passwd   elasticsearch# 添加权限chown -R elasticsearch:elasticsearch  /usr/local/elasticsearch  chown -R elasticsearch:elasticsearch  /datachown -R elasticsearch:elasticsearch  /data1
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

###### 1.5 系统优化

etc/security/limits.conf，增加最大线程个数

```
vim /etc/security/limits.conf* soft nofile 65536* hard nofile 65536* soft nproc 32000* hard nproc 32000* hard memlock unlimited* soft memlock unlimited
```

vim /etc/systemd/system.conf

```
DefaultLimitNOFILE=65536DefaultLimitNPROC=32000DefaultLimitMEMLOCK=infinity/bin/systemctl daemon-reload    # 使其生效
```

vim /etc/sysctl.conf

```
vm.max_map_count=655360sysctl -p
```

###### 1.6 kibana

下载压缩

```
tar -xzvf kibana-7.5.0-linux-x86_64.tar.gzmv kibana-7.5.0-linux-x86_64 kibana
```

配置文件

vim kibana.yml

```
server.port: 9191   server.host: "0.0.0.0"# es服务器集群链接和端口elasticsearch.hosts: ["http://x.17.75.37:x", "http://x.17.75.38:x", "http://x.17.75.36:x"]# 中文设置i18n.locale: "zh-CN" 
```

权限设置或者直接用root启动

```
chown -R elasticsearch:elasticsearch /usr/local/kibananohup ./kibana --allow-root &
```

##### 集群密码添加

###### 2.1 创建证书文件

主节点一台操作

cd /usr/local/elasticsearch/

./bin/elasticsearch-certutil ca
两次回车
./bin/elasticsearch-certutil cert --ca elastic-stack-ca.p12
三次回车

```
mkdir config/certs        # 放置证书位置mv elastic-*.p12 config/certs/      chown -R elasticsearch:elasticsearch config/certs/
```

再把证书文件 elastic-certificates.p12 复制到其他master节点并赋予权限。
scp或者ftp等

###### 2.2 修改配置

所有节点配置完后重启 elasticsearch 

vim elasticsearch.yml  

```
xpack.security.enabled: truexpack.security.transport.ssl.enabled: truexpack.security.transport.ssl.verification_mode: certificatexpack.security.transport.ssl.keystore.path: certs/elastic-certificates.p12xpack.security.transport.ssl.truststore.path: certs/elastic-certificates.p12
```

###### 2.3 生成客户端证书

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

cd /usr/local/elasticsearch

bin/elasticsearch-certutil cert --ca \
config/certs/elastic-stack-ca.p12 \
-name "CN=esuser,OU=dev,DC=weqhealth,DC=com"

回车
client.p12
回车

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

拆分证书

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

```
mv client.p12 config/certs/cd config/certs/openssl pkcs12 -in client.p12 -nocerts -nodes > client-key.pemopenssl pkcs12 -in client.p12 -clcerts -nokeys  > client.crtopenssl pkcs12 -in client.p12 -cacerts -nokeys -chain > client-ca.crtchown elasticsearch:elasticsearch client*
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

###### 2.4 设置默认密码

主节点一台操作(启动es的账户)

注：如果之前运行的集群，请删掉elasticsearch.keystore 再启动后初始化密码

```
bin/elasticsearch-setup-passwords interactive
```

分别设置 elastic、apm_system、kibana、logstash_system、beats_system、remote_monitoring_user账号的密码。（密码设置最好相同）

###### 2.5 kibana中添加配置

修改 kibana.yml 文件

```
elasticsearch.username: "kibana"elasticsearch.password: "password"
```

然后用超级管理员账号 elastic 登入到 kibana。在kibana中设置角色和账号，也可以修改账号密码。

###### 2.6 验证

head  kibana curl 都可验证

#### 禁止使用虚拟内存设置

3.1 禁止系统虚拟内存

```
swapoff -a 　　关闭虚拟内存（释放）swapon -a 　　 打开虚拟内存swapon    /path/file   开启swapoff   /path/file    关闭
```

3.2 添加es配置

```
bootstrap.memory_lock: true
```

这个配置的意义：锁定物理内存地址，防止es内存被交换出去，也就是避免es使用swap交换分区，频繁的交换，会导致IOPS变高。



### 5.28 LogStash

最新在研究elastic stack (elk) ：

logstash 安装，下载最新版本的logstash: [点击打开链接](https://www.elastic.co/fr/downloads/logstash)

解压到磁盘根目录下：在logstash>bin 

1、目录下创建：logstash.conf

2、输入内容:



```html
input {    stdin{    }} output {    stdout{    }}
```

logstash -f logstash.conf

![img](https://img-blog.csdn.net/20180203095617388?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveHV5YW5odWl3ZWxjb21l/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)



![img](https://img-blog.csdn.net/20180203095649180?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveHV5YW5odWl3ZWxjb21l/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)





——

### 5.29 RockerMQ

1.介绍

[RocketMQ](https://rocketmq.apache.org/) 是一款开源的分布式消息系统，基于高可用分布式集群技术，提供低延时的、高可靠的消息发布与订阅服务。同时，广泛应用于多个领域，包括异步通信解耦、企业解决方案、金融支付、电信、电子商务、快递物流、广告营销、社交、即时通信、移动应用、手游、视频、物联网、车联网等。

具有以下特点：

- 能够保证严格的消息顺序
- 提供丰富的消息拉取模式
- 高效的订阅者水平扩展能力
- 实时的消息订阅机制
- 亿级消息堆积能力

### RocketMQ 基本使用

- 下载 RocketMQ

下载 [RocketMQ最新的二进制文件](https://www.apache.org/dyn/closer.cgi?path=rocketmq/4.3.2/rocketmq-all-4.3.2-bin-release.zip)，并解压

解压后的目录结构如下：

~~~conf
apache-rocketmq├── LICENSE├── NOTICE├── README.md├── benchmark├── bin├── conf└── lib
~~~

- 启动 NameServer

```
nohup sh bin/mqnamesrv &tail -f ~/logs/rocketmqlogs/namesrv.log
```

- 启动 Broker

```
nohup sh bin/mqbroker -n localhost:9876 &tail -f ~/logs/rocketmqlogs/broker.log
```

- 发送、接收消息

发送消息：

```
sh bin/tools.sh org.apache.rocketmq.example.quickstart.Producer
```

发送成功后显示：`SendResult [sendStatus=SEND_OK, msgId= …`

接收消息：

```
sh bin/tools.sh org.apache.rocketmq.example.quickstart.Consumer
```

接收成功后显示：`ConsumeMessageThread_%d Receive New Messages: [MessageExt…`

- 关闭 Server

```
sh bin/mqshutdown brokersh bin/mqshutdown namesrv
```

官方文档：https://github.com/alibaba/spring-cloud-alibaba/wiki/RocketMQ

## 六：底层学习

### 6.1 HashMap底层学习

### 6.2 Spring 源码学习

### 6.3 Mybatis源码学习

### 6.4  SpringBoot源码学习

## 七：算法学习

### 算法的定义及特性

在数学和计算机科学/算学之中，算法/演算法/算则法（algorithm）为一个计算的具体步骤，常用于计算、数据处理和自动推理。精确而言，算法是一个表示为有限长列表的有效方法。算法应包含清晰定义的指令用于计算函数。

算法中的指令描述的是一个计算，当其运行时能从一个初始状态和初始输入（可能为空）开始，经过一系列有限而清晰定义的状态最终产生输出并停止于一个终态。一个状态到另一个状态的转移不一定是确定的。随机化算法在内的一些算法，包含了一些随机输入。

形式化算法的概念部分源自尝试解决希尔伯特提出的判定问题，并在其后尝试定义有效可计算性或者有效方法中成形。这些尝试包括库尔特·哥德尔、雅克·埃尔布朗和斯蒂芬·科尔·克莱尼分别于1930年、1934年和1935年提出的递归函数，阿隆佐·邱奇于1936年提出的λ演算，1936年埃米尔·莱昂·珀斯特的Formulation 1和艾伦·图灵1937年提出的图灵机。即使在当前，依然常有直觉想法难以定义为形式化算法的情况。

一个算法应该具有以下五个重要的特征：

有穷性（Finiteness）算法的有穷性是指算法必须能在执行有限个步骤之后终止；

确切性(Definiteness)算法的每一步骤必须有确切的定义；

输入项(Input)一个算法有0个或多个输入，以刻画运算对象的初始情况，所谓0个输入是指算法本身定出了初始条件；

输出项(Output)一个算法有一个或多个输出，以反映对输入数据加工后的结果。没有输出的算法是毫无意义的；

可行性(Effectiveness)算法中执行的任何计算步骤都是可以被分解为基本的可执行的操作步，即每个计算步都可以在有限时间内完成（也称之为有效性）。

02算法的设计

**设计原则**

正确性算法的正确性是指算法至少应该具有输入，输出和加工处理无歧义，能正确反映问题的需求，能够得到问题的正确答案。

算法正确大体分为四个层次：

\1. 算法程序没有语法的错误。

\2. 算法程序对于合法的输入数据能够产生满足要求的输出的结果。

\3. 算法程序对于非法的输入数据能够得出满足规格说明的结果。

\4. 算法程序对于精心选择的，甚至刁难的测试数据都有满足要求的输出结果。

可读性可读性：算法设计的另一个目的是为了便于阅读，理解和交流。

写代码的目的一是为了计算机执行，另一个为了便于他人阅读，让人理解和交流。

键壮性当输入数据不合法时，算法也能做出相关处理，而不是产生异常或莫名其妙的结果。

时间效率高和存储量低**设计方法**

1）、递归和递推。递归和递推是学习算法设计的第一步。递归算法是把大问题分解成相对较小的问题的过程，而递推就是从小问题逐步推导出大问题的过程。无论递归还是递推，都应该有初始状态。

2）、搜索、枚举及优化剪枝。搜索在所有算法中既是最简单也是最复杂的算法。说它简单，是因为算法本身并不复杂，实现容易；说它最复杂，是因为要对搜索的范围进行一定的控制，不然就会出现超时等问题。搜索技术主要包括广度优先搜索和深度优先搜索。当其余算法都无法对问题进行求解时，搜索或许是唯一可用的方法。搜索是对问题的解空间进行遍历的过程。有时问题解空间相当庞大，完全遍历解空间是不现实的，此时就必须充分发掘问题所包含的约束条件，在搜索过程中应用这些条件进行剪枝，从而减少搜索量。

3）、动态规划（简称DP）。动态规划的特点是能够把很复杂的问题分解成一个个阶段来处理的递推方法，动态规划必须符合两个特点：无后效性（一个状态的抉择不会影响到更大问题的状态的抉择）及最优化原理（一个大问题的最优性必须建立在其子问题的最优性之上）。动态规划是竞赛中经常出现的的类型，而且变化很大（有线性DP，环形DP，树形DP等），难易跨度大，技巧性强，甚至还有DP的优化等问题。

4）、贪心。贪心算法是所谓的“只顾眼前利益”的算法。其具体策略是并不从整体最优上加以考虑，而是选取某种意义下的局部最优解。当然使用贪心算法时，要使得到的结果也是整体最优的。

5）、分治、构造等。分治就是把问题分成若干子问题，然后“分而治之”；构造是指按照一定的规则产生解决问题的方法。这两种算法都是在合理的分析题目后，通过一定的规律性推导，从而解决问题。快速排序可以认为是利用了分治法。

03算法效率的度量方法

**事后统计方法**

这种方法主要是通过设计好的测试程序和数据,利用计算机对不同算法编制的程序的运行时间进行时间比较,从而确定算法效率的高低。

缺陷必须根据算法提前编写好测试程序,花费时间精力较大。

运行时间严重依赖硬件以及软件等环境因素,可能会影响算法本身的优劣。

算法的测试数据设计困难,并且程序的运行时间和测试数据的规模有很大关系。

总结事后统计法虽然直观,但是实际困难且缺陷多,很少使用。

事前分析估算方法

在计算机程序编程前，依据统计方法对算法进行估算。

一个用高级程序语言编写的程序在计算机上运行时所消耗的时间取决于下列因素：

算法采用的策略，方法(算法优劣的根本)

编译产生的代码质量(软件)

问题的输入规模

机器执行指令的速度(硬件)

一个程序的运行时间依赖于算法的好坏和问题的输入规模,所谓问题输入规模的是指输入量的多少。

在分析程序的分析时间时，最重要的是把程序看成是独立于程序设计语言的算法或者是一系列步骤。

分析一个算法的运行时间时，重要的是把基本操作的数量与输入规模关联起来，即基本操作的数量必须表示成输入规模的函数。随着问题输入规模（n）越来越大，它们在时间效率上的差异也就越来越大.

\#include <stdio.h>

/**

\* 1-100求和

\* @param end

\* @return

*/

int sum(int end){

int result = 0;

for (int i=1;i<=end;i++){

result += i;

}

return result;

}

/**

\* 高斯算法

\* @param end

\* @return

*/

int simpleSum(int end){

int result = (1+end)*end/2;

return result;

}

int main() {

int res = sum(100);

printf("1+2+3+...+100=%d\n",res);

int res2 = simpleSum(100);

printf("1+2+3+...+100=%d\n",res2);

return 0;

}

这两种求1-100以内和的算法随着end数值的增大(不考虑int溢出),算法优劣不言而喻。

04算法的渐进增长

先看几组算法的变化:

A

![img](http://pics7.baidu.com/feed/dbb44aed2e738bd4ea892f0675e3bbd0267ff9c8.jpeg?token=d671def4663dcfd42cbf05f2d77e6308&s=58883472190B504D5EF5F1DA0300C0B1)

当n=1时, C要优于A(C的执行次数要比A少),随着n的增加,A要优于C.所以，综上来说A要优于C.

函数的渐近增长：给定两个函数f(n)和g(n)，如果存在一个整数N，使得对于所有的n > N，f(n)总是比g(n)大，那么，我们说f(n)的渐近增长快于g(n)。

随着n的不断增大，A,B,C,D算法的常数对总体的执行次数影响可以忽略。

B

![img](http://pics4.baidu.com/feed/86d6277f9e2f070850308de13b4c849fa801f28d.jpeg?token=417697b272b548115ab03591c583f739&s=58883C721312546D1EDD91CA0300E0B1)

C

![img](http://t11.baidu.com/it/u=3458919514,3676025012&fm=173&app=25&f=JPG?w=516&h=627&s=5AA83462491B664F1E5D94DA0300E0B1)

观察发现,最高次幂大的函数,随着n的增大,n的最高次幂大的结果的变化也大。

**时间复杂度**

一般情况下，算法中基本操作重复执行的次数是问题规模n的某个函数，用T(n)表示，若有某个辅助函数f(n),使得当n趋近于无穷大时，T(n)/f(n)的极限值为不等于零的常数，则称f(n)是T(n)的同数量级函数。记作T(n)=Ｏ(f(n)),称Ｏ(f(n)) 为算法的渐进时间复杂度，简称时间复杂度。

渐近记号（Asymptotic Notation）通常有 O、 Θ 和 Ω 记号法。Θ 记号渐进地给出了一个函数的上界和下界，当只有渐近上界时使用 O 记号，当只有渐近下界时使用 Ω 记号。尽管技术上 Θ 记号较为准确，但通常仍然使用 O 记号表示。

一般情况下,随着n的增大,T(n)增长最慢的算法为最优算法.

推导大O阶

用常数1取代运行时间中的所有加法常数

在修改后的运行次数函数中，只保留最高项

如果最高项存在且不是1，则去除与这个项相乘的常数。

**常数阶**以经典的高斯算法求和为例,

/**

\* 高斯方法

\* @param end

\* @return

*/

int simpleSum(int end){

int result = (1+end)*end/2;

printf("result=%d\n",result);

return result;

}

程序执行两步便获取到结果,所以时间复杂度为T(n)=2,按照推导大O阶方法,时间复杂度为O(1).

**线性阶**以1-100 求和为例:

/**

\* 1-100求和

\* @param end

\* @return

*/

int sum(int end){

int result = 0;

for (int i=1;i<=end;i++){

result += i;

}

return result;

}

for 循环中共执行的次数取决于end的值,所以时间复杂度为T(n)=n ,按照推导大O阶的方法,记做O(n)。

**对数阶**void logFunc(int n){

int count = 1;

while(count<n){

count = count * 2 ;

}

printf("count=%d\n",count);

}

设循环x次后退出循环(count>=n),即 2^x = n,则：x= logn 。所以时间复杂度为O(logn);

**平方阶**void square(int n){

int sum = 0;

for (int i=0;i<n;i++){

for (int j=0;j<n;j++){

sum = i+j;

}

}

printf("sum=%d\n",sum);

}

内层循环执行n^2次, 时间复杂度为:O(n^2);

常用时间复杂度，如下表所示：

![img](http://pics6.baidu.com/feed/8601a18b87d6277f8c1ef2d2fb502336e824fcbf.jpeg?token=a37d1c1d7ff0f64a9a2c1c08d72707a5&s=5A2834621FD348434AFDF1CA0300C0B1)

常见的时间复杂度消耗时间的大小排列:

O(1)< O(logn)< O(n)< O(nlogn)< O(n^2)< O(n^3)< O(2^n)< O(n!)< O(n^n)

**时间复杂度练习**

分析下列各程序段的时间复杂度

(1)

void main() {

int i=1,k=0,n=10;

while (i<=n-1) {

k+=10*i;i++;

}

}

(2)

void main() {

int i=1,k=0,n=100; do {

k+=10*i;i++;

}while (i==n)

}

(3)

void main() {

int i=1,j=0,n=10;

while (i+j<=n)

if (i>j)

j++;

else

i++;

}

(4)

void main() {

int n=10,x=n,y=0;

while (x>=(y+1)*(y+1))

y++;

}

(5)

void main() {

int n=9,i=1; while (i<=n)

i=i*3;

}

(6)

计算斐波拉契数列的时间复杂度。F(n)=f(n-1)+f(n-2)

(7)计算该函数的时间复杂度。F(n)=6f(n-1)-9f(n-2) 即fn=6fn-1-9fn-2 (8)求多项式A(x)的值的算法可直接根据下列两个公式之一来设计：(1)A(x)=anxn+ an-1xn-1 +……+ a1x + a0 (2)A(x)=(…(anx+ an-1)x+…. a1)x)+ a0 根据算法的时间复杂性比较这两种算法的优劣。

答案：(1) O(n)

(2) O(1)

(3) O(n)

(4) O(√n)

(5)O(log3n)

(6)方法：假设F(n)的时间复杂度为T(n),有 t(n)=t(n-1)+t(n-2)<2t(n-1)<2*2t(n-2)<2*2*2t(n-3)<....<2nt(0)=O(2n)

即t(n)<O(2n) 又 t(n)=t(n-1)+t(n-2)>2t(n-2)<2*2t(n-4)<2*2*2t(n-8)>....>2n/2t

(1)(n为奇数时，或2n/2t(0),n为偶数时) 即：t(n)>O(2n/2) 所以O(2n/2)<t(n)<O(2n) 取最坏情况上限，即t(n)≈O(2n)

（7）解：令fn=rn，则原式变为rn-6rn-1+9rn-2=0 同除以rn-2 则原式为r2-6r+9=0 如果解出来的是重根的话，则第一个根以rn代入，第2个重根以nrn代入，第3个重根以n2rn代入，第4个重根以n3rn代入，依此类推。解出的两个根为重根，均为3 所以，tn=c1*3n+c2*n*3n 依题意知t0=0,t1=1,代入后得：t0=c1*30+c2*0*30=0 t1=c1*31+c2*1*31=1 解得：c1=0,c2=1/3 则 tn=1/3*n*3n

(8)解：

(1)A(x)=anxn+ an-1xn-1 +……+ a1x + a0

(2)A(x)=(…(anx+ an-1)x+…. a1)x)+ a0 公式一：假设有一专门的子程序用于计算xn ，则x2需运乘法2次，x3需运行乘法3次，xn需运行乘法n次。由此可知，使用公式一时，子程序被调用的次数为n+(n-1)+(n-2)+….+1=n(n+1)/2。公式二：使用一个简单的循环运行n-1次即可。

**最坏情况和平均情况**

算法(Algorithms)的复杂度(Complexity)是指运行一个算法所需消耗的资源(时间或者空间)。同一个算法处理不同的输入数据所消耗的资源也可能不同，所以分析一个算法的复杂度时，主要有三种情况可以考虑，最差情况(Worst Case)下的，平均情况(Average Case)的， 最好情况(Best Case)下的。

算法的分析也是类似，我们查找一个有n个随机数字数组中的某个数字，最好的情况是第一个数字就是，那么算法的时间复杂度为O(1)，但也有可能这个数字就在最后一个位置上待着，那么算法的时间复杂度就是O(n)，这是最坏的一种情况了。

最坏情况运行时间是一种保证，那就是运行时间将不会再坏了。在应用中，这是一种最重要的需求，通常，除非特别指定，我们提到的运行时间都是最坏情况的运行时间。

而平均运行时间也就是从概率的角度看，这个数字在每一个位置的可能性是相同的，所以平均的查找时间为n/2次后发现这个目标元素。平均情况更能反映大多数情况下算法的表现。平均情况分析就是对所有输入尺寸为n的输入，让算法运转一遍，然后取它们的平均值。当然，实际中不可能将所有可能的输入都运行一遍，因此平均情况通常指的是一种数学期望值，而计算数学期望值则需要对输入的分布情况进行假设。

平均运行时间是所有情况中最有意义的，因为它是期望的运行时间。也就是说，我们运行一段程序代码时，是希望看到平均运行时间的。可现实中，平均运行时间很难通过分析得到，一般都是通过运行一定数量的实验数据后估算出来的。

有时候我们还需要知道最好情况是什么，这有两层意义：一是我们想知道如果运气好，能好到什么程度；二是如果我们能够证明好运气与我们同在，当然需要知道运气好的时候算法表现如何。这种最好分析就是在给定输入规模的时候，看看哪种输入能使算法的运行最有效率。当然，有人认为这种最好情况分析有点假：我们可以操控输入来使一个本来很慢的算法表现得很快，从而达到蒙蔽人的效果。

对算法的分析，一种方法是计算所有情况的平均值，这种时间复杂度的计算方法称为平均时间复杂度。另一种方法是计算最坏情况下的时间复杂度，这种方法称为最坏时间复杂度。一般在没有特殊说明的情况下，都是指最坏时间复杂度。

为什么要分析最坏情况下的算法时间复杂性？

最差情况下的复杂度是所有可能的输入数据所消耗的最大资源，如果最差情况下的复杂度符合我们的要求， 我们就可以保证所有的情况下都不会有问题。

某些算法经常遇到最差情况。比如一个查找算法，经常需要查找一个不存在的值。

也许你觉得平均情况下的复杂度更吸引你，可是平均情况也有几点问题。

第一，难计算，多数算法的最差情况下的复杂度要比平均情况下的容易计算的多，

第二，有很多算法的平均情况和最差情况的复杂度是一样的.

第三，什么才是真正的平均情况？如果你假设所有可能的输入数据出现的概率是一样的话，也是不合理的。其实多数情况是不一样的。而且输入数据的分布函数很可能是你没法知道。

考虑最好情况的复杂度更是没有意义。几乎所有的算法你都可以稍微修改一下，以获得很好的最好情况下的复杂度(要看输入数据的结构，可以是O(1))。怎样修改呢?

预先计算好某一输入的答案，在算法的开始部分判断输入，如果符合，给出答案。

**空间复杂度**

空间复杂度(Space Complexity)是对一个算法在运行过程中临时占用存储空间大小的量度，记做S(n)=O(f(n))。比如直接插入排序的时间复杂度是O(n^2),空间复杂度是O(1) 。而一般的递归算法就要有O(n)的空间复杂度了，因为每次递归都要存储返回信息。一个算法的优劣主要从算法的执行时间和所需要占用的存储空间两个方面衡量。

类似于时间复杂度的讨论，一个算法的空间复杂度S(n)定义为该算法所耗费的存储空间，它也是问题规模n的函数。渐近空间复杂度也常常简称为空间复杂度。空间复杂度(SpaceComplexity)是对一个算法在运行过程中临时占用存储空间大小的量度。一个算法在计算机存储器上所占用的存储空间，包括存储算法本身所占用的存储空间，算法的输入输出数据所占用的存储空间和算法在运行过程中临时占用的存储空间这三个方面。算法的输入输出数据所占用的存储空间是由要解决的问题决定的，是通过参数表由调用函数传递而来的，它不随本算法的不同而改变。

存储算法本身所占用的存储空间与算法书写的长短成正比，要压缩这方面的存储空间，就必须编写出较短的算法。算法在运行过程中临时占用的存储空间随算法的不同而异，有的算法只需要占用少量的临时工作单元，而且不随问题规模的大小而改变，我们称这种算法是“就地\”进行的，是节省存储的算法，有的算法需要占用的临时工作单元数与解决问题的规模n有关，它随着n的增大而增大，当n较大时，将占用较多的存储单元，例如快速排序和归并排序算法就属于这种情况。

分析一个算法所占用的存储空间要从各方面综合考虑。如对于递归算法来说，一般都比较简短，算法本身所占用的存储空间较少，但运行时需要一个附加堆栈，从而占用较多的临时工作单元；若写成非递归算法，一般可能比较长，算法本身占用的存储空间较多，但运行时将可能需要较少的存储单元。一个算法的空间复杂度只考虑在运行过程中为局部变量分配的存储空间的大小，它包括为参数表中形参变量分配的存储空间和为在函数体中定义的局部变量分配的存储空间两个部分。

若一个算法为递归算法，其空间复杂度为递归所使用的堆栈空间的大小，它等于一次调用所分配的临时存储空间的大小乘以被调用的次数(即为递归调用的次数加1，这个1表示开始进行的一次非递归调用)。算法的空间复杂度一般也以数量级的形式给出。如当一个算法的空间复杂度为一个常量，即不随被处理数据量n的大小而改变时，可表示为O(1)；当一个算法的空间复杂度与以2为底的n的对数成正比时，可表示为O(log2n)；当一个算法的空间复杂度与n成线性比例关系时，可表示为O(n).若形参为数组，则只需要为它分配一个存储由实参传送来的一个地址指针的空间，即一个机器字长空间；若形参为引用方式，则也只需要为其分配存储一个地址的空间，用它来存储对应实参变量的地址，以便由系统自动引用实参变量。

### 7.1 红黑树



概念：自平衡，左旋，右旋

红黑树也是二叉查找树，我们知道，二叉查找树这一数据结构并不难，而红黑树之所以难是难在它是自平衡的二叉查找树，在进行插入和删除等可能会破坏树的平衡的操作时，需要重新自处理达到平衡状态。现在在脑海想下怎么实现？是不是太多情景需要考虑了？啧啧，先别急，通过本文的学习后，你会觉得，其实也不过如此而已

#### 红黑树定义和性质

红黑树是一种含有红黑结点并能自平衡的二叉查找树。它必须满足下面性质：

- 性质1：每个节点要么是黑色，要么是红色。
- 性质2：根节点是黑色。
- 性质3：每个叶子节点（NIL）是黑色。
- 性质4：每个红色结点的两个子结点一定都是黑色。
- **性质5：任意一结点到每个叶子结点的路径都包含数量相同的黑结点。**



![img](https://upload-images.jianshu.io/upload_images/2392382-4996bbfb4017a3b2.png?imageMogr2/auto-orient/strip|imageView2/2/w/526/format/webp)

红黑树并不是一个*完美*平衡二叉查找树，从图1可以看到，根结点P的左子树显然比右子树高，但左子树和右子树的黑结点的层数是相等的，也即任意一个结点到到每个叶子结点的路径都包含数量相同的黑结点(性质5)。所以我们叫红黑树这种平衡为**黑色完美平衡**。



![img](https://upload-images.jianshu.io/upload_images/2392382-abedf3ecc733ccd5.png?imageMogr2/auto-orient/strip|imageView2/2/w/772/format/webp)

我们把正在处理(遍历)的结点叫做当前结点，如图2中的D，它的父亲叫做父结点，它的父亲的另外一个子结点叫做兄弟结点，父亲的父亲叫做祖父结点。

前面讲到红黑树能自平衡，它靠的是什么？三种操作：左旋、右旋和变色。

- **左旋**：以某个结点作为支点(旋转结点)，其右子结点变为旋转结点的父结点，右子结点的左子结点变为旋转结点的右子结点，左子结点保持不变。如图3。
- **右旋**：以某个结点作为支点(旋转结点)，其左子结点变为旋转结点的父结点，左子结点的右子结点变为旋转结点的左子结点，右子结点保持不变。如图4。
- **变色**：结点的颜色由红变黑或由黑变红。



细：https://www.jianshu.com/p/e136ec79235c

### 7.2 堆 栈 方法区

### 7.3 冒泡排序

### 7.4  排序二叉树

### 7.5 平衡二叉树

### 7.6 B+树

### 7.7 递归

### 7.8 快速排序

　快速排序（Quicksort）是对冒泡排序的一种改进。在大学学过之后现在基本忘了，最近在好多地方都看到说快速排序在面试会问到，于是自己也准备重新拾起以前忘记的东西来，慢慢的积累自己的基础知识。fighting

**算法概念**

　　快速排序由C. A. R. Hoare在1962（50多年了呢）年提出，它的基本思想是：通过一趟排序将要排序的数据分割成独立的两部分，其中一部分的所有数据都比另外一部分的所有数据都要小，然后再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列（摘自百度百科）。

　　快速排序采用了一种分治的策略，所以有时候我们也称为分治算法。

**算法思想**

　　1．先从数列中取出一个数作为基准数，一般会取第一个数做为基准数。

　　2．然后对数列进行分区，首先将比这个基准数大的数全放到它的右边，小于或等于基准数的数全放到它的左边（一刀切，左边小于基准数，右边大于基准数）。

　　3．再对划分的左右区间重复第二步，直到各区间只剩一个数就完成了排序。

　　下面画一个详细的大图，只画了第一趟排序的过程，知道第一躺怎么排序，后面都是一样的。

　快速排序（Quicksort）是对冒泡排序的一种改进。在大学学过之后现在基本忘了，最近在好多地方都看到说快速排序在面试会问到，于是自己也准备重新拾起以前忘记的东西来，慢慢的积累自己的基础知识。fighting

**算法概念**

　　快速排序由C. A. R. Hoare在1962（50多年了呢）年提出，它的基本思想是：通过一趟排序将要排序的数据分割成独立的两部分，其中一部分的所有数据都比另外一部分的所有数据都要小，然后再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列（摘自百度百科）。

　　快速排序采用了一种分治的策略，所以有时候我们也称为分治算法。

**算法思想**

　　1．先从数列中取出一个数作为基准数，一般会取第一个数做为基准数。

　　2．然后对数列进行分区，首先将比这个基准数大的数全放到它的右边，小于或等于基准数的数全放到它的左边（一刀切，左边小于基准数，右边大于基准数）。

　　3．再对划分的左右区间重复第二步，直到各区间只剩一个数就完成了排序。

　　下面画一个详细的大图，只画了第一趟排序的过程，知道第一躺怎么排序，后面都是一样的。

![img](https://images2015.cnblogs.com/blog/717907/201610/717907-20161029164601609-707252512.png)



算法如下：

~~~java
package com.roc.Quicksort;/** * 快速排序 *  * @author liaowp *  */public class Quicksort {    static void sort(int value[], int left, int right) {        if (left < right) {// 判断左边的下标是小于右            int i = left, j = right;// i为小值，j为大值            int temp = value[left];// 默认中间数为temp，即最左边的数            while (i < j) {// 如果i<j                while (i < j && value[j] >= temp) {// 从右往左比较,如果i<j且value[j]>=temp                    j--;                }                if (i < j) {// 如果i<j，找到有比中间数大的                    value[i] = value[j];// 左边的数放右边的数                    i++;// 左移一位                }                while (i < j && value[i] < temp) {// 从左往右找                    i++;                }                if (i < j) {// 找到有比中间数小的，替换到右边                    value[j] = value[i];                    j--;                }            }            value[i] = temp;            for (int n = 0; n < value.length; n++) {                System.out.print(value[n] + " ");            }            System.out.println();            sort(value, left, i - 1);// 左边的重复            sort(value, i + 1, right);// 右边的重复        }    }    public static void main(String[] args) {        int value[] = { 5, 1, 8, 4, 15 };        System.out.print("原始数据：");        for (int i = 0; i < value.length; i++) {            System.out.print(value[i] + " ");        }        System.out.println();        sort(value, 0, 4);        System.out.print("排序结果：");        for (int i = 0; i < value.length; i++) {            System.out.print(value[i] + " ");        }    }}
~~~

执行结果如下：

~~~
原始数据：5 1 8 4 15 4 1 5 8 15 1 4 5 8 15 1 4 5 8 15 排序结果：1 4 5 8 15 
~~~

注意：第一遍快速排序不会直接得到最终结果，只会把比基准数大和比基准数小的数分到基准数的两边。为了得到最后结果，需要再次对基准数两边的数组分别执行此步骤，然后再分解数组，直到数组不能再分解为止（只有一个数据），才能得到正确结果。

## 八：综合学习

### 8.1 Vmware 虚拟机

####   8.1.1 CenterOs7.0的安装 （Linux环境搭建）

  ![image-20201114225507277](C:\Users\lei41\AppData\Roaming\Typora\typora-user-images\image-20201114225507277.png)

####  8.1.2 Linux环境下安装 FastDfs 文件服务器

##### 8.1.2.1 安装GCC

```shell
[root@localhost ~]# yum -y install gcc-c++
```

*ps:检查gcc-c++是否已经安装(如果已安装，执行 yum -y install gcc-c++ 也会提示)*

```shell
[root@localhost src]# whereis gcc   gcc:[root@localhost src]#        # 未安装输出gcc: /usr/bin/gcc /usr/lib/gcc /usr/libexec/gcc /usr/share/man/man1/gcc.1.gz        #已安装输出
```



##### 8.1.2.1 安装libevent

FastDFS依赖libevent库，需要安装:

```shell
[root@localhost ~]# yum -y install libevent
```

```shell
[root@localhost ~]# cd /usr/local/src/    #切换到下载目录[root@localhost src]# wget -O libfastcommon-1.0.39.tar.gz  https://codeload.github.com/happyfish100/libfastcommon/tar.gz/V1.0.39 #下载（如果下载慢 可以将下载好的文件上传到此目录)[root@localhost src]# tar -zxvf libfastcommon-1.0.39.tar.gz      #解压[root@localhost src]# cd libfastcommon-1.0.39/# 安装[root@localhost libfastcommon-1.0.39]# ./make.sh [root@localhost libfastcommon-1.0.39]# ./make.sh  install
```



##### 8.1.2.1 安装libfastcommon

 libfastcommon是FastDFS官方提供的，libfastcommon包含了FastDFS运行所需要的一些基础库。

下载地址： https://github.com/happyfish100/libfastcommon/releases 选择合适的版本



##### 8.1.2.1 安装FastDFS

下载地址：https://github.com/happyfish100/fastdfs/releases 选择合适的版本	

```shell
[root@localhost libfastcommon-1.0.39]# cd /usr/local/src/      #切换到下载目录#下载（如果下载慢 可以将下载好的文件上传到此目录)[root@localhost src]# wget -O fastdfs-5.11.tar.gz https://codeload.github.com/happyfish100/fastdfs/tar.gz/V5.11[root@localhost src]# tar -zxvf fastdfs-5.11.tar.gz   #解压[root@localhost src]# cd fastdfs-5.11/#安装[root@localhost fastdfs-5.11]# ./make.sh [root@localhost fastdfs-5.11]# ./make.sh  install
```

![image-20201115001750705](C:\Users\lei41\AppData\Roaming\Typora\typora-user-images\image-20201115001750705.png)



Linux重启防火墙  systemctl restart iptables.service



tracker

​       /etc/init.d/fdfs_tracker start  #启动tracker

​      /etc/init.d/fdfs_tracker stop #关闭tracker

storaged

​     /etc/init.d/fdfs_storaged start  #启动storaged 

​      /etc/init.d/fdfs_storaged stop #关闭storaged

### 8.2 开发辅助操作

#### 8.2.1md转html

#####  安装

```
npm install -g i5ting_toc
```

##### 用法

###### 进入 markdown 文件所在的文件夹

举个栗子:
 你的`sample.md`文件放在桌面上
 `cd /Users/dora/Desktop/`

###### 进入 md 文件所在的文件夹后, 输入命令:

```
i5ting_toc -f sample.md -o
```

#### 8.2.2 html转pdf

#####  安装

###### linux版本

~~~
rpm -ivh wkhtmltox-0.12.5-1.centos7.x86_64.rpm 安装
~~~

~~~
rpm -q wkhtmltox    查看是否安装成功
~~~

~~~
wkhtmltopdf https://www.baidu.com baidu.pdf { 要生成图片的的网址（例：https://www.baidu.com）baidu.pdf是生成的图片格式}
~~~

~~~
wkhtmltopdf --grayscale --disable-smart-shrinking --header-html head.html www.baidu.com baidu.pdf[         1       ][        2      ] [                 3                  ] [                 4                 ] [               5                       ]从左到右依次是：1命令开始、2使用灰度模式、3禁止智能缩放、4设置页眉为html文件、5生成pdf的页面网址、5生成的pdf文件名称
~~~

###### windows版本

~~~
下载地址：http://wkhtmltopdf.org/downloads.html 
~~~

~~~
设置环境变量后 如上所示输入对应指令
~~~



### 8.3 Linux环境

#### 8.3.1 Linux下部署下 安装jdk tomcat  mysql

https://www.cnblogs.com/shenjianping/p/10984540.html mysql

JDK环境配置  用文本编辑器打开/etc/profile，在profile文件末尾加入：

~~~java
JAVA_HOME=/usr/share/jdk1.5.0_05PATH=$JAVA_HOME/bin:$PATHCLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jarexport JAVA_HOMEexport PATHexport CLASSPATH
~~~

重新加载 source /etc/profile



Tomcat 环境配置 

~~~java
export  CATALINA_HOME=/usr/local/tomcat/apache-tomcat-9.0.43export  PATH=$CATALINA_HOME/bin:$PATH
~~~



#### 8.3.2 Linux 部署宝塔 （快速部署环境）

##### 安装宝塔面板只需要一句话命令：

> yum install -y wget && wget -O install.sh http://download.bt.cn/install/install_6.0.sh && sh install.sh

宝塔下 可安装nginx、部署站点、redis、mysql、mongodb、memcache



#### 8.3.3 unzip和zip命令安装

~~~shell
yum install -y unzip zip
~~~



#### 8.3.4 集群搭建

##### 1.nginx集群

upstream配置集群

首先，docker中存在nginx 镜像。
其次，实例化生成三个容器。(实例化nginx )
三台容器的IP地址并不需要修改，在生成容器之初不需要指定bridge和sub等选项。其中一台容器为主节点需要端口映射，而其他容器并不需要端口映射。
部署过程
docker pull nginx

docker pull daocloud.io/nginx

拉取镜像使用这两条命令中的任意一个，速度第二个快。



实例化容器，注意镜像名需要更换。

docker run -itd --name nginx1 -p 8080:80 centos_nginx /bin/bash

返回容器ID64位， 在'docker ps'中可以查到，ID为实例化时[:12]

docker run -itd --name nginx2 centos_nginx /bin/bash

docker run -itd --name nginx3 centos_nginx /bin/bash

创建三台nginx容器，主节点为第一台名为'nginx1'，因为拥有端口映射。其余nginx容器作为负载均衡。


用另外一个终端去检查docker的虚拟网卡bridge



根据反馈结果，可以看出来bridge 中的存在nginx1-3它们的网卡信息。



接下来的步骤是nginx1节点的步骤

进入容器的方式

docker exec -it [nginx1节点的ID] /bin/bash


三台容器都需要的步骤如下

apt update

apt install vim 


nginx1需要做的

cd /etc/nginx/ 
vim nginx.conf



相比于没有修改的nginx.conf 文件，现在多了upstream 172.17.0.2和server两个字典。

在upstream中，可以指定域名，同样可以指定Ip，但是不需要加端口。因为server中已经开始监听80端口了。如果需要，可以修改80端口。

upstream中，填写三台容器中另外两台子节点。因为它们是负载节点，所以分配它们权重值。

重启nginx服务

service nginx restart

这一步执行之后，容器将会关闭。因为当前容器依赖的镜像是nginx镜像

然后在外部用docker指令将nginx1启动

docker start [nginx1ID]

接下来的步骤是nginx2节点的步骤

进入容器的方式

docker exec -it [nginx2节点的ID] /bin/bash

apt

apt update

apt install vim 

然后只需要修改nginx所使用的默认html文件就可以了。

cd /usr/share/nginx/html/

vim index.html



仅仅只是在<h1>标签中写了一句From 172.16.0.2:80!当然，主节点nginx1不需要修改html文件。但是nginx2和nginx3需要修改html文件。在nginx2的html文件中，别写成主机点nginx1的IP地址。

nginx3节点和nginx2节点步骤一样，只需要将html中的添加一下当前所处容器的IP+port即可（port可加可不加）


##### 2.redis集群

环境：Docker + ( Redis:5.0.5 * 3 )

###### 1、拉取镜像

```
docker  pull  redis:5.0.5
```

![img](https://gitee.com/niceyoo/blog/raw/master/img/image-20200531101955906.png)

###### 2、创建Redis容器

创建三个 redis 容器：

- redis-node1：6379
- redis-node2：6380
- redis-node3：6381

```
docker create --name redis-node1 -v /data/redis-data/node1:/data -p 6379:6379 redis:5.0.5 --cluster-enabled yes --cluster-config-file nodes-node-1.confdocker create --name redis-node2 -v /data/redis-data/node2:/data -p 6380:6379 redis:5.0.5 --cluster-enabled yes --cluster-config-file nodes-node-2.confdocker create --name redis-node3 -v /data/redis-data/node3:/data -p 6381:6379 redis:5.0.5 --cluster-enabled yes --cluster-config-file nodes-node-3.conf
```

![img](https://gitee.com/niceyoo/blog/raw/master/img/image-20200531103114409.png)

###### 3、启动并组建集群

启动容器

首先通过命令`docker start`来启动3个Redis容器：

![img](https://gitee.com/niceyoo/blog/raw/master/img/image-20200531104809850.png)

执行完运行命令后检查一下容器的启动情况：

![img](https://gitee.com/niceyoo/blog/raw/master/img/image-20200531105644785.png)

如果出现上图情况，`Exited (1) 3 seconds ago`，可以通过 `docker logs` 查看：

![img](https://gitee.com/niceyoo/blog/raw/master/img/image-20200531105938546.png)

如上提示的是权限问题，我们尝试修改一下权限：

```
chmod -R  777 /data
```

启动成功后如下图所示：

![img](https://gitee.com/niceyoo/blog/raw/master/img/image-20200531115746286.png)

###### 组建集群

查看3个Redis在Docker中分配的ip结点信息：

```
执行「docker inspect redis-node1」得到 redis-node1 ip 信息为：172.17.0.4 执行「docker inspect redis-node2」得到 redis-node2 ip 信息为：172.17.0.3 执行「docker inspect redis-node3」得到 redis-node3 ip 信息为：172.17.0.2
```

![img](https://gitee.com/niceyoo/blog/raw/master/img/image-20200531115950259.png)

拿到 ip 信息后（每个人的ip信息可能不一样），接下来进入某一个容器进行组建集群：

```
# 这里以进入 node1 为例docker exec -it redis-node1 /bin/bash# 接着执行组建集群命令（请根据自己的ip信息进行拼接）redis-cli --cluster create 172.17.0.2:6379  172.17.0.3:6379  172.17.0.4:6379 --cluster-replicas 0
```

![img](https://gitee.com/niceyoo/blog/raw/master/img/image-20200531125547420.png)

ok，此时集群搭建完了，我们接下来测试一下。

###### 测试集群

使用 `redis-cli -c` 命令连接到集群结点，然后 set 值，set 值之后会自动重定向到 0.2 ip地址，然后通过 get 获取一下，获取成功证明集群有效。

![img](https://gitee.com/niceyoo/blog/raw/master/img/image-20200531130002028.png)

###### 4、存在的问题

按照如上的步骤，虽然集群搭建成功了，但其实还是有点问题的，由于集群结点中的 `ip地址` 是docket内部分配的，如：`172.17.0.2` 等，如果使用 `redis集群` 的项目跟集群不在一台服务器上，那么项目是没法使用集群的，因为是访问不通的。

![img](https://gitee.com/niceyoo/blog/raw/master/img/image-20200531135356244.png)

一种解决方案是让**Docker**使用 `host模式` 的网络连接类型，**Docker**在使用`host模式`下创建的容器是没有自己独立的网络命名空间的，是跟物理机共享一个网络空间，进而可以共享物理机的所有**端口与IP**，这样就可以让公共网络直接访问容器了，尽管这种方式有安全隐患，但目前来说还没找到其他可行性模式。

就存在的问题我们重新采用 `host模式`，重新创建一下容器：

###### 1、停止已运行的容器

```
docker stop redis-node1 redis-node2 redis-node3
```

###### 2、删除之前创建的容器

```
docker rm redis-node1 redis-node2 redis-node3# 清空上面创建的配置文件rm -rf /data/redis-data/node*
```

###### 3、重新基于host模式创建

```
docker create --name redis-node1 --net host -v /data/redis-data/node1:/data redis:5.0.5 --cluster-enabled yes --cluster-config-file nodes-node-1.conf --port 6379docker create --name redis-node2 --net host -v /data/redis-data/node2:/data redis:5.0.5 --cluster-enabled yes --cluster-config-file nodes-node-2.conf --port 6380docker create --name redis-node3 --net host -v /data/redis-data/node3:/data redis:5.0.5 --cluster-enabled yes --cluster-config-file nodes-node-3.conf --port 6381
```

跟之前创建命令不同，一是指定了 `--net` 网络类型为 `host`，二是这种情况下就不需要端口映射了，比如 `-p 6379:6379`，因为此时需要对外共享容器端口服务，所以只需要指定对外暴露的端口 `-p 6379`、`-p 6380` 等。

![img](https://gitee.com/niceyoo/blog/raw/master/img/image-20200531141150532.png)

###### 4、启动容器并组建集群

```
# 启动命令docker start redis-node1 redis-node2 redis-node3# 进入某一个容器docker exec -it redis-node1 /bin/bash# 组建集群,10.211.55.4为当前物理机的ip地址redis-cli --cluster create 10.211.55.4:6379  10.211.55.4:6380  10.211.55.4:6381 --cluster-replicas 0
```

![img](https://gitee.com/niceyoo/blog/raw/master/img/image-20200531141853380.png)

###### 5、查看集群信息

```
root@CentOS7:/data# redis-cli127.0.0.1:6379> cluster nodes72c291c32815194b64d1f6d0fdf771f5cc04e14a 10.211.55.4:6380@16380 master - 0 1590905997358 2 connected 5461-109226a595b67bbff15c94e5874c2d2cd556d6a6a6c17 10.211.55.4:6381@16381 master - 0 1590905998362 3 connected 10923-163834e3dbdc8f835dcbc38291c88f08165ee51d53d3d 10.211.55.4:6379@16379 myself,master - 0 1590905997000 1 connected 0-5460127.0.0.1:6379>
```

###### 6、测试集群

使用 `redis-cli -c` 连接到集群上，`set`一个值，然后从其他节点再获取值查看是否成功：

```
root@CentOS7:/data# redis-cli -c127.0.0.1:6379> set wxiaowei 123-> Redirected to slot [7515] located at 10.211.55.4:6380OK10.211.55.4:6380> get wxiaowei"123"
```

![img](https://gitee.com/niceyoo/blog/raw/master/img/image-20200531142541229.png)

至此，本次基于Docker的Redis集群`单副本模式`算是搭建好了，文中3个redis都是用的主节点，关于多副本、主从架构高可用在后文补充。

**你们要的主从集群**：https://www.cnblogs.com/niceyoo/p/14118146.html



#### 8.3.5  Linux 安装 supervised 进程守护根据 

##### 一、supervisor简介

Supervisor是用Python开发的一套通用的进程管理程序，能将一个普通的命令行进程变为后台daemon，并监控进程状态，异常退出时能自动重启。它是通过fork/exec的方式把这些被管理的进程当作supervisor的子进程来启动，这样只要在supervisor的配置文件中，把要管理的进程的可执行文件的路径写进去即可。也实现当子进程挂掉的时候，父进程可以准确获取子进程挂掉的信息的，可以选择是否自己启动和报警。supervisor还提供了一个功能，可以为supervisord或者每个子进程，设置一个非root的user，这个user就可以管理它对应的进程。

*注：本文以centos7为例，supervisor版本3.4.0。*

##### 二、supervisor安装

1. 配置好yum源后，可以直接安装

   

   ```undefined
   yum install supervisor
   ```

2. Debian/Ubuntu可通过apt安装

   

   ```csharp
   apt-get install supervisor
   ```

3. pip安装

   

   ```undefined
   pip install supervisor
   ```

4. easy_install安装

   

   ```undefined
   easy_install supervisor
   ```

##### 三、supervisor使用

##### supervisor配置文件：`/etc/supervisord.conf`

*注：supervisor的配置文件默认是不全的，不过在大部分默认的情况下，上面说的基本功能已经满足。*

##### 子进程配置文件路径：`/etc/supervisord.d/`

*注：默认子进程配置文件为ini格式，可在supervisor主配置文件中修改。*

##### 四、配置文件说明

###### supervisor.conf配置文件说明：



```cpp
[unix_http_server]file=/tmp/supervisor.sock   ;UNIX socket 文件，supervisorctl 会使用;chmod=0700                 ;socket文件的mode，默认是0700;chown=nobody:nogroup       ;socket文件的owner，格式：uid:gid ;[inet_http_server]         ;HTTP服务器，提供web管理界面;port=127.0.0.1:9001        ;Web管理后台运行的IP和端口，如果开放到公网，需要注意安全性;username=user              ;登录管理后台的用户名;password=123               ;登录管理后台的密码 [supervisord]logfile=/tmp/supervisord.log ;日志文件，默认是 $CWD/supervisord.loglogfile_maxbytes=50MB        ;日志文件大小，超出会rotate，默认 50MB，如果设成0，表示不限制大小logfile_backups=10           ;日志文件保留备份数量默认10，设为0表示不备份loglevel=info                ;日志级别，默认info，其它: debug,warn,tracepidfile=/tmp/supervisord.pid ;pid 文件nodaemon=false               ;是否在前台启动，默认是false，即以 daemon 的方式启动minfds=1024                  ;可以打开的文件描述符的最小值，默认 1024minprocs=200                 ;可以打开的进程数的最小值，默认 200 [supervisorctl]serverurl=unix:///tmp/supervisor.sock ;通过UNIX socket连接supervisord，路径与unix_http_server部分的file一致;serverurl=http://127.0.0.1:9001 ; 通过HTTP的方式连接supervisord ; [program:xx]是被管理的进程配置参数，xx是进程的名称[program:xx]command=/opt/apache-tomcat-8.0.35/bin/catalina.sh run  ; 程序启动命令autostart=true       ; 在supervisord启动的时候也自动启动startsecs=10         ; 启动10秒后没有异常退出，就表示进程正常启动了，默认为1秒autorestart=true     ; 程序退出后自动重启,可选值：[unexpected,true,false]，默认为unexpected，表示进程意外杀死后才重启startretries=3       ; 启动失败自动重试次数，默认是3user=tomcat          ; 用哪个用户启动进程，默认是rootpriority=999         ; 进程启动优先级，默认999，值小的优先启动redirect_stderr=true ; 把stderr重定向到stdout，默认falsestdout_logfile_maxbytes=20MB  ; stdout 日志文件大小，默认50MBstdout_logfile_backups = 20   ; stdout 日志文件备份数，默认是10; stdout 日志文件，需要注意当指定目录不存在时无法正常启动，所以需要手动创建目录（supervisord 会自动创建日志文件）stdout_logfile=/opt/apache-tomcat-8.0.35/logs/catalina.outstopasgroup=false     ;默认为false,进程被杀死时，是否向这个进程组发送stop信号，包括子进程killasgroup=false     ;默认为false，向进程组发送kill信号，包括子进程 ;包含其它配置文件[include]files = relative/directory/*.ini    ;可以指定一个或多个以.ini结束的配置文件
```

##### 子进程配置文件说明：

给需要管理的子进程(程序)编写一个配置文件，放在`/etc/supervisor.d/`目录下，以`.ini`作为扩展名（每个进程的配置文件都可以单独分拆也可以把相关的脚本放一起）。如任意定义一个和脚本相关的项目名称的选项组（/etc/supervisord.d/test.conf）：



```ruby
#项目名[program:blog]#脚本目录directory=/opt/bin#脚本执行命令command=/usr/bin/python /opt/bin/test.py#supervisor启动的时候是否随着同时启动，默认Trueautostart=true#当程序exit的时候，这个program不会自动重启,默认unexpected，设置子进程挂掉后自动重启的情况，有三个选项，false,unexpected和true。如果为false的时候，无论什么情况下，都不会被重新启动，如果为unexpected，只有当进程的退出码不在下面的exitcodes里面定义的autorestart=false#这个选项是子进程启动多少秒之后，此时状态如果是running，则我们认为启动成功了。默认值为1startsecs=1#脚本运行的用户身份 user = test#日志输出 stderr_logfile=/tmp/blog_stderr.log stdout_logfile=/tmp/blog_stdout.log #把stderr重定向到stdout，默认 falseredirect_stderr = true#stdout日志文件大小，默认 50MBstdout_logfile_maxbytes = 20MB#stdout日志文件备份数stdout_logfile_backups = 20
```

##### 子进程配置示例：



```bash
#说明同上[program:test] directory=/opt/bin command=/opt/bin/testautostart=true autorestart=false stderr_logfile=/tmp/test_stderr.log stdout_logfile=/tmp/test_stdout.log #user = test  
```

##### 五、supervisor命令说明

##### 常用命令



```cpp
supervisorctl status        //查看所有进程的状态supervisorctl stop es       //停止essupervisorctl start es      //启动essupervisorctl restart       //重启essupervisorctl update        //配置文件修改后使用该命令加载新的配置supervisorctl reload        //重新启动配置中的所有程序
```

注：把`es`换成`all`可以管理配置中的所有进程。直接输入`supervisorctl`进入supervisorctl的shell交互界面，此时上面的命令不带supervisorctl可直接使用。

##### 注意事项

使用supervisor进程管理命令之前先启动supervisord，否则程序报错。
 使用命令`supervisord -c /etc/supervisord.conf`启动。
 若是centos7：



```cpp
systemctl start supervisord.service     //启动supervisor并加载默认配置文件systemctl enable supervisord.service    //将supervisor加入开机启动项
```

##### 常见问题

1. unix:///var/run/supervisor.sock no such file
   问题描述：安装好supervisor没有开启服务直接使用supervisorctl报的错
   解决办法：`supervisord -c /etc/supervisord.conf`
2. command中指定的进程已经起来，但supervisor还不断重启
   问题描述：command中启动方式为后台启动，导致识别不到pid，然后不断重启，这里使用的是elasticsearch，command指定的是`$path/bin/elasticsearch -d`                    
   解决办法：supervisor无法检测后台启动进程的pid，而supervisor本身就是后台启动守护进程，因此不用担心这个
3. 启动了多个supervisord服务，导致无法正常关闭服务
   问题描述：在运行`supervisord -c /etc/supervisord.conf`之前，直接运行过`supervisord -c /etc/supervisord.d/xx.conf`导致有些进程被多个superviord管理，无法正常关闭进程。
   解决办法：使用`ps -fe | grep supervisord`查看所有启动过的supervisord服务，kill相关的进程。

###### 更多信息请移步Supervisor官网：[http://supervisord.org](https://links.jianshu.com/go?to=http%3A%2F%2Fsupervisord.org)



### 8.3.6 Linux 安装 Keepalived（高可用）

#### [Linux下Keepalived 安装与配置](https://www.cnblogs.com/dcrq/p/5642680.html)

一、环境说明

 

1、操作系统内核版本：2.6.9-78.ELsmp

  2、Keepalived软件版本：keepalived-1.1.20.tar.gz

 

二、环境配置

 

1、主Keepalived服务器IP地址 192.168.111.223

2、备Keepalived服务器IP地址 192.168.111.100

3、Keepalived虚拟IP地址 192.168.111.150

 

三、软件下载地址

 

   http://www.keepalived.org/software/keepalived-1.1.20.tar.gz

 

四、安装流程

 

  1、上传Keepalived至/home/目录

  2、解压Keepalived软件

   [root@localhost home]# tar -zxvf keepalived-1.1.20.tar.gz 

   [root@localhost home]# cd keepalived-1.1.20

   [root@localhost keepalived-1.1.20]# ln -s /usr/src/kernels/2.6.9-78.EL-i686/usr/src//linux

   [root@localhost keepalived-1.1.20]# ./configure 

 

　　遇到错误提示：configure: error: Popt libraries is required

　　这个错误是因为没有安装popt的开发包导致的，解决方法也很简单，只要yum install popt-devel 就可以安装好popt的开发包了。

　　重新./configure

　　没有遇到跳过这一步

  3、提示

​     ![img](https://images2015.cnblogs.com/blog/971251/201609/971251-20160911132315044-327292328.png)

 

  4、编译以及编译安装

   [root@localhost keepalived-1.1.20]# make && make install

![img](https://images2015.cnblogs.com/blog/971251/201609/971251-20160911132338937-1524470999.png)

   5、将types.h调用的部分注释掉即可解决4出现的问题

   vi/usr/src/kernels/2.6.9-78.EL-i686/include/linux/types.h 

   到158行操作如下

   

  \#endif 

  

  

 6、重新编译以及编译安装

   [root@localhost keepalived-1.1.20]# make && make install

​    ![img](https://images2015.cnblogs.com/blog/971251/201609/971251-20160911132406501-1039410226.png)

  7、修改配置文件路径

​    [[root@localhostkeepalived-1.1.20\]#cp/usr/local/etc/rc.d/init.d/keepalived/etc/rc.d/init.d/](mailto:[root@localhostkeepalived-1.1.20]#cp/usr/local/etc/rc.d/init.d/keepalived/etc/rc.d/init.d/)

​    [root@localhostkeepalived-1.1.20]# cp /usr/local/etc/sysconfig/keepalived /etc/sysconfig/

​    [root@localhost keepalived-1.1.20]# mkdir /etc/keepalived

​    [[root@localhostkeepalived-1.1.20\]#cp](mailto:[root@localhostkeepalived-1.1.20]#cp) /usr/local/etc/keepalived/keepalived.conf/etc/keepalived/              

​    [root@localhost keepalived-1.1.20]# cp /usr/local/sbin/keepalived /usr/sbin/

  8、设置为服务，开机启动

​    [root@localhost keepalived-1.1.20]# vi /etc/rc.local 

​    ![img](https://images2015.cnblogs.com/blog/971251/201609/971251-20160911132438425-2092407419.png)

 

五、主Keepalived配置

   1、修改配置文件

​    [root@localhost keepalived-1.1.20]# vi /etc/keepalived/keepalived.conf 

​    ![img](https://images2015.cnblogs.com/blog/971251/201609/971251-20160911132507333-1046966779.png)

六、备Keepalived配置

​    1、修改配置文件

​    ![img](https://images2015.cnblogs.com/blog/971251/201609/971251-20160911132530632-10532484.png)

七、启动服务

  ![img](https://images2015.cnblogs.com/blog/971251/201609/971251-20160911132551633-1820977883.png)

八、查看网卡信息

 1、主Keepalived网卡信息

![img](https://images2015.cnblogs.com/blog/971251/201609/971251-20160911132624651-125190919.png)

九、验证测试

 1、在主服务器上新建一个网页，内容为 192.168.111.223

 2、在备用服务器上新建一个网页，内容为 192.168.111.100

 3、启动主备服务器的http服务和Keepalived服务

 4、通过浏览数，输入虚拟IP地址 192.168.111.150

​    页面显示为 192.168.111.223

5、关闭主服务器的Keepalived服务，通过浏览器输入IP地址192.168.111.150

​    页面显示为 192.168.111.100

6、再次启动主服务器的Keepalived服务，通过浏览器输入IP地址192.168.111.150

​    页面显示为 192.168.111.223



配置介绍

~~~makefile
全局定义块1、email通知（notification_email、smtp_server、smtp_connect_timeout）：用于服务有故障时发送邮件报警，可选项，不建议用。需要系统开启sendmail服务，建议用第三独立监控服务，如用nagios全面监控代替。2、lvs_id：lvs负载均衡器标识，在一个网络内，它的值应该是唯一的。3、router_id：用户标识本节点的名称，通常为hostname4、花括号｛｝：用来分隔定义块，必须成对出现。如果写漏了，keepalived运行时不会得到预期的结果。由于定义块存在嵌套关系，因此很容易遗漏结尾处的花括号，这点需要特别注意。VRRP实例定义块vrrp_sync_group：同步vrrp级，用于确定失败切换（FailOver）包含的路由实例个数。即在有2个负载均衡器的场景，一旦某个负载均衡器失效，需要自动切换到另外一个负载均衡器的实例是哪group：至少要包含一个vrrp实例，vrrp实例名称必须和vrrp_instance定义的一致vrrp_instance：vrrp实例名1> state：实例状态，只有MASTER 和 BACKUP两种状态，并且需要全部大写。抢占模式下，其中MASTER为工作状态，BACKUP为备用状态。当MASTER所在的服务器失效时，BACKUP所在的服务会自动把它的状态由BACKUP切换到MASTER状态。当失效的MASTER所在的服务恢复时，BACKUP从MASTER恢复到BACKUP状态。2> interface：对外提供服务的网卡接口，即VIP绑定的网卡接口。如：eth0，eth1。当前主流的服务器都有2个或2个以上的接口（分别对应外网和内网），在选择网卡接口时，一定要核实清楚。3> mcast_src_ip：本机IP地址4> virtual_router_id：虚拟路由的ID号，每个节点设置必须一样，可选择IP最后一段使用，相同的 VRID 为一个组，他将决定多播的 MAC 地址。5> priority：节点优先级，取值范围0～254，MASTER要比BACKUP高6> advert_int：MASTER与BACKUP节点间同步检查的时间间隔，单位为秒7> lvs_sync_daemon_inteface：负载均衡器之间的监控接口,类似于 HA HeartBeat 的心跳线。但它的机制优于 Heartbeat，因为它没有“裂脑”这个问题,它是以优先级这个机制来规避这个麻烦的。在 DR 模式中，lvs_sync_daemon_inteface与服务接口interface使用同一个网络接口8> authentication：验证类型和验证密码。类型主要有 PASS、AH 两种，通常使用PASS类型，据说AH使用时有问题。验证密码为明文，同一vrrp 实例MASTER与BACKUP使用相同的密码才能正常通信。9> smtp_alert：有故障时是否激活邮件通知10> nopreempt：禁止抢占服务。默认情况，当MASTER服务挂掉之后，BACKUP自动升级为MASTER并接替它的任务，当MASTER服务恢复后，升级为MASTER的BACKUP服务又自动降为BACKUP，把工作权交给原MASTER。当配置了nopreempt，MASTER从挂掉到恢复，不再将服务抢占过来。11> virtual_ipaddress：虚拟IP地址池，可以有多个IP，每个IP占一行，不需要指定子网掩码。注意：这个IP必须与我们的设定的vip保持一致。虚拟服务器virtual_server定义块virtual_server：定义一个虚拟服务器，这个ip是virtual_ipaddress中定义的其中一个，后面一个空格，然后加上虚拟服务的端口号。1> delay_loop：健康检查时间间隔，单位：秒2> lb_algo：负载均衡调度算法，互联网应用常用方式为wlc或rr3> lb_kind：负载均衡转发规则。包括DR、NAT、TUN 3种，一般使用路由（DR）转发规则。4> persistence_timeout：http服务会话保持时间，单位：秒5> protocol：转发协议，分为TCP和UDP两种real_server：真实服务器IP和端口，可以定义多个1> weight：负载权重，值越大，转发的优先级越高2> notify_down：服务停止后执行的脚本3> TCP_CHECK：服务有效性检测* connect_port：服务连接端口* connect_timeout：服务连接超时时长，单位：秒* nb_get_retry：服务连接失败重试次数* delay_before_retry：重试连接间隔，单位：秒
~~~







## 九：工具

~~~java
package com.tongrong.utils;import java.util.Collection;import java.util.Map;import java.util.regex.Matcher;import java.util.regex.Pattern;import org.apache.commons.lang.StringUtils;/** * Java表单验证工具类 *  * @author jiqinlin *  */@SuppressWarnings("unchecked")public class RegexUtil {    public static void main(String[] args) {//        System.out.println("过滤中英文特殊字符: "+RegexUtil.stringFilter("中国~~!#$%%."));//        System.out.println("是否包含中英文特殊字符: "+RegexUtil.isContainsSpecialChar("12"));//        System.out.println("过滤html代码: "+RegexUtil.htmltoText("<JAVASCRIPT>12</JAVASCRIPT>DDDDD"));//        System.out.println("判断中文字符: "+RegexUtil.isChineseChar("中国！"));        System.out.println("匹配汉字: "+RegexUtil.isChinese("中国！"));//        System.out.println("判断英文字符: "+RegexUtil.isEnglish("abc!"));//        System.out.println("判断合法字符: "+RegexUtil.isRightfulString("abc_-11AAA"));//        System.out.println("邮政编码验证: "+RegexUtil.isZipCode("162406"));//        System.out.println("身份证号码验证: "+RegexUtil.isIdCardNo("35052419880210133e"));//        System.out.println("手机号码验证: "+RegexUtil.isMobile("18918611111"));//        System.out.println("电话号码验证: "+RegexUtil.isPhone("8889333"));//        System.out.println("电话号码验证: "+RegexUtil.isNumeric("888.9333"));//        System.out.println("匹配密码: "+RegexUtil.isPwd("d888d_ddddd"));//        System.out.println("匹配密码: "+RegexUtil.isUrl("http://baidu.com"));        System.out.println("验证字符: "+RegexUtil.stringCheck("中文aabc001_-"));//        System.out.println(isEmail("416501600@qq.com"));        //http://baidu.com www.baidu.com baidu.com//        System.out.println(NumberUtils.toInt("-0000000002"));    }        public final static boolean isNull(Object[] objs){        if(objs==null||objs.length==0) return true;        return false;    }        public final static boolean isNull(Integer integer){        if(integer==null||integer==0) return true;        return false;    }        public final static boolean isNull(Collection collection){        if(collection==null||collection.size()==0) return true;        return false;    }        public final static boolean isNull(Map map){        if(map==null||map.size()==0) return true;        return false;    }        public final static boolean isNull(String str){        return str == null || "".equals(str.trim()) || "null".equals(str.toLowerCase());    }            public final static boolean isNull(Long longs){        if(longs==null||longs==0) return true;        return false;    }        public final static boolean isNotNull(Long longs){        return !isNull(longs);    }        public final static boolean isNotNull(String str){        return !isNull(str);    }        public final static boolean isNotNull(Collection collection){        return !isNull(collection);    }        public final static boolean isNotNull(Map map){        return !isNull(map);    }        public final static boolean isNotNull(Integer integer){        return !isNull(integer);    }        public final static boolean isNotNull(Object[] objs){        return !isNull(objs);    }        /**     * 匹配URL地址     *      * @param str     * @return     * @author jiqinlin     */    public final static boolean isUrl(String str) {        return match(str, "^http://([\\w-]+\\.)+[\\w-]+(/[\\w-./?%&=]*)?$");    }        /**     * 匹配密码，以字母开头，长度在6-12之间，只能包含字符、数字和下划线。     *      * @param str     * @return     * @author jiqinlin     */    public final static boolean isPwd(String str) {        return match(str, "^[a-zA-Z]\\w{6,12}$");    }        /**     * 验证字符，只能包含中文、英文、数字、下划线等字符。     *      * @param str     * @return     * @author jiqinlin     */    public final static boolean stringCheck(String str) {        return match(str, "^[a-zA-Z0-9\u4e00-\u9fa5-_]+$");    }        /**     * 匹配Email地址     *      * @param str     * @return     * @author jiqinlin     */    public final static boolean isEmail(String str) {        return match(str, "^\\w+([-+.]\\w+)*@\\w+([-.]\\w+)*\\.\\w+([-.]\\w+)*$");    }        /**     * 匹配非负整数（正整数+0）     *      * @param str     * @return     * @author jiqinlin     */    public final static boolean isInteger(String str) {        return match(str, "^[+]?\\d+$");    }        /**     * 判断数值类型，包括整数和浮点数     *      * @param str     * @return     * @author jiqinlin     */    public final static boolean isNumeric(String str) {         if(isFloat(str) || isInteger(str)) return true;        return false;    }        /**     * 只能输入数字     *      * @param str     * @return     * @author jiqinlin     */    public final static boolean isDigits(String str) {        return match(str, "^[0-9]*$");    }        /**     * 匹配正浮点数     *      * @param str     * @return     * @author jiqinlin     */    public final static boolean isFloat(String str) {        return match(str, "^[-\\+]?\\d+(\\.\\d+)?$");    }        /**     * 联系电话(手机/电话皆可)验证        *      * @param text     * @return     * @author jiqinlin     */    public final static boolean isTel(String text){        if(isMobile(text)||isPhone(text)) return true;        return false;    }        /**     * 电话号码验证       *      * @param text     * @return     * @author jiqinlin     */    public final static boolean isPhone(String text){        return match(text, "^(\\d{3,4}-?)?\\d{7,9}$");    }        /**     * 手机号码验证        *      * @param text     * @return     * @author jiqinlin     */    public final static boolean isMobile(String text){        if(text.length()!=11) return false;        return match(text, "^(((13[0-9]{1})|(15[0-9]{1})|(18[0-9]{1}))+\\d{8})$");    }        /**     * 身份证号码验证      *      * @param text     * @return     * @author jiqinlin     */    public final static boolean isIdCardNo(String text){        return match(text, "^(\\d{6})()?(\\d{4})(\\d{2})(\\d{2})(\\d{3})(\\w)$");    }        /**     * 邮政编码验证      *      * @param text     * @return     * @author jiqinlin     */    public final static boolean isZipCode(String text){        return match(text, "^[0-9]{6}$");    }        /**     * 判断整数num是否等于0     *      * @param num     * @return     * @author jiqinlin     */    public final static boolean isIntEqZero(int num){          return num==0;    }        /**     * 判断整数num是否大于0     *      * @param num     * @return     * @author jiqinlin     */    public final static boolean isIntGtZero(int num){          return num>0;    }        /**     * 判断整数num是否大于或等于0     *      * @param num     * @return     * @author jiqinlin     */    public final static boolean isIntGteZero(int num){         return num>=0;    }        /**     * 判断浮点数num是否等于0     *      * @param num 浮点数     * @return     * @author jiqinlin     */    public final static boolean isFloatEqZero(float num){          return num==0f;    }        /**     * 判断浮点数num是否大于0     *      * @param num 浮点数     * @return     * @author jiqinlin     */    public final static boolean isFloatGtZero(float num){          return num>0f;    }        /**     * 判断浮点数num是否大于或等于0     *      * @param num 浮点数     * @return     * @author jiqinlin     */    public final static boolean isFloatGteZero(float num){         return num>=0f;    }        /**     * 判断是否为合法字符(a-zA-Z0-9-_)     *      * @param text     * @return     * @author jiqinlin     */    public final static boolean isRightfulString(String text){        return match(text, "^[A-Za-z0-9_-]+$");     }        /**     * 判断英文字符(a-zA-Z)     *      * @param text     * @return     * @author jiqinlin     */    public final static boolean isEnglish(String text){        return match(text, "^[A-Za-z]+$");     }        /**     * 判断中文字符(包括汉字和符号)     *      * @param text     * @return     * @author jiqinlin     */    public final static boolean isChineseChar(String text){        return match(text, "^[\u0391-\uFFE5]+$");    }        /**     * 匹配汉字     *      * @param text     * @return     * @author jiqinlin     */    public final static boolean isChinese(String text){        return match(text, "^[\u4e00-\u9fa5]+$");    }        /**     * 是否包含中英文特殊字符，除英文"-_"字符外     *      * @param str     * @return     */    public static boolean isContainsSpecialChar(String text) {        if(StringUtils.isBlank(text)) return false;        String[] chars={"[","`","~","!","@","#","$","%","^","&","*","(",")","+","=","|","{","}","'",                ":",";","'",",","[","]",".","<",">","/","?","~","！","@","#","￥","%","…","&","*","（","）",                "—","+","|","{","}","【","】","‘","；","：","”","“","’","。","，","、","？","]"};        for(String ch : chars){            if(text.contains(ch)) return true;        }        return false;    }        /**     * 过滤中英文特殊字符，除英文"-_"字符外     *      * @param text     * @return     */    public static String stringFilter(String text) {        String regExpr="[`~!@#$%^&*()+=|{}':;',\\[\\].<>/?~！@#￥%……&*（）——+|{}【】‘；：”“’。，、？]";          Pattern p = Pattern.compile(regExpr);        Matcher m = p.matcher(text);        return m.replaceAll("").trim();         }        /**     * 过滤html代码     *      * @param inputString 含html标签的字符串     * @return     */    public static String htmlFilter(String inputString) {        String htmlStr = inputString; // 含html标签的字符串        String textStr = "";        java.util.regex.Pattern p_script;        java.util.regex.Matcher m_script;        java.util.regex.Pattern p_style;        java.util.regex.Matcher m_style;        java.util.regex.Pattern p_html;        java.util.regex.Matcher m_html;        java.util.regex.Pattern p_ba;        java.util.regex.Matcher m_ba;        try {            String regEx_script = "<[\\s]*?script[^>]*?>[\\s\\S]*?<[\\s]*?\\/[\\s]*?script[\\s]*?>"; // 定义script的正则表达式{或<script[^>]*?>[\\s\\S]*?<\\/script>            // }            String regEx_style = "<[\\s]*?style[^>]*?>[\\s\\S]*?<[\\s]*?\\/[\\s]*?style[\\s]*?>"; // 定义style的正则表达式{或<style[^>]*?>[\\s\\S]*?<\\/style>            // }            String regEx_html = "<[^>]+>"; // 定义HTML标签的正则表达式            String patternStr = "\\s+";            p_script = Pattern.compile(regEx_script, Pattern.CASE_INSENSITIVE);            m_script = p_script.matcher(htmlStr);            htmlStr = m_script.replaceAll(""); // 过滤script标签            p_style = Pattern.compile(regEx_style, Pattern.CASE_INSENSITIVE);            m_style = p_style.matcher(htmlStr);            htmlStr = m_style.replaceAll(""); // 过滤style标签            p_html = Pattern.compile(regEx_html, Pattern.CASE_INSENSITIVE);            m_html = p_html.matcher(htmlStr);            htmlStr = m_html.replaceAll(""); // 过滤html标签            p_ba = Pattern.compile(patternStr, Pattern.CASE_INSENSITIVE);            m_ba = p_ba.matcher(htmlStr);            htmlStr = m_ba.replaceAll(""); // 过滤空格            textStr = htmlStr;        } catch (Exception e) {            System.err.println("Html2Text: " + e.getMessage());        }        return textStr;// 返回文本字符串    }        /**     * 正则表达式匹配     *      * @param text 待匹配的文本     * @param reg 正则表达式     * @return     * @author jiqinlin     */    private final static boolean match(String text, String reg) {        if (StringUtils.isBlank(text) || StringUtils.isBlank(reg))            return false;        return Pattern.compile(reg).matcher(text).matches();    }        // 参考地址：http://www.cnblogs.com/yansheng/archive/2010/05/07/1730188.html    // 附 ： 常用的正则表达式：//    匹配特定数字：//    ^[1-9]d*$　 　 //匹配正整数//    ^-[1-9]d*$ 　 //匹配负整数//    ^-?[1-9]d*$　　 //匹配整数//    ^[1-9]d*|0$　 //匹配非负整数（正整数 + 0）//    ^-[1-9]d*|0$　　 //匹配非正整数（负整数 + 0）//    ^[1-9]d*.d*|0.d*[1-9]d*$　　 //匹配正浮点数//    ^-([1-9]d*.d*|0.d*[1-9]d*)$　 //匹配负浮点数//    ^-?([1-9]d*.d*|0.d*[1-9]d*|0?.0+|0)$　 //匹配浮点数//    ^[1-9]d*.d*|0.d*[1-9]d*|0?.0+|0$　　 //匹配非负浮点数（正浮点数 + 0）//    ^(-([1-9]d*.d*|0.d*[1-9]d*))|0?.0+|0$　　//匹配非正浮点数（负浮点数 + 0）//    评注：处理大量数据时有用，具体应用时注意修正////    匹配特定字符串：//    ^[A-Za-z]+$　　//匹配由26个英文字母组成的字符串//    ^[A-Z]+$　　//匹配由26个英文字母的大写组成的字符串//    ^[a-z]+$　　//匹配由26个英文字母的小写组成的字符串//    ^[A-Za-z0-9]+$　　//匹配由数字和26个英文字母组成的字符串//    ^w+$　　//匹配由数字、26个英文字母或者下划线组成的字符串////    在使用RegularExpressionValidator验证控件时的验证功能及其验证表达式介绍如下:////    只能输入数字：“^[0-9]*$”//    只能输入n位的数字：“^d{n}$”//    只能输入至少n位数字：“^d{n,}$”//    只能输入m-n位的数字：“^d{m,n}$”//    只能输入零和非零开头的数字：“^(0|[1-9][0-9]*)$”//    只能输入有两位小数的正实数：“^[0-9]+(.[0-9]{2})?$”//    只能输入有1-3位小数的正实数：“^[0-9]+(.[0-9]{1,3})?$”//    只能输入非零的正整数：“^+?[1-9][0-9]*$”//    只能输入非零的负整数：“^-[1-9][0-9]*$”//    只能输入长度为3的字符：“^.{3}$”//    只能输入由26个英文字母组成的字符串：“^[A-Za-z]+$”//    只能输入由26个大写英文字母组成的字符串：“^[A-Z]+$”//    只能输入由26个小写英文字母组成的字符串：“^[a-z]+$”//    只能输入由数字和26个英文字母组成的字符串：“^[A-Za-z0-9]+$”//    只能输入由数字、26个英文字母或者下划线组成的字符串：“^w+$”//    验证用户密码:“^[a-zA-Z]\\w{5,17}$”正确格式为：以字母开头，长度在6-18之间，////    只能包含字符、数字和下划线。//    验证是否含有^%&’,;=?$”等字符：“[^%&’,;=?$x22]+”//    只能输入汉字：“^[u4e00-u9fa5],{0,}$”//    验证Email地址：“^w+[-+.]w+)*@w+([-.]w+)*.w+([-.]w+)*$”//    验证InternetURL：“^http://([\\w-]+\\.)+[\\w-]+(/[\\w-./?%&=]*)?$”//    验证电话号码：“^((d{3,4})|d{3,4}-)?d{7,8}$”////    正确格式为：“XXXX-XXXXXXX”，“XXXX-XXXXXXXX”，“XXX-XXXXXXX”，////    “XXX-XXXXXXXX”，“XXXXXXX”，“XXXXXXXX”。//    验证身份证号（15位或18位数字）：“^d{15}|d{}18$”//    验证一年的12个月：“^(0?[1-9]|1[0-2])$”正确格式为：“01”-“09”和“1”“12”//    验证一个月的31天：“^((0?[1-9])|((1|2)[0-9])|30|31)$” 正确格式为：“01”“09”和“1”“31”。////    匹配中文字符的正则表达式： [u4e00-u9fa5]//    匹配双字节字符(包括汉字在内)：[^x00-xff]//    匹配空行的正则表达式：n[s| ]*r//    匹配HTML标记的正则表达式：/< (.*)>.*|< (.*) />///    匹配首尾空格的正则表达式：(^s*)|(s*$)//    匹配Email地址的正则表达式：w+([-+.]w+)*@w+([-.]w+)*.w+([-.]w+)*//    匹配网址URL的正则表达式：^http://([\\w-]+\\.)+[\\w-]+(/[\\w-./?%&=]*)?$}
~~~

